{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9HQY_81AHCW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from math import sqrt\n",
        "from time import time\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs4VKeqVLptn",
        "outputId": "48acdb99-c55a-480c-a220-044cb425046f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint  path.zip  sample_data  weather-final.npy\n",
            "flow.zip    poi.zip   time.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip flow.zip\n",
        "!unzip path.zip\n",
        "!unzip poi.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks3806bzLl3O",
        "outputId": "f0c47fe3-6f05-4eb5-a958-e72a30f8e81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  flow.zip\n",
            "  inflating: flow/flow_bike_nyc_irregular.json  \n",
            "  inflating: flow/flow_bike_nyc_regular.json  \n",
            "Archive:  path.zip\n",
            "  inflating: path/irregular_path.npy  \n",
            "  inflating: path/regular_path.npy   \n",
            "Archive:  poi.zip\n",
            "  inflating: poi/irregular_feature.npy  \n",
            "  inflating: poi/irregular_idx.npy   \n",
            "  inflating: poi/irregular_label.npy  \n",
            "  inflating: poi/irregular_weight.npy  \n",
            "  inflating: poi/regular_feature.npy  \n",
            "  inflating: poi/regular_idx.npy     \n",
            "  inflating: poi/regular_label.npy   \n",
            "  inflating: poi/regular_weight.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PopulationDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 division='regular',\n",
        "                 T=5,\n",
        "                 type='train'):\n",
        "        len_t = 24 * (31 + 31 + 30)\n",
        "        N = len_t - T\n",
        "        N_train = int(N * 0.8)\n",
        "        N_val = int(N * 0.1)\n",
        "        N_test = int(N * 0.1)\n",
        "        weekend = [i for i in range(1, 93, 7)] + [i for i in range(2, 93, 7)] + [4, 66]\n",
        "        T_SLOT = 24\n",
        "        C = 2\n",
        "        if division == 'regular':\n",
        "            H = 16\n",
        "            W = 8\n",
        "            num_node = H * W\n",
        "            raw_data = json.load(open(\"flow/flow_bike_nyc_regular.json\"))\n",
        "        elif division == 'irregular':\n",
        "            num_node = 82\n",
        "            raw_data = json.load(open(\"flow/flow_bike_nyc_irregular.json\"))\n",
        "\n",
        "        dataset = np.zeros((C, len_t, num_node), dtype=np.float32)\n",
        "        data1 = raw_data['inflow']\n",
        "        data2 = raw_data['outflow']\n",
        "\n",
        "\n",
        "        weather = np.load(\"/content/weather-final.npy\")\n",
        "        time = np.load(\"/content/time.npy\")\n",
        "\n",
        "        for node_no in range(num_node):\n",
        "            dataset[0, :, node_no] = np.array(data1[str(node_no)])\n",
        "            dataset[1, :, node_no] = np.array(data2[str(node_no)])\n",
        "\n",
        "        if type == 'train':\n",
        "            xy = np.zeros((N_train, C, T + 1, num_node), dtype=np.float32)\n",
        "            x_t = np.zeros((N_train, T), dtype=np.int64)\n",
        "            w_t = np.zeros((N_train, T + 1, weather.shape[1]), dtype=np.float32)\n",
        "            t_t = np.zeros((N_train, T + 1, time.shape[1]), dtype=np.float32)\n",
        "\n",
        "            for t in range(N_train):\n",
        "                xy[t, :, :, :] = dataset[:, t:t + T + 1, :]\n",
        "                w_t[t,:] = weather[t:t + T + 1,:]\n",
        "                t_t[t,:] = time[t:t + T + 1,:]\n",
        "                if (t + T + 1) // T_SLOT + 1 in weekend:\n",
        "                    x_t[t, :] = np.arange(t, t + T) % T_SLOT + T_SLOT\n",
        "                else:\n",
        "                    x_t[t, :] = np.arange(t, t + T) % T_SLOT\n",
        "\n",
        "        elif type == 'val':\n",
        "            xy = np.zeros((N_val, C, T + 1, num_node), dtype=np.float32)\n",
        "            x_t = np.zeros((N_val, T), dtype=np.int64)\n",
        "            w_t = np.zeros((N_val, T + 1, weather.shape[1]), dtype=np.float32)\n",
        "            t_t = np.zeros((N_val, T + 1, time.shape[1]), dtype=np.float32)\n",
        "\n",
        "            for t in range(N_train, N_train + N_val):\n",
        "                xy[t - N_train, :, :, :] = dataset[:, t:t + T + 1, :]\n",
        "                w_t[t- N_train,:] = weather[t:t + T + 1,:]\n",
        "                t_t[t- N_train,:] = time[t:t + T + 1,:]\n",
        "                if (t + T + 1) // T_SLOT + 1 in weekend:\n",
        "                    x_t[t - N_train, :] = np.arange(t, t + T) % T_SLOT + T_SLOT\n",
        "                else:\n",
        "                    x_t[t - N_train, :] = np.arange(t, t + T) % T_SLOT\n",
        "\n",
        "        elif type == 'test':\n",
        "            xy = np.zeros((N_test, C, T + 1, num_node), dtype=np.float32)\n",
        "            x_t = np.zeros((N_test, T), dtype=np.int64)\n",
        "            w_t = np.zeros((N_test, T + 1, weather.shape[1]), dtype=np.float32)\n",
        "            t_t = np.zeros((N_test, T + 1, time.shape[1]), dtype=np.float32)\n",
        "\n",
        "            for t in range(N_train + N_val, N_train + N_val + N_test):\n",
        "                xy[t - N_train - N_val, :, :, :] = dataset[:, t:t + T + 1, :]\n",
        "                w_t[t - N_train - N_val,:] = weather[t:t + T + 1,:]\n",
        "                t_t[t - N_train - N_val,:] = time[t:t + T + 1,:]\n",
        "                if (t + T + 1) // T_SLOT + 1 in weekend:\n",
        "                    x_t[t - N_train - N_val, :] = np.arange(t, t + T) % T_SLOT + T_SLOT\n",
        "                else:\n",
        "                    x_t[t - N_train - N_val, :] = np.arange(t, t + T) % T_SLOT\n",
        "\n",
        "        self.x_data = torch.from_numpy(xy[:, :, 0:-1, :])\n",
        "        self.x_t = torch.from_numpy(x_t)\n",
        "        self.w_t = torch.from_numpy(w_t[:,0:-1,:])\n",
        "        self.t_t = torch.from_numpy(t_t[:,0:-1,:])\n",
        "        self.y_data = torch.from_numpy(xy[:, :, -1, :])\n",
        "        self.len = xy.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.x_t[index], self.y_data[index], self.w_t[index], self.t_t[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "wP0QRYkzJ2f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "OkMW91QHJ9Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 division='regular',\n",
        "                 C=2,\n",
        "                 K=9,\n",
        "                 T=5):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.T_SLOT = 24\n",
        "        self.K = K\n",
        "        self.T = T\n",
        "        self.Gamma = 1\n",
        "\n",
        "        A = np.load('path/' + division + '_path.npy')\n",
        "        A_0 = A[:, :, :, 0]\n",
        "        A_sum = np.sum(A[:, :, :, 1:], axis=3)\n",
        "        for i in range(1, K + 1):\n",
        "            A[:, :, :, i] = A_sum\n",
        "        self.A = torch.Tensor(A)\n",
        "\n",
        "        feature = np.load('poi/' + division + '_feature.npy').astype(np.float32)\n",
        "\n",
        "        feature_size = np.size(feature, 1)\n",
        "        V = np.size(feature, 0)\n",
        "        self.F = torch.Tensor(feature)\n",
        "        self.A_mean = torch.Tensor(np.mean(A_0 + A_sum, axis=0)).permute(1, 0).contiguous()\n",
        "        self.I = torch.ones(V, V, 1)\n",
        "\n",
        "        self.networks = nn.ModuleList([\n",
        "            DGCN(C_in=C, C_out=32, kernel_size=(2 * self.Gamma + 1, K + 1)),\n",
        "            DGCN(C_in=32, C_out=64, kernel_size=(2 * self.Gamma + 1, K + 1)),\n",
        "            DGCN(C_in=64, C_out=32, kernel_size=(2 * self.Gamma + 1, K + 1)),\n",
        "            DGCN(C_in=32, C_out=16, kernel_size=(2 * self.Gamma + 1, K + 1)),\n",
        "            #DGCN(C_in=64, C_out=16, kernel_size=(2 * self.Gamma + 1, K + 1)),\n",
        "        ])\n",
        "\n",
        "        self.gru = nn.GRU(input_size=8, hidden_size=2, num_layers=8, batch_first=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(T, 1), stride=(1, 1))\n",
        "\n",
        "        self.semi1 = nn.Linear(feature_size, 16)\n",
        "        self.semi2 = nn.Linear(16, K)\n",
        "        self.LeakyReLU = nn.LeakyReLU()\n",
        "        self.Softmax = nn.Softmax()\n",
        "        self.temporal_conv = nn.Conv2d(16, C, kernel_size=(T, 1))\n",
        "        self.gru_conv = nn.Conv2d(1, C, kernel_size=(T, 1))\n",
        "        self.maxpool_conv = nn.Conv2d(16, C, kernel_size=(1, 1))\n",
        "        self.gru_time = nn.GRU(input_size=2, hidden_size=2, num_layers=1, batch_first=True)\n",
        "        self.weights = nn.Parameter(torch.rand(4))\n",
        "        self.conv1d_layer = nn.Conv1d(in_channels = 2, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x, x_t, idx, w_t, t_t):\n",
        "        N, C, T, V = x.size()\n",
        "        last = x[:, :, -1, :]\n",
        "        Y1 = self.LeakyReLU(torch.mm(self.A_mean, self.semi1(self.F)))\n",
        "        Y2 = self.LeakyReLU(torch.mm(self.A_mean, self.semi2(Y1)))\n",
        "        Y = torch.index_select(Y2, 0, idx)\n",
        "        Z = self.Softmax(Y2)\n",
        "        A_K = self.A * torch.cat((self.I, Z.repeat(V, 1, 1)), dim=2).repeat(self.T_SLOT * 2, 1, 1, 1)\n",
        "        x_t = x_t.view(N * T)\n",
        "        x_A = torch.index_select(A_K, 0, x_t)\n",
        "        x_A = x_A.view(N, T, V, V, -1)\n",
        "        for dgcn in self.networks:\n",
        "            x = dgcn(x, x_A)\n",
        "        # Perform maxpool on input X\n",
        "        output3 = self.maxpool(x)\n",
        "        output3 = self.maxpool_conv(output3)\n",
        "        output3 = output3.squeeze(-2)\n",
        "        # Temporal convolution on input X\n",
        "        x = self.temporal_conv(x)\n",
        "        output1 = x.view(N,-1,V)\n",
        "        # Gru for weather data\n",
        "        output2, _ = self.gru(w_t)\n",
        "        output2 = output2.unsqueeze(0)\n",
        "        output2 = output2.permute(1,0,2,3)\n",
        "        output2 = self.gru_conv(output2)\n",
        "        output2 = output2.view(N,-1,2)\n",
        "        output2 = output2[:, :, 0:1]\n",
        "        output2 = output2.squeeze(-1)\n",
        "        output2 = output2.unsqueeze(2)\n",
        "        # Gru for time data\n",
        "        output4, _ = self.gru_time(t_t)\n",
        "        output4 = output4.unsqueeze(0)\n",
        "        output4 = output4.permute(1,0,2,3)\n",
        "        output4 = self.gru_conv(output4)\n",
        "        output4 = output4.view(N,-1,2)\n",
        "        output4 = output4[:, :, 0:1]\n",
        "        output4 = output4.squeeze(-1)\n",
        "        output4 = output4.unsqueeze(2)\n",
        "        # weights calculation\n",
        "        weighted_tensor1 = output1 * self.weights[0]\n",
        "        weighted_tensor2 = output2 * self.weights[1]\n",
        "        weighted_tensor3 = output3 * self.weights[2]\n",
        "        weighted_tensor4 = output4 * self.weights[3]\n",
        "        # weighted fusion\n",
        "        weighted_fusion_tensor = weighted_tensor1 + weighted_tensor2 + weighted_tensor3 + weighted_tensor4\n",
        "        # Compute the gating factor\n",
        "        gate_factor = 0.8\n",
        "        #print(gate_factor)\n",
        "        fused_features = gate_factor * output1 + (1 - gate_factor) * (weighted_tensor2 + weighted_tensor3 + weighted_tensor4) + weighted_fusion_tensor\n",
        "        # resulted tensor\n",
        "        result = fused_features + last\n",
        "        result = self.conv1d_layer(result)\n",
        "        return result, Y\n",
        "\n",
        "\n",
        "class DGCN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 C_in,\n",
        "                 C_out,\n",
        "                 kernel_size):\n",
        "        super(DGCN, self).__init__()\n",
        "\n",
        "        self.K = kernel_size[1] - 1\n",
        "        self.C_out = C_out\n",
        "        self.conv = nn.Sequential(nn.BatchNorm3d(C_in),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Conv3d(C_in,\n",
        "                                            C_out,\n",
        "                                            kernel_size=(kernel_size[0], 1, kernel_size[1]),\n",
        "                                            padding=(1, 0, 0),\n",
        "                                            stride=(1, 1, 1),\n",
        "                                            bias=True),\n",
        "                                  nn.BatchNorm3d(C_out),\n",
        "                                  nn.Dropout3d(p=0.2, inplace=True))\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, x_A):\n",
        "\n",
        "        N, C, T, V = x.size()\n",
        "\n",
        "        x_reshape = x.permute(0, 2, 1, 3).contiguous().view(N * T, C, V)\n",
        "        A_reshape = x_A.view(N * T, V, V * (self.K + 1)).contiguous()\n",
        "        x = torch.bmm(x_reshape, A_reshape).view(N, T, C, V, (self.K + 1)).permute(0, 2, 1, 3, 4).contiguous()\n",
        "        x = self.conv(x).view(N, self.C_out, T, V)\n",
        "\n",
        "        return self.relu(x)\n"
      ],
      "metadata": {
        "id": "bdj3ZmKhJ2fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main Block"
      ],
      "metadata": {
        "id": "BZApoDIJKS9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, epoch, label, label_idx, label_weight, theta):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # Define the weight decay (L2 regularization) hyperparameter\n",
        "    weight_decay = 0.001\n",
        "    # Calculate the regularization term\n",
        "    regularization_loss = 0\n",
        "\n",
        "    for batch_idx, (data, x_t, target, w_t, t_t) in enumerate(train_loader):\n",
        "        data, x_t, target, w_t, t_t = Variable(data).cuda(), Variable(x_t).cuda(), Variable(target).cuda(), Variable(w_t).cuda(), Variable(t_t).cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output, y = model(data, x_t, label_idx, w_t, t_t)\n",
        "        loss1 = criterion(output, target)\n",
        "        loss2 = nn.functional.cross_entropy(y, label, weight=label_weight)\n",
        "        for param in model.parameters():\n",
        "               regularization_loss += torch.norm(param, 2)\n",
        "        loss = loss1 + loss2 * theta + weight_decay * regularization_loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            #print (\"Hello \",epoch, batch_idx, len(data), len(train_loader.dataset),100*batch_idx/len(train_loader),loss1.data.item())\n",
        "            print (\"Epoch: %d [%d/%d (%.0f%%)]\\tLoss: %.6f\\tLabel Loss: %.6f\" % (epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), sqrt(loss1.data.item()), loss2.data.item()))\n",
        "        train_loss += loss1.data.item() * len(data)\n",
        "    return sqrt(train_loss/ len(train_loader.dataset))\n",
        "\n",
        "\n",
        "def val(model, val_loader, criterion, epoch, label_idx):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    absolute_errors = 0  # Variable to store the sum of absolute errors\n",
        "    squared_errors = 0\n",
        "    num_samples = 0\n",
        "    for batch_idx, (data, x_t, target, w_t, t_t) in enumerate(val_loader):\n",
        "        data, x_t, target, w_t, t_t = Variable(data).cuda(), Variable(x_t).cuda(), Variable(target).cuda(), Variable(w_t).cuda(), Variable(t_t).cuda()\n",
        "        output, _ = model(data, x_t, label_idx, w_t, t_t)\n",
        "        loss = criterion(output, target)\n",
        "        val_loss += loss.data.item() * len(data)\n",
        "         # Calculate absolute and squared errors\n",
        "        absolute_errors += torch.sum(torch.abs(output - target)).item()/164\n",
        "        squared_errors += torch.sum((output - target) ** 2).item()/164\n",
        "\n",
        "        num_samples += len(data)\n",
        "\n",
        "    print (\"\\nEpoch: %d \\tVal Loss: %.6f\" % (epoch, sqrt(val_loss / len(val_loader.dataset))))\n",
        "    val_mae = absolute_errors / len(val_loader.dataset)\n",
        "    val_rmse = sqrt(squared_errors / len(val_loader.dataset))\n",
        "    val_loss = sqrt(val_loss / len(val_loader.dataset))\n",
        "\n",
        "    return val_loss, val_mae, val_rmse\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion, epoch, label_idx):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    absolute_errors = 0  # Variable to store the sum of absolute errors\n",
        "    squared_errors = 0\n",
        "    num_samples = 0\n",
        "    for batch_idx, (data, x_t, target, w_t, t_t) in enumerate(test_loader):\n",
        "        data, x_t, target, w_t, t_t = Variable(data).cuda(), Variable(x_t).cuda(), Variable(target).cuda(), Variable(w_t).cuda(), Variable(t_t).cuda()\n",
        "        output, _ = model(data, x_t, label_idx, w_t, t_t)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.data.item()* len(data)\n",
        "         # Calculate absolute and squared errors\n",
        "        absolute_errors += torch.sum(torch.abs(output - target)).item()/164\n",
        "        squared_errors += torch.sum((output - target) ** 2).item()/164\n",
        "\n",
        "        num_samples += len(data)\n",
        "\n",
        "    print (\"Epoch: %d \\tTest Loss: %.6f\\n\" % (epoch, sqrt(test_loss / len(test_loader.dataset))))\n",
        "    test_mae = absolute_errors / len(test_loader.dataset)\n",
        "    test_rmse = sqrt(squared_errors / len(test_loader.dataset))\n",
        "    test_loss = sqrt(test_loss / len(test_loader.dataset))\n",
        "\n",
        "\n",
        "    return test_loss, test_mae, test_rmse"
      ],
      "metadata": {
        "id": "mG6bRyQwKc76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main Function"
      ],
      "metadata": {
        "id": "ohnAFFrPNvY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  batch = 32\n",
        "  test_batch = 32\n",
        "  epoch = 500\n",
        "  lr = 0.001\n",
        "  seed = 1\n",
        "  division = 'irregular'\n",
        "  K = 9\n",
        "  C = 2\n",
        "  T = 5\n",
        "  theta = 10\n",
        "  load = 0\n",
        "\n",
        "args=Args()"
      ],
      "metadata": {
        "id": "kDe4WWGssb6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(PopulationDataset(division=args.division,\n",
        "                                                                 T=args.T,\n",
        "                                                                 type='train'),\n",
        "                                               batch_size=args.test_batch,\n",
        "                                               shuffle=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(PopulationDataset(division=args.division,\n",
        "                                                               T=args.T,\n",
        "                                                               type='val'),\n",
        "                                             batch_size=args.test_batch,\n",
        "                                             shuffle=False)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(PopulationDataset(division=args.division,\n",
        "                                                                T=args.T,\n",
        "                                                                type='test'),\n",
        "                                              batch_size=args.test_batch,\n",
        "                                              shuffle=False)\n",
        "\n",
        "    model = Model(division=args.division,\n",
        "                  C=args.C,\n",
        "                  K=args.K,\n",
        "                  T=args.T)\n",
        "\n",
        "    torch.cuda.set_device(0)\n",
        "    torch.manual_seed(args.seed)\n",
        "    model = model.cuda()\n",
        "\n",
        "    model.A = Variable(model.A).cuda()\n",
        "    model.F = Variable(model.F).cuda()\n",
        "    model.A_mean = Variable(model.A_mean).cuda()\n",
        "    model.I = Variable(model.I).cuda()\n",
        "\n",
        "    label = np.load('poi/' + args.division + '_label.npy').astype(np.int64)\n",
        "    label_idx = np.load('poi/' + args.division + '_idx.npy').astype(np.int64)\n",
        "    label_weight = np.load('poi/' + args.division + '_weight.npy').astype(np.float32)\n",
        "\n",
        "    label = torch.from_numpy(label[label_idx])\n",
        "    label_idx = torch.from_numpy(label_idx)\n",
        "    label_weight = torch.from_numpy(label_weight)\n",
        "    label = Variable(label).cuda()\n",
        "    label_idx = Variable(label_idx).cuda()\n",
        "    label_weight = Variable(label_weight).cuda()\n",
        "\n",
        "    if args.load > 0:\n",
        "        model.load_state_dict(torch.load('checkpoint/epoch_' + str(args.load) + '.tar'))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    criterion = nn.SmoothL1Loss(size_average=True)\n",
        "    loss = np.zeros((3, args.epoch), dtype=np.float32)\n",
        "    mae = np.zeros((2, args.epoch), dtype=np.float32)\n",
        "    rmse = np.zeros((2, args.epoch), dtype=np.float32)\n",
        "\n",
        "    val_loss_min = 100\n",
        "    test_loss_min = 100\n",
        "\n",
        "    for epoch in range(1 + args.load, args.epoch + 1 + args.load):\n",
        "        start = time()\n",
        "        train_loss = train(model, train_loader, optimizer, criterion, epoch, label, label_idx, label_weight, args.theta)\n",
        "        stop = time()\n",
        "        print (\"Time used: %.0f\" % (stop - start))\n",
        "        loss[0, epoch - args.load - 1] = train_loss\n",
        "\n",
        "        with torch.no_grad():\n",
        "          val_loss, val_mae, val_rmse = val(model, val_loader, criterion, epoch, label_idx)\n",
        "          test_loss, test_mae, test_rmse = test(model, test_loader, criterion, epoch, label_idx)\n",
        "          loss[1, epoch - args.load - 1] = val_loss\n",
        "          loss[2, epoch - args.load - 1] = test_loss\n",
        "          mae[0, epoch - args.load - 1] = val_mae\n",
        "          mae[1, epoch - args.load - 1] = test_mae\n",
        "          rmse[0, epoch - args.load - 1] = val_rmse\n",
        "          rmse[1, epoch - args.load - 1] = test_rmse\n",
        "          if val_loss < val_loss_min:\n",
        "            val_loss_min = val_loss\n",
        "            test_loss_min = test_loss\n",
        "        if epoch % 100 == 0:\n",
        "            torch.save(model.state_dict(), 'checkpoint/epoch_' + str(epoch) + '.tar')\n",
        "\n",
        "    np.save('checkpoint/loss.npy', loss)\n",
        "    np.save('checkpoint/mae.npy', mae)\n",
        "    np.save('checkpoint/rmse.npy', rmse)\n",
        "    #np.save('checkpoint/valmae.npy', val_mae')\n",
        "    # print(\"Val RMSE: %.4f \\tTest RMSE: %.4f\\n\" % (\n",
        "    #     val_loss_min, test_loss_min))\n",
        "    weights = model.weights\n",
        "    print(weights)\n",
        "    print(\"Val RMSE: %.4f \\tTest RMSE: %.4f\\n\" % (val_loss_min, test_loss_min))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYVDl64RK1FX",
        "outputId": "c6b936f2-df87-4c5c-bb00-f590f1e7da04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5fbfbe8d66f4>:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  Z = self.Softmax(Y2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 [0/1762 (0%)]\tLoss: 5.324369\tLabel Loss: 2.233970\n",
            "Epoch: 1 [640/1762 (36%)]\tLoss: 4.094552\tLabel Loss: 2.199896\n",
            "Epoch: 1 [1280/1762 (71%)]\tLoss: 4.440077\tLabel Loss: 2.186282\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 1 \tVal Loss: 4.595229\n",
            "Epoch: 1 \tTest Loss: 4.432323\n",
            "\n",
            "Epoch: 2 [0/1762 (0%)]\tLoss: 3.929124\tLabel Loss: 2.181448\n",
            "Epoch: 2 [640/1762 (36%)]\tLoss: 4.241244\tLabel Loss: 2.176781\n",
            "Epoch: 2 [1280/1762 (71%)]\tLoss: 3.830724\tLabel Loss: 2.171706\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 2 \tVal Loss: 3.970286\n",
            "Epoch: 2 \tTest Loss: 3.803791\n",
            "\n",
            "Epoch: 3 [0/1762 (0%)]\tLoss: 3.646853\tLabel Loss: 2.167148\n",
            "Epoch: 3 [640/1762 (36%)]\tLoss: 3.601558\tLabel Loss: 2.116262\n",
            "Epoch: 3 [1280/1762 (71%)]\tLoss: 3.567322\tLabel Loss: 2.070585\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 3 \tVal Loss: 3.656804\n",
            "Epoch: 3 \tTest Loss: 3.486801\n",
            "\n",
            "Epoch: 4 [0/1762 (0%)]\tLoss: 3.231067\tLabel Loss: 2.021091\n",
            "Epoch: 4 [640/1762 (36%)]\tLoss: 3.136838\tLabel Loss: 1.937677\n",
            "Epoch: 4 [1280/1762 (71%)]\tLoss: 3.306188\tLabel Loss: 1.873743\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 4 \tVal Loss: 3.468325\n",
            "Epoch: 4 \tTest Loss: 3.290935\n",
            "\n",
            "Epoch: 5 [0/1762 (0%)]\tLoss: 3.531425\tLabel Loss: 1.822456\n",
            "Epoch: 5 [640/1762 (36%)]\tLoss: 3.466642\tLabel Loss: 1.767442\n",
            "Epoch: 5 [1280/1762 (71%)]\tLoss: 3.034989\tLabel Loss: 1.723287\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 5 \tVal Loss: 3.246355\n",
            "Epoch: 5 \tTest Loss: 3.067167\n",
            "\n",
            "Epoch: 6 [0/1762 (0%)]\tLoss: 2.834481\tLabel Loss: 1.691712\n",
            "Epoch: 6 [640/1762 (36%)]\tLoss: 2.615775\tLabel Loss: 1.656562\n",
            "Epoch: 6 [1280/1762 (71%)]\tLoss: 2.771990\tLabel Loss: 1.625477\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 6 \tVal Loss: 3.065768\n",
            "Epoch: 6 \tTest Loss: 2.887487\n",
            "\n",
            "Epoch: 7 [0/1762 (0%)]\tLoss: 2.757802\tLabel Loss: 1.603771\n",
            "Epoch: 7 [640/1762 (36%)]\tLoss: 2.703366\tLabel Loss: 1.543939\n",
            "Epoch: 7 [1280/1762 (71%)]\tLoss: 2.640905\tLabel Loss: 1.497622\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 7 \tVal Loss: 2.935261\n",
            "Epoch: 7 \tTest Loss: 2.730313\n",
            "\n",
            "Epoch: 8 [0/1762 (0%)]\tLoss: 2.609374\tLabel Loss: 1.469518\n",
            "Epoch: 8 [640/1762 (36%)]\tLoss: 2.670765\tLabel Loss: 1.438992\n",
            "Epoch: 8 [1280/1762 (71%)]\tLoss: 2.423190\tLabel Loss: 1.347528\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 8 \tVal Loss: 2.811146\n",
            "Epoch: 8 \tTest Loss: 2.623102\n",
            "\n",
            "Epoch: 9 [0/1762 (0%)]\tLoss: 2.737974\tLabel Loss: 1.285435\n",
            "Epoch: 9 [640/1762 (36%)]\tLoss: 2.606025\tLabel Loss: 1.241399\n",
            "Epoch: 9 [1280/1762 (71%)]\tLoss: 2.672248\tLabel Loss: 1.144097\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 9 \tVal Loss: 2.788383\n",
            "Epoch: 9 \tTest Loss: 2.598313\n",
            "\n",
            "Epoch: 10 [0/1762 (0%)]\tLoss: 2.772104\tLabel Loss: 1.099856\n",
            "Epoch: 10 [640/1762 (36%)]\tLoss: 2.793075\tLabel Loss: 1.056285\n",
            "Epoch: 10 [1280/1762 (71%)]\tLoss: 2.375603\tLabel Loss: 1.011594\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 10 \tVal Loss: 2.772883\n",
            "Epoch: 10 \tTest Loss: 2.570664\n",
            "\n",
            "Epoch: 11 [0/1762 (0%)]\tLoss: 2.518298\tLabel Loss: 0.982691\n",
            "Epoch: 11 [640/1762 (36%)]\tLoss: 2.707281\tLabel Loss: 0.948028\n",
            "Epoch: 11 [1280/1762 (71%)]\tLoss: 2.565470\tLabel Loss: 0.916626\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 11 \tVal Loss: 2.825094\n",
            "Epoch: 11 \tTest Loss: 2.620357\n",
            "\n",
            "Epoch: 12 [0/1762 (0%)]\tLoss: 2.173796\tLabel Loss: 0.891933\n",
            "Epoch: 12 [640/1762 (36%)]\tLoss: 2.622488\tLabel Loss: 0.864316\n",
            "Epoch: 12 [1280/1762 (71%)]\tLoss: 2.711491\tLabel Loss: 0.838388\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 12 \tVal Loss: 2.750293\n",
            "Epoch: 12 \tTest Loss: 2.554193\n",
            "\n",
            "Epoch: 13 [0/1762 (0%)]\tLoss: 2.623465\tLabel Loss: 0.819230\n",
            "Epoch: 13 [640/1762 (36%)]\tLoss: 2.305183\tLabel Loss: 0.795861\n",
            "Epoch: 13 [1280/1762 (71%)]\tLoss: 2.553142\tLabel Loss: 0.774007\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 13 \tVal Loss: 2.710972\n",
            "Epoch: 13 \tTest Loss: 2.511791\n",
            "\n",
            "Epoch: 14 [0/1762 (0%)]\tLoss: 2.746341\tLabel Loss: 0.758083\n",
            "Epoch: 14 [640/1762 (36%)]\tLoss: 2.364089\tLabel Loss: 0.738622\n",
            "Epoch: 14 [1280/1762 (71%)]\tLoss: 2.523067\tLabel Loss: 0.719235\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 14 \tVal Loss: 2.688029\n",
            "Epoch: 14 \tTest Loss: 2.497403\n",
            "\n",
            "Epoch: 15 [0/1762 (0%)]\tLoss: 2.420192\tLabel Loss: 0.704424\n",
            "Epoch: 15 [640/1762 (36%)]\tLoss: 2.753852\tLabel Loss: 0.687635\n",
            "Epoch: 15 [1280/1762 (71%)]\tLoss: 2.327090\tLabel Loss: 0.672022\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 15 \tVal Loss: 2.700638\n",
            "Epoch: 15 \tTest Loss: 2.494039\n",
            "\n",
            "Epoch: 16 [0/1762 (0%)]\tLoss: 2.543773\tLabel Loss: 0.660095\n",
            "Epoch: 16 [640/1762 (36%)]\tLoss: 2.414215\tLabel Loss: 0.522733\n",
            "Epoch: 16 [1280/1762 (71%)]\tLoss: 2.631311\tLabel Loss: 0.480020\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 16 \tVal Loss: 2.661049\n",
            "Epoch: 16 \tTest Loss: 2.465622\n",
            "\n",
            "Epoch: 17 [0/1762 (0%)]\tLoss: 2.421259\tLabel Loss: 0.458435\n",
            "Epoch: 17 [640/1762 (36%)]\tLoss: 2.570245\tLabel Loss: 0.437159\n",
            "Epoch: 17 [1280/1762 (71%)]\tLoss: 2.819171\tLabel Loss: 0.418046\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 17 \tVal Loss: 2.649972\n",
            "Epoch: 17 \tTest Loss: 2.454348\n",
            "\n",
            "Epoch: 18 [0/1762 (0%)]\tLoss: 2.355544\tLabel Loss: 0.404169\n",
            "Epoch: 18 [640/1762 (36%)]\tLoss: 2.452956\tLabel Loss: 0.388264\n",
            "Epoch: 18 [1280/1762 (71%)]\tLoss: 2.253506\tLabel Loss: 0.373543\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 18 \tVal Loss: 2.640361\n",
            "Epoch: 18 \tTest Loss: 2.453552\n",
            "\n",
            "Epoch: 19 [0/1762 (0%)]\tLoss: 2.441995\tLabel Loss: 0.362781\n",
            "Epoch: 19 [640/1762 (36%)]\tLoss: 2.262157\tLabel Loss: 0.349267\n",
            "Epoch: 19 [1280/1762 (71%)]\tLoss: 2.317817\tLabel Loss: 0.336832\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 19 \tVal Loss: 2.643319\n",
            "Epoch: 19 \tTest Loss: 2.453270\n",
            "\n",
            "Epoch: 20 [0/1762 (0%)]\tLoss: 2.250685\tLabel Loss: 0.327693\n",
            "Epoch: 20 [640/1762 (36%)]\tLoss: 2.322399\tLabel Loss: 0.316345\n",
            "Epoch: 20 [1280/1762 (71%)]\tLoss: 2.813500\tLabel Loss: 0.305881\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 20 \tVal Loss: 2.624281\n",
            "Epoch: 20 \tTest Loss: 2.438816\n",
            "\n",
            "Epoch: 21 [0/1762 (0%)]\tLoss: 2.447022\tLabel Loss: 0.297880\n",
            "Epoch: 21 [640/1762 (36%)]\tLoss: 2.351436\tLabel Loss: 0.288774\n",
            "Epoch: 21 [1280/1762 (71%)]\tLoss: 2.333631\tLabel Loss: 0.279050\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 21 \tVal Loss: 2.601236\n",
            "Epoch: 21 \tTest Loss: 2.400543\n",
            "\n",
            "Epoch: 22 [0/1762 (0%)]\tLoss: 2.253640\tLabel Loss: 0.272252\n",
            "Epoch: 22 [640/1762 (36%)]\tLoss: 2.542623\tLabel Loss: 0.263568\n",
            "Epoch: 22 [1280/1762 (71%)]\tLoss: 2.367533\tLabel Loss: 0.255751\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 22 \tVal Loss: 2.590316\n",
            "Epoch: 22 \tTest Loss: 2.395564\n",
            "\n",
            "Epoch: 23 [0/1762 (0%)]\tLoss: 2.514196\tLabel Loss: 0.249681\n",
            "Epoch: 23 [640/1762 (36%)]\tLoss: 2.367155\tLabel Loss: 0.243172\n",
            "Epoch: 23 [1280/1762 (71%)]\tLoss: 2.652494\tLabel Loss: 0.235450\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 23 \tVal Loss: 2.599305\n",
            "Epoch: 23 \tTest Loss: 2.404898\n",
            "\n",
            "Epoch: 24 [0/1762 (0%)]\tLoss: 2.435542\tLabel Loss: 0.230177\n",
            "Epoch: 24 [640/1762 (36%)]\tLoss: 2.315267\tLabel Loss: 0.223619\n",
            "Epoch: 24 [1280/1762 (71%)]\tLoss: 2.409169\tLabel Loss: 0.217842\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 24 \tVal Loss: 2.577963\n",
            "Epoch: 24 \tTest Loss: 2.390585\n",
            "\n",
            "Epoch: 25 [0/1762 (0%)]\tLoss: 2.418096\tLabel Loss: 0.212994\n",
            "Epoch: 25 [640/1762 (36%)]\tLoss: 2.343482\tLabel Loss: 0.207329\n",
            "Epoch: 25 [1280/1762 (71%)]\tLoss: 2.049851\tLabel Loss: 0.201794\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 25 \tVal Loss: 2.561177\n",
            "Epoch: 25 \tTest Loss: 2.381624\n",
            "\n",
            "Epoch: 26 [0/1762 (0%)]\tLoss: 2.678688\tLabel Loss: 0.197343\n",
            "Epoch: 26 [640/1762 (36%)]\tLoss: 2.307829\tLabel Loss: 0.192278\n",
            "Epoch: 26 [1280/1762 (71%)]\tLoss: 2.620641\tLabel Loss: 0.188832\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 26 \tVal Loss: 2.547642\n",
            "Epoch: 26 \tTest Loss: 2.374575\n",
            "\n",
            "Epoch: 27 [0/1762 (0%)]\tLoss: 2.382557\tLabel Loss: 0.185105\n",
            "Epoch: 27 [640/1762 (36%)]\tLoss: 2.800137\tLabel Loss: 0.179171\n",
            "Epoch: 27 [1280/1762 (71%)]\tLoss: 2.407229\tLabel Loss: 0.174913\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 27 \tVal Loss: 2.524667\n",
            "Epoch: 27 \tTest Loss: 2.349710\n",
            "\n",
            "Epoch: 28 [0/1762 (0%)]\tLoss: 2.524336\tLabel Loss: 0.171669\n",
            "Epoch: 28 [640/1762 (36%)]\tLoss: 2.190658\tLabel Loss: 0.167119\n",
            "Epoch: 28 [1280/1762 (71%)]\tLoss: 2.262389\tLabel Loss: 0.163210\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 28 \tVal Loss: 2.510511\n",
            "Epoch: 28 \tTest Loss: 2.325603\n",
            "\n",
            "Epoch: 29 [0/1762 (0%)]\tLoss: 2.534509\tLabel Loss: 0.159989\n",
            "Epoch: 29 [640/1762 (36%)]\tLoss: 2.106405\tLabel Loss: 0.156619\n",
            "Epoch: 29 [1280/1762 (71%)]\tLoss: 2.536192\tLabel Loss: 0.152700\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 29 \tVal Loss: 2.501213\n",
            "Epoch: 29 \tTest Loss: 2.314631\n",
            "\n",
            "Epoch: 30 [0/1762 (0%)]\tLoss: 2.188193\tLabel Loss: 0.150139\n",
            "Epoch: 30 [640/1762 (36%)]\tLoss: 2.474256\tLabel Loss: 0.146534\n",
            "Epoch: 30 [1280/1762 (71%)]\tLoss: 2.097990\tLabel Loss: 0.143385\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 30 \tVal Loss: 2.519464\n",
            "Epoch: 30 \tTest Loss: 2.343221\n",
            "\n",
            "Epoch: 31 [0/1762 (0%)]\tLoss: 2.529797\tLabel Loss: 0.141397\n",
            "Epoch: 31 [640/1762 (36%)]\tLoss: 2.210172\tLabel Loss: 0.138171\n",
            "Epoch: 31 [1280/1762 (71%)]\tLoss: 2.248910\tLabel Loss: 0.135144\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 31 \tVal Loss: 2.471857\n",
            "Epoch: 31 \tTest Loss: 2.304391\n",
            "\n",
            "Epoch: 32 [0/1762 (0%)]\tLoss: 2.373358\tLabel Loss: 0.132386\n",
            "Epoch: 32 [640/1762 (36%)]\tLoss: 2.552727\tLabel Loss: 0.129910\n",
            "Epoch: 32 [1280/1762 (71%)]\tLoss: 2.569978\tLabel Loss: 0.126688\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 32 \tVal Loss: 2.451190\n",
            "Epoch: 32 \tTest Loss: 2.277273\n",
            "\n",
            "Epoch: 33 [0/1762 (0%)]\tLoss: 2.336278\tLabel Loss: 0.124984\n",
            "Epoch: 33 [640/1762 (36%)]\tLoss: 2.412619\tLabel Loss: 0.122107\n",
            "Epoch: 33 [1280/1762 (71%)]\tLoss: 2.354329\tLabel Loss: 0.120081\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 33 \tVal Loss: 2.436435\n",
            "Epoch: 33 \tTest Loss: 2.272232\n",
            "\n",
            "Epoch: 34 [0/1762 (0%)]\tLoss: 2.466591\tLabel Loss: 0.117691\n",
            "Epoch: 34 [640/1762 (36%)]\tLoss: 2.274695\tLabel Loss: 0.115219\n",
            "Epoch: 34 [1280/1762 (71%)]\tLoss: 2.137447\tLabel Loss: 0.113200\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 34 \tVal Loss: 2.431681\n",
            "Epoch: 34 \tTest Loss: 2.268861\n",
            "\n",
            "Epoch: 35 [0/1762 (0%)]\tLoss: 2.373658\tLabel Loss: 0.111114\n",
            "Epoch: 35 [640/1762 (36%)]\tLoss: 2.150104\tLabel Loss: 0.109042\n",
            "Epoch: 35 [1280/1762 (71%)]\tLoss: 2.375128\tLabel Loss: 0.106761\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 35 \tVal Loss: 2.406891\n",
            "Epoch: 35 \tTest Loss: 2.252010\n",
            "\n",
            "Epoch: 36 [0/1762 (0%)]\tLoss: 2.294977\tLabel Loss: 0.105529\n",
            "Epoch: 36 [640/1762 (36%)]\tLoss: 2.611592\tLabel Loss: 0.103627\n",
            "Epoch: 36 [1280/1762 (71%)]\tLoss: 2.407421\tLabel Loss: 0.101487\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 36 \tVal Loss: 2.392706\n",
            "Epoch: 36 \tTest Loss: 2.245815\n",
            "\n",
            "Epoch: 37 [0/1762 (0%)]\tLoss: 2.378713\tLabel Loss: 0.100460\n",
            "Epoch: 37 [640/1762 (36%)]\tLoss: 2.158317\tLabel Loss: 0.097939\n",
            "Epoch: 37 [1280/1762 (71%)]\tLoss: 2.502882\tLabel Loss: 0.095846\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 37 \tVal Loss: 2.388945\n",
            "Epoch: 37 \tTest Loss: 2.219863\n",
            "\n",
            "Epoch: 38 [0/1762 (0%)]\tLoss: 2.356887\tLabel Loss: 0.095373\n",
            "Epoch: 38 [640/1762 (36%)]\tLoss: 2.344199\tLabel Loss: 0.093090\n",
            "Epoch: 38 [1280/1762 (71%)]\tLoss: 2.248751\tLabel Loss: 0.091891\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 38 \tVal Loss: 2.394361\n",
            "Epoch: 38 \tTest Loss: 2.247474\n",
            "\n",
            "Epoch: 39 [0/1762 (0%)]\tLoss: 2.455266\tLabel Loss: 0.090350\n",
            "Epoch: 39 [640/1762 (36%)]\tLoss: 2.313410\tLabel Loss: 0.088060\n",
            "Epoch: 39 [1280/1762 (71%)]\tLoss: 2.266715\tLabel Loss: 0.086623\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 39 \tVal Loss: 2.368172\n",
            "Epoch: 39 \tTest Loss: 2.212705\n",
            "\n",
            "Epoch: 40 [0/1762 (0%)]\tLoss: 2.275906\tLabel Loss: 0.085599\n",
            "Epoch: 40 [640/1762 (36%)]\tLoss: 2.305229\tLabel Loss: 0.084381\n",
            "Epoch: 40 [1280/1762 (71%)]\tLoss: 2.265345\tLabel Loss: 0.082438\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 40 \tVal Loss: 2.373205\n",
            "Epoch: 40 \tTest Loss: 2.234908\n",
            "\n",
            "Epoch: 41 [0/1762 (0%)]\tLoss: 2.280991\tLabel Loss: 0.082473\n",
            "Epoch: 41 [640/1762 (36%)]\tLoss: 2.248902\tLabel Loss: 0.080526\n",
            "Epoch: 41 [1280/1762 (71%)]\tLoss: 2.150050\tLabel Loss: 0.078557\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 41 \tVal Loss: 2.345792\n",
            "Epoch: 41 \tTest Loss: 2.196983\n",
            "\n",
            "Epoch: 42 [0/1762 (0%)]\tLoss: 2.427916\tLabel Loss: 0.078026\n",
            "Epoch: 42 [640/1762 (36%)]\tLoss: 2.817402\tLabel Loss: 0.076242\n",
            "Epoch: 42 [1280/1762 (71%)]\tLoss: 2.301985\tLabel Loss: 0.074980\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 42 \tVal Loss: 2.353656\n",
            "Epoch: 42 \tTest Loss: 2.195545\n",
            "\n",
            "Epoch: 43 [0/1762 (0%)]\tLoss: 2.252094\tLabel Loss: 0.073963\n",
            "Epoch: 43 [640/1762 (36%)]\tLoss: 2.052224\tLabel Loss: 0.072742\n",
            "Epoch: 43 [1280/1762 (71%)]\tLoss: 2.253444\tLabel Loss: 0.072208\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 43 \tVal Loss: 2.329571\n",
            "Epoch: 43 \tTest Loss: 2.181602\n",
            "\n",
            "Epoch: 44 [0/1762 (0%)]\tLoss: 2.479708\tLabel Loss: 0.071764\n",
            "Epoch: 44 [640/1762 (36%)]\tLoss: 2.059352\tLabel Loss: 0.069689\n",
            "Epoch: 44 [1280/1762 (71%)]\tLoss: 2.455814\tLabel Loss: 0.068581\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 44 \tVal Loss: 2.341589\n",
            "Epoch: 44 \tTest Loss: 2.184607\n",
            "\n",
            "Epoch: 45 [0/1762 (0%)]\tLoss: 2.382443\tLabel Loss: 0.067486\n",
            "Epoch: 45 [640/1762 (36%)]\tLoss: 2.203265\tLabel Loss: 0.066564\n",
            "Epoch: 45 [1280/1762 (71%)]\tLoss: 2.088092\tLabel Loss: 0.065726\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 45 \tVal Loss: 2.338032\n",
            "Epoch: 45 \tTest Loss: 2.183782\n",
            "\n",
            "Epoch: 46 [0/1762 (0%)]\tLoss: 2.414557\tLabel Loss: 0.064497\n",
            "Epoch: 46 [640/1762 (36%)]\tLoss: 2.123090\tLabel Loss: 0.063686\n",
            "Epoch: 46 [1280/1762 (71%)]\tLoss: 2.184640\tLabel Loss: 0.062692\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 46 \tVal Loss: 2.354172\n",
            "Epoch: 46 \tTest Loss: 2.192830\n",
            "\n",
            "Epoch: 47 [0/1762 (0%)]\tLoss: 2.251081\tLabel Loss: 0.061767\n",
            "Epoch: 47 [640/1762 (36%)]\tLoss: 2.277680\tLabel Loss: 0.061593\n",
            "Epoch: 47 [1280/1762 (71%)]\tLoss: 1.993823\tLabel Loss: 0.061307\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 47 \tVal Loss: 2.319187\n",
            "Epoch: 47 \tTest Loss: 2.165749\n",
            "\n",
            "Epoch: 48 [0/1762 (0%)]\tLoss: 2.456499\tLabel Loss: 0.059443\n",
            "Epoch: 48 [640/1762 (36%)]\tLoss: 2.432900\tLabel Loss: 0.058363\n",
            "Epoch: 48 [1280/1762 (71%)]\tLoss: 2.441698\tLabel Loss: 0.057790\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 48 \tVal Loss: 2.347165\n",
            "Epoch: 48 \tTest Loss: 2.188290\n",
            "\n",
            "Epoch: 49 [0/1762 (0%)]\tLoss: 2.178759\tLabel Loss: 0.056952\n",
            "Epoch: 49 [640/1762 (36%)]\tLoss: 2.143781\tLabel Loss: 0.056373\n",
            "Epoch: 49 [1280/1762 (71%)]\tLoss: 2.177173\tLabel Loss: 0.055733\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 49 \tVal Loss: 2.316819\n",
            "Epoch: 49 \tTest Loss: 2.170000\n",
            "\n",
            "Epoch: 50 [0/1762 (0%)]\tLoss: 2.197886\tLabel Loss: 0.054460\n",
            "Epoch: 50 [640/1762 (36%)]\tLoss: 2.171329\tLabel Loss: 0.053688\n",
            "Epoch: 50 [1280/1762 (71%)]\tLoss: 1.999187\tLabel Loss: 0.052927\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 50 \tVal Loss: 2.367394\n",
            "Epoch: 50 \tTest Loss: 2.208656\n",
            "\n",
            "Epoch: 51 [0/1762 (0%)]\tLoss: 2.419679\tLabel Loss: 0.052617\n",
            "Epoch: 51 [640/1762 (36%)]\tLoss: 2.214670\tLabel Loss: 0.051405\n",
            "Epoch: 51 [1280/1762 (71%)]\tLoss: 2.177160\tLabel Loss: 0.050775\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 51 \tVal Loss: 2.324221\n",
            "Epoch: 51 \tTest Loss: 2.186882\n",
            "\n",
            "Epoch: 52 [0/1762 (0%)]\tLoss: 2.142227\tLabel Loss: 0.050324\n",
            "Epoch: 52 [640/1762 (36%)]\tLoss: 2.309695\tLabel Loss: 0.050683\n",
            "Epoch: 52 [1280/1762 (71%)]\tLoss: 2.247331\tLabel Loss: 0.049359\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 52 \tVal Loss: 2.298927\n",
            "Epoch: 52 \tTest Loss: 2.162097\n",
            "\n",
            "Epoch: 53 [0/1762 (0%)]\tLoss: 2.339227\tLabel Loss: 0.048810\n",
            "Epoch: 53 [640/1762 (36%)]\tLoss: 2.190013\tLabel Loss: 0.047898\n",
            "Epoch: 53 [1280/1762 (71%)]\tLoss: 2.088823\tLabel Loss: 0.047284\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 53 \tVal Loss: 2.317813\n",
            "Epoch: 53 \tTest Loss: 2.165158\n",
            "\n",
            "Epoch: 54 [0/1762 (0%)]\tLoss: 2.263927\tLabel Loss: 0.046687\n",
            "Epoch: 54 [640/1762 (36%)]\tLoss: 2.170951\tLabel Loss: 0.045767\n",
            "Epoch: 54 [1280/1762 (71%)]\tLoss: 2.170768\tLabel Loss: 0.045294\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 54 \tVal Loss: 2.302419\n",
            "Epoch: 54 \tTest Loss: 2.159639\n",
            "\n",
            "Epoch: 55 [0/1762 (0%)]\tLoss: 2.078439\tLabel Loss: 0.045625\n",
            "Epoch: 55 [640/1762 (36%)]\tLoss: 2.294670\tLabel Loss: 0.044037\n",
            "Epoch: 55 [1280/1762 (71%)]\tLoss: 2.250747\tLabel Loss: 0.043620\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 55 \tVal Loss: 2.297503\n",
            "Epoch: 55 \tTest Loss: 2.146090\n",
            "\n",
            "Epoch: 56 [0/1762 (0%)]\tLoss: 1.997945\tLabel Loss: 0.042945\n",
            "Epoch: 56 [640/1762 (36%)]\tLoss: 2.238679\tLabel Loss: 0.042355\n",
            "Epoch: 56 [1280/1762 (71%)]\tLoss: 2.205936\tLabel Loss: 0.041909\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 56 \tVal Loss: 2.293158\n",
            "Epoch: 56 \tTest Loss: 2.156973\n",
            "\n",
            "Epoch: 57 [0/1762 (0%)]\tLoss: 2.458888\tLabel Loss: 0.042051\n",
            "Epoch: 57 [640/1762 (36%)]\tLoss: 2.317527\tLabel Loss: 0.040831\n",
            "Epoch: 57 [1280/1762 (71%)]\tLoss: 2.342202\tLabel Loss: 0.040456\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 57 \tVal Loss: 2.357441\n",
            "Epoch: 57 \tTest Loss: 2.187278\n",
            "\n",
            "Epoch: 58 [0/1762 (0%)]\tLoss: 2.200244\tLabel Loss: 0.040353\n",
            "Epoch: 58 [640/1762 (36%)]\tLoss: 2.334563\tLabel Loss: 0.040143\n",
            "Epoch: 58 [1280/1762 (71%)]\tLoss: 2.391000\tLabel Loss: 0.039854\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 58 \tVal Loss: 2.285040\n",
            "Epoch: 58 \tTest Loss: 2.148008\n",
            "\n",
            "Epoch: 59 [0/1762 (0%)]\tLoss: 2.346050\tLabel Loss: 0.038840\n",
            "Epoch: 59 [640/1762 (36%)]\tLoss: 2.458845\tLabel Loss: 0.038132\n",
            "Epoch: 59 [1280/1762 (71%)]\tLoss: 2.434028\tLabel Loss: 0.037675\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 59 \tVal Loss: 2.290613\n",
            "Epoch: 59 \tTest Loss: 2.145451\n",
            "\n",
            "Epoch: 60 [0/1762 (0%)]\tLoss: 1.902614\tLabel Loss: 0.037235\n",
            "Epoch: 60 [640/1762 (36%)]\tLoss: 2.240794\tLabel Loss: 0.036870\n",
            "Epoch: 60 [1280/1762 (71%)]\tLoss: 2.436977\tLabel Loss: 0.036298\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 60 \tVal Loss: 2.278278\n",
            "Epoch: 60 \tTest Loss: 2.136071\n",
            "\n",
            "Epoch: 61 [0/1762 (0%)]\tLoss: 2.199389\tLabel Loss: 0.035935\n",
            "Epoch: 61 [640/1762 (36%)]\tLoss: 2.100051\tLabel Loss: 0.035328\n",
            "Epoch: 61 [1280/1762 (71%)]\tLoss: 2.382624\tLabel Loss: 0.034980\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 61 \tVal Loss: 2.279026\n",
            "Epoch: 61 \tTest Loss: 2.142436\n",
            "\n",
            "Epoch: 62 [0/1762 (0%)]\tLoss: 1.884290\tLabel Loss: 0.034771\n",
            "Epoch: 62 [640/1762 (36%)]\tLoss: 2.233199\tLabel Loss: 0.034333\n",
            "Epoch: 62 [1280/1762 (71%)]\tLoss: 2.373626\tLabel Loss: 0.034512\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 62 \tVal Loss: 2.275504\n",
            "Epoch: 62 \tTest Loss: 2.140388\n",
            "\n",
            "Epoch: 63 [0/1762 (0%)]\tLoss: 2.105819\tLabel Loss: 0.033973\n",
            "Epoch: 63 [640/1762 (36%)]\tLoss: 2.428833\tLabel Loss: 0.033187\n",
            "Epoch: 63 [1280/1762 (71%)]\tLoss: 2.356506\tLabel Loss: 0.032508\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 63 \tVal Loss: 2.286074\n",
            "Epoch: 63 \tTest Loss: 2.145014\n",
            "\n",
            "Epoch: 64 [0/1762 (0%)]\tLoss: 2.122584\tLabel Loss: 0.032190\n",
            "Epoch: 64 [640/1762 (36%)]\tLoss: 2.361067\tLabel Loss: 0.032194\n",
            "Epoch: 64 [1280/1762 (71%)]\tLoss: 2.214500\tLabel Loss: 0.031546\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 64 \tVal Loss: 2.277311\n",
            "Epoch: 64 \tTest Loss: 2.141341\n",
            "\n",
            "Epoch: 65 [0/1762 (0%)]\tLoss: 1.876573\tLabel Loss: 0.031210\n",
            "Epoch: 65 [640/1762 (36%)]\tLoss: 2.267325\tLabel Loss: 0.030811\n",
            "Epoch: 65 [1280/1762 (71%)]\tLoss: 2.027233\tLabel Loss: 0.030792\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 65 \tVal Loss: 2.282188\n",
            "Epoch: 65 \tTest Loss: 2.139155\n",
            "\n",
            "Epoch: 66 [0/1762 (0%)]\tLoss: 2.142767\tLabel Loss: 0.030216\n",
            "Epoch: 66 [640/1762 (36%)]\tLoss: 2.141459\tLabel Loss: 0.030001\n",
            "Epoch: 66 [1280/1762 (71%)]\tLoss: 2.209671\tLabel Loss: 0.029482\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 66 \tVal Loss: 2.266299\n",
            "Epoch: 66 \tTest Loss: 2.134404\n",
            "\n",
            "Epoch: 67 [0/1762 (0%)]\tLoss: 2.256093\tLabel Loss: 0.029245\n",
            "Epoch: 67 [640/1762 (36%)]\tLoss: 2.193873\tLabel Loss: 0.029013\n",
            "Epoch: 67 [1280/1762 (71%)]\tLoss: 2.151124\tLabel Loss: 0.028720\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 67 \tVal Loss: 2.260143\n",
            "Epoch: 67 \tTest Loss: 2.118959\n",
            "\n",
            "Epoch: 68 [0/1762 (0%)]\tLoss: 2.345380\tLabel Loss: 0.028526\n",
            "Epoch: 68 [640/1762 (36%)]\tLoss: 2.206731\tLabel Loss: 0.027840\n",
            "Epoch: 68 [1280/1762 (71%)]\tLoss: 2.194233\tLabel Loss: 0.027697\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 68 \tVal Loss: 2.285798\n",
            "Epoch: 68 \tTest Loss: 2.144103\n",
            "\n",
            "Epoch: 69 [0/1762 (0%)]\tLoss: 2.407872\tLabel Loss: 0.027885\n",
            "Epoch: 69 [640/1762 (36%)]\tLoss: 2.468232\tLabel Loss: 0.027355\n",
            "Epoch: 69 [1280/1762 (71%)]\tLoss: 2.307693\tLabel Loss: 0.027633\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 69 \tVal Loss: 2.268962\n",
            "Epoch: 69 \tTest Loss: 2.122659\n",
            "\n",
            "Epoch: 70 [0/1762 (0%)]\tLoss: 2.069477\tLabel Loss: 0.026686\n",
            "Epoch: 70 [640/1762 (36%)]\tLoss: 2.138937\tLabel Loss: 0.026464\n",
            "Epoch: 70 [1280/1762 (71%)]\tLoss: 2.272468\tLabel Loss: 0.026029\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 70 \tVal Loss: 2.265262\n",
            "Epoch: 70 \tTest Loss: 2.130548\n",
            "\n",
            "Epoch: 71 [0/1762 (0%)]\tLoss: 2.330247\tLabel Loss: 0.025867\n",
            "Epoch: 71 [640/1762 (36%)]\tLoss: 2.166873\tLabel Loss: 0.025425\n",
            "Epoch: 71 [1280/1762 (71%)]\tLoss: 2.197036\tLabel Loss: 0.025513\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 71 \tVal Loss: 2.290052\n",
            "Epoch: 71 \tTest Loss: 2.159735\n",
            "\n",
            "Epoch: 72 [0/1762 (0%)]\tLoss: 2.290936\tLabel Loss: 0.025474\n",
            "Epoch: 72 [640/1762 (36%)]\tLoss: 2.185718\tLabel Loss: 0.025706\n",
            "Epoch: 72 [1280/1762 (71%)]\tLoss: 2.132003\tLabel Loss: 0.025127\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 72 \tVal Loss: 2.280150\n",
            "Epoch: 72 \tTest Loss: 2.133047\n",
            "\n",
            "Epoch: 73 [0/1762 (0%)]\tLoss: 2.346001\tLabel Loss: 0.024411\n",
            "Epoch: 73 [640/1762 (36%)]\tLoss: 2.243627\tLabel Loss: 0.023887\n",
            "Epoch: 73 [1280/1762 (71%)]\tLoss: 2.054887\tLabel Loss: 0.023807\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 73 \tVal Loss: 2.267652\n",
            "Epoch: 73 \tTest Loss: 2.133493\n",
            "\n",
            "Epoch: 74 [0/1762 (0%)]\tLoss: 2.165042\tLabel Loss: 0.023943\n",
            "Epoch: 74 [640/1762 (36%)]\tLoss: 2.079920\tLabel Loss: 0.023599\n",
            "Epoch: 74 [1280/1762 (71%)]\tLoss: 2.093997\tLabel Loss: 0.023300\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 74 \tVal Loss: 2.275816\n",
            "Epoch: 74 \tTest Loss: 2.136994\n",
            "\n",
            "Epoch: 75 [0/1762 (0%)]\tLoss: 2.364002\tLabel Loss: 0.022733\n",
            "Epoch: 75 [640/1762 (36%)]\tLoss: 2.486838\tLabel Loss: 0.022649\n",
            "Epoch: 75 [1280/1762 (71%)]\tLoss: 2.313554\tLabel Loss: 0.022706\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 75 \tVal Loss: 2.355582\n",
            "Epoch: 75 \tTest Loss: 2.208002\n",
            "\n",
            "Epoch: 76 [0/1762 (0%)]\tLoss: 2.404543\tLabel Loss: 0.023091\n",
            "Epoch: 76 [640/1762 (36%)]\tLoss: 2.313882\tLabel Loss: 0.021936\n",
            "Epoch: 76 [1280/1762 (71%)]\tLoss: 2.206684\tLabel Loss: 0.021743\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 76 \tVal Loss: 2.315072\n",
            "Epoch: 76 \tTest Loss: 2.163327\n",
            "\n",
            "Epoch: 77 [0/1762 (0%)]\tLoss: 2.139513\tLabel Loss: 0.021710\n",
            "Epoch: 77 [640/1762 (36%)]\tLoss: 2.251671\tLabel Loss: 0.021695\n",
            "Epoch: 77 [1280/1762 (71%)]\tLoss: 2.351074\tLabel Loss: 0.021029\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 77 \tVal Loss: 2.246105\n",
            "Epoch: 77 \tTest Loss: 2.112114\n",
            "\n",
            "Epoch: 78 [0/1762 (0%)]\tLoss: 2.180107\tLabel Loss: 0.020906\n",
            "Epoch: 78 [640/1762 (36%)]\tLoss: 2.328236\tLabel Loss: 0.021013\n",
            "Epoch: 78 [1280/1762 (71%)]\tLoss: 2.394600\tLabel Loss: 0.020943\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 78 \tVal Loss: 2.265217\n",
            "Epoch: 78 \tTest Loss: 2.115837\n",
            "\n",
            "Epoch: 79 [0/1762 (0%)]\tLoss: 2.157427\tLabel Loss: 0.022047\n",
            "Epoch: 79 [640/1762 (36%)]\tLoss: 2.258733\tLabel Loss: 0.020191\n",
            "Epoch: 79 [1280/1762 (71%)]\tLoss: 2.076105\tLabel Loss: 0.020176\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 79 \tVal Loss: 2.290665\n",
            "Epoch: 79 \tTest Loss: 2.147788\n",
            "\n",
            "Epoch: 80 [0/1762 (0%)]\tLoss: 2.691360\tLabel Loss: 0.019858\n",
            "Epoch: 80 [640/1762 (36%)]\tLoss: 2.095902\tLabel Loss: 0.020369\n",
            "Epoch: 80 [1280/1762 (71%)]\tLoss: 2.331017\tLabel Loss: 0.019491\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 80 \tVal Loss: 2.281657\n",
            "Epoch: 80 \tTest Loss: 2.132076\n",
            "\n",
            "Epoch: 81 [0/1762 (0%)]\tLoss: 2.247172\tLabel Loss: 0.019491\n",
            "Epoch: 81 [640/1762 (36%)]\tLoss: 2.079427\tLabel Loss: 0.019135\n",
            "Epoch: 81 [1280/1762 (71%)]\tLoss: 2.249613\tLabel Loss: 0.019096\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 81 \tVal Loss: 2.241999\n",
            "Epoch: 81 \tTest Loss: 2.110633\n",
            "\n",
            "Epoch: 82 [0/1762 (0%)]\tLoss: 2.087160\tLabel Loss: 0.019108\n",
            "Epoch: 82 [640/1762 (36%)]\tLoss: 2.373045\tLabel Loss: 0.018673\n",
            "Epoch: 82 [1280/1762 (71%)]\tLoss: 2.209652\tLabel Loss: 0.018334\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 82 \tVal Loss: 2.245708\n",
            "Epoch: 82 \tTest Loss: 2.116163\n",
            "\n",
            "Epoch: 83 [0/1762 (0%)]\tLoss: 2.080340\tLabel Loss: 0.018242\n",
            "Epoch: 83 [640/1762 (36%)]\tLoss: 2.309617\tLabel Loss: 0.018201\n",
            "Epoch: 83 [1280/1762 (71%)]\tLoss: 2.290628\tLabel Loss: 0.017845\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 83 \tVal Loss: 2.248012\n",
            "Epoch: 83 \tTest Loss: 2.117121\n",
            "\n",
            "Epoch: 84 [0/1762 (0%)]\tLoss: 2.026794\tLabel Loss: 0.017804\n",
            "Epoch: 84 [640/1762 (36%)]\tLoss: 2.361644\tLabel Loss: 0.017660\n",
            "Epoch: 84 [1280/1762 (71%)]\tLoss: 2.023547\tLabel Loss: 0.017728\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 84 \tVal Loss: 2.246440\n",
            "Epoch: 84 \tTest Loss: 2.114893\n",
            "\n",
            "Epoch: 85 [0/1762 (0%)]\tLoss: 2.098428\tLabel Loss: 0.018108\n",
            "Epoch: 85 [640/1762 (36%)]\tLoss: 1.902234\tLabel Loss: 0.017125\n",
            "Epoch: 85 [1280/1762 (71%)]\tLoss: 2.227131\tLabel Loss: 0.016964\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 85 \tVal Loss: 2.337760\n",
            "Epoch: 85 \tTest Loss: 2.198960\n",
            "\n",
            "Epoch: 86 [0/1762 (0%)]\tLoss: 2.354502\tLabel Loss: 0.017316\n",
            "Epoch: 86 [640/1762 (36%)]\tLoss: 2.164869\tLabel Loss: 0.016668\n",
            "Epoch: 86 [1280/1762 (71%)]\tLoss: 2.181684\tLabel Loss: 0.017400\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 86 \tVal Loss: 2.291753\n",
            "Epoch: 86 \tTest Loss: 2.143783\n",
            "\n",
            "Epoch: 87 [0/1762 (0%)]\tLoss: 2.164508\tLabel Loss: 0.016467\n",
            "Epoch: 87 [640/1762 (36%)]\tLoss: 2.338334\tLabel Loss: 0.016146\n",
            "Epoch: 87 [1280/1762 (71%)]\tLoss: 2.073789\tLabel Loss: 0.016559\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 87 \tVal Loss: 2.243795\n",
            "Epoch: 87 \tTest Loss: 2.108905\n",
            "\n",
            "Epoch: 88 [0/1762 (0%)]\tLoss: 2.306363\tLabel Loss: 0.015959\n",
            "Epoch: 88 [640/1762 (36%)]\tLoss: 2.428787\tLabel Loss: 0.015654\n",
            "Epoch: 88 [1280/1762 (71%)]\tLoss: 2.131521\tLabel Loss: 0.017575\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 88 \tVal Loss: 2.250487\n",
            "Epoch: 88 \tTest Loss: 2.123701\n",
            "\n",
            "Epoch: 89 [0/1762 (0%)]\tLoss: 2.198135\tLabel Loss: 0.016503\n",
            "Epoch: 89 [640/1762 (36%)]\tLoss: 2.166524\tLabel Loss: 0.015878\n",
            "Epoch: 89 [1280/1762 (71%)]\tLoss: 1.981198\tLabel Loss: 0.015462\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 89 \tVal Loss: 2.271413\n",
            "Epoch: 89 \tTest Loss: 2.120857\n",
            "\n",
            "Epoch: 90 [0/1762 (0%)]\tLoss: 2.122543\tLabel Loss: 0.015101\n",
            "Epoch: 90 [640/1762 (36%)]\tLoss: 2.064463\tLabel Loss: 0.014516\n",
            "Epoch: 90 [1280/1762 (71%)]\tLoss: 2.080025\tLabel Loss: 0.014429\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 90 \tVal Loss: 2.249328\n",
            "Epoch: 90 \tTest Loss: 2.120759\n",
            "\n",
            "Epoch: 91 [0/1762 (0%)]\tLoss: 2.022100\tLabel Loss: 0.014291\n",
            "Epoch: 91 [640/1762 (36%)]\tLoss: 2.304176\tLabel Loss: 0.014192\n",
            "Epoch: 91 [1280/1762 (71%)]\tLoss: 2.187647\tLabel Loss: 0.014489\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 91 \tVal Loss: 2.243877\n",
            "Epoch: 91 \tTest Loss: 2.106734\n",
            "\n",
            "Epoch: 92 [0/1762 (0%)]\tLoss: 2.315332\tLabel Loss: 0.014764\n",
            "Epoch: 92 [640/1762 (36%)]\tLoss: 2.248314\tLabel Loss: 0.013767\n",
            "Epoch: 92 [1280/1762 (71%)]\tLoss: 2.266650\tLabel Loss: 0.013765\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 92 \tVal Loss: 2.323536\n",
            "Epoch: 92 \tTest Loss: 2.184540\n",
            "\n",
            "Epoch: 93 [0/1762 (0%)]\tLoss: 2.034149\tLabel Loss: 0.013841\n",
            "Epoch: 93 [640/1762 (36%)]\tLoss: 2.052315\tLabel Loss: 0.014529\n",
            "Epoch: 93 [1280/1762 (71%)]\tLoss: 2.156156\tLabel Loss: 0.013461\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 93 \tVal Loss: 2.228667\n",
            "Epoch: 93 \tTest Loss: 2.095212\n",
            "\n",
            "Epoch: 94 [0/1762 (0%)]\tLoss: 2.276518\tLabel Loss: 0.013289\n",
            "Epoch: 94 [640/1762 (36%)]\tLoss: 2.055382\tLabel Loss: 0.013780\n",
            "Epoch: 94 [1280/1762 (71%)]\tLoss: 2.165724\tLabel Loss: 0.013012\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 94 \tVal Loss: 2.248107\n",
            "Epoch: 94 \tTest Loss: 2.118854\n",
            "\n",
            "Epoch: 95 [0/1762 (0%)]\tLoss: 2.039921\tLabel Loss: 0.012965\n",
            "Epoch: 95 [640/1762 (36%)]\tLoss: 2.172319\tLabel Loss: 0.013027\n",
            "Epoch: 95 [1280/1762 (71%)]\tLoss: 2.300612\tLabel Loss: 0.013724\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 95 \tVal Loss: 2.247399\n",
            "Epoch: 95 \tTest Loss: 2.106858\n",
            "\n",
            "Epoch: 96 [0/1762 (0%)]\tLoss: 1.970507\tLabel Loss: 0.012984\n",
            "Epoch: 96 [640/1762 (36%)]\tLoss: 2.155747\tLabel Loss: 0.012504\n",
            "Epoch: 96 [1280/1762 (71%)]\tLoss: 2.177322\tLabel Loss: 0.012470\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 96 \tVal Loss: 2.233836\n",
            "Epoch: 96 \tTest Loss: 2.102974\n",
            "\n",
            "Epoch: 97 [0/1762 (0%)]\tLoss: 2.185343\tLabel Loss: 0.012232\n",
            "Epoch: 97 [640/1762 (36%)]\tLoss: 2.190837\tLabel Loss: 0.012510\n",
            "Epoch: 97 [1280/1762 (71%)]\tLoss: 2.164353\tLabel Loss: 0.012606\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 97 \tVal Loss: 2.225732\n",
            "Epoch: 97 \tTest Loss: 2.095985\n",
            "\n",
            "Epoch: 98 [0/1762 (0%)]\tLoss: 2.287374\tLabel Loss: 0.012148\n",
            "Epoch: 98 [640/1762 (36%)]\tLoss: 2.480135\tLabel Loss: 0.012048\n",
            "Epoch: 98 [1280/1762 (71%)]\tLoss: 2.032558\tLabel Loss: 0.011851\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 98 \tVal Loss: 2.248807\n",
            "Epoch: 98 \tTest Loss: 2.114665\n",
            "\n",
            "Epoch: 99 [0/1762 (0%)]\tLoss: 2.023359\tLabel Loss: 0.011791\n",
            "Epoch: 99 [640/1762 (36%)]\tLoss: 2.179100\tLabel Loss: 0.011860\n",
            "Epoch: 99 [1280/1762 (71%)]\tLoss: 2.160469\tLabel Loss: 0.011688\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 99 \tVal Loss: 2.237610\n",
            "Epoch: 99 \tTest Loss: 2.111793\n",
            "\n",
            "Epoch: 100 [0/1762 (0%)]\tLoss: 2.047706\tLabel Loss: 0.011717\n",
            "Epoch: 100 [640/1762 (36%)]\tLoss: 2.020220\tLabel Loss: 0.011544\n",
            "Epoch: 100 [1280/1762 (71%)]\tLoss: 2.184152\tLabel Loss: 0.011370\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 100 \tVal Loss: 2.246651\n",
            "Epoch: 100 \tTest Loss: 2.127825\n",
            "\n",
            "Epoch: 101 [0/1762 (0%)]\tLoss: 2.280706\tLabel Loss: 0.011752\n",
            "Epoch: 101 [640/1762 (36%)]\tLoss: 2.315815\tLabel Loss: 0.011162\n",
            "Epoch: 101 [1280/1762 (71%)]\tLoss: 2.330415\tLabel Loss: 0.010974\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 101 \tVal Loss: 2.228918\n",
            "Epoch: 101 \tTest Loss: 2.102343\n",
            "\n",
            "Epoch: 102 [0/1762 (0%)]\tLoss: 2.100105\tLabel Loss: 0.011316\n",
            "Epoch: 102 [640/1762 (36%)]\tLoss: 1.870193\tLabel Loss: 0.011310\n",
            "Epoch: 102 [1280/1762 (71%)]\tLoss: 2.161829\tLabel Loss: 0.010838\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 102 \tVal Loss: 2.238274\n",
            "Epoch: 102 \tTest Loss: 2.098777\n",
            "\n",
            "Epoch: 103 [0/1762 (0%)]\tLoss: 2.120230\tLabel Loss: 0.010806\n",
            "Epoch: 103 [640/1762 (36%)]\tLoss: 2.173885\tLabel Loss: 0.010631\n",
            "Epoch: 103 [1280/1762 (71%)]\tLoss: 2.135748\tLabel Loss: 0.010459\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 103 \tVal Loss: 2.230709\n",
            "Epoch: 103 \tTest Loss: 2.099330\n",
            "\n",
            "Epoch: 104 [0/1762 (0%)]\tLoss: 2.256621\tLabel Loss: 0.010505\n",
            "Epoch: 104 [640/1762 (36%)]\tLoss: 2.111114\tLabel Loss: 0.011127\n",
            "Epoch: 104 [1280/1762 (71%)]\tLoss: 2.009999\tLabel Loss: 0.010346\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 104 \tVal Loss: 2.227762\n",
            "Epoch: 104 \tTest Loss: 2.097410\n",
            "\n",
            "Epoch: 105 [0/1762 (0%)]\tLoss: 2.293413\tLabel Loss: 0.010944\n",
            "Epoch: 105 [640/1762 (36%)]\tLoss: 2.349237\tLabel Loss: 0.010192\n",
            "Epoch: 105 [1280/1762 (71%)]\tLoss: 2.216383\tLabel Loss: 0.010558\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 105 \tVal Loss: 2.240372\n",
            "Epoch: 105 \tTest Loss: 2.114943\n",
            "\n",
            "Epoch: 106 [0/1762 (0%)]\tLoss: 1.956033\tLabel Loss: 0.011287\n",
            "Epoch: 106 [640/1762 (36%)]\tLoss: 1.985832\tLabel Loss: 0.010238\n",
            "Epoch: 106 [1280/1762 (71%)]\tLoss: 2.281881\tLabel Loss: 0.009961\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 106 \tVal Loss: 2.224686\n",
            "Epoch: 106 \tTest Loss: 2.096372\n",
            "\n",
            "Epoch: 107 [0/1762 (0%)]\tLoss: 2.449532\tLabel Loss: 0.009937\n",
            "Epoch: 107 [640/1762 (36%)]\tLoss: 1.895478\tLabel Loss: 0.009787\n",
            "Epoch: 107 [1280/1762 (71%)]\tLoss: 2.305693\tLabel Loss: 0.009713\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 107 \tVal Loss: 2.237556\n",
            "Epoch: 107 \tTest Loss: 2.111230\n",
            "\n",
            "Epoch: 108 [0/1762 (0%)]\tLoss: 2.065669\tLabel Loss: 0.009737\n",
            "Epoch: 108 [640/1762 (36%)]\tLoss: 2.116351\tLabel Loss: 0.009906\n",
            "Epoch: 108 [1280/1762 (71%)]\tLoss: 2.314941\tLabel Loss: 0.010275\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 108 \tVal Loss: 2.253156\n",
            "Epoch: 108 \tTest Loss: 2.112761\n",
            "\n",
            "Epoch: 109 [0/1762 (0%)]\tLoss: 2.032561\tLabel Loss: 0.009735\n",
            "Epoch: 109 [640/1762 (36%)]\tLoss: 2.227239\tLabel Loss: 0.009566\n",
            "Epoch: 109 [1280/1762 (71%)]\tLoss: 2.309644\tLabel Loss: 0.009317\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 109 \tVal Loss: 2.268159\n",
            "Epoch: 109 \tTest Loss: 2.124973\n",
            "\n",
            "Epoch: 110 [0/1762 (0%)]\tLoss: 2.039180\tLabel Loss: 0.009558\n",
            "Epoch: 110 [640/1762 (36%)]\tLoss: 2.166186\tLabel Loss: 0.009215\n",
            "Epoch: 110 [1280/1762 (71%)]\tLoss: 1.914361\tLabel Loss: 0.009254\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 110 \tVal Loss: 2.237056\n",
            "Epoch: 110 \tTest Loss: 2.105302\n",
            "\n",
            "Epoch: 111 [0/1762 (0%)]\tLoss: 2.300867\tLabel Loss: 0.009488\n",
            "Epoch: 111 [640/1762 (36%)]\tLoss: 2.275715\tLabel Loss: 0.009409\n",
            "Epoch: 111 [1280/1762 (71%)]\tLoss: 2.128473\tLabel Loss: 0.009013\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 111 \tVal Loss: 2.227347\n",
            "Epoch: 111 \tTest Loss: 2.092264\n",
            "\n",
            "Epoch: 112 [0/1762 (0%)]\tLoss: 2.184070\tLabel Loss: 0.008943\n",
            "Epoch: 112 [640/1762 (36%)]\tLoss: 2.119141\tLabel Loss: 0.009071\n",
            "Epoch: 112 [1280/1762 (71%)]\tLoss: 2.212805\tLabel Loss: 0.008817\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 112 \tVal Loss: 2.242547\n",
            "Epoch: 112 \tTest Loss: 2.117376\n",
            "\n",
            "Epoch: 113 [0/1762 (0%)]\tLoss: 2.348218\tLabel Loss: 0.008787\n",
            "Epoch: 113 [640/1762 (36%)]\tLoss: 2.038549\tLabel Loss: 0.008744\n",
            "Epoch: 113 [1280/1762 (71%)]\tLoss: 2.068999\tLabel Loss: 0.008706\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 113 \tVal Loss: 2.236110\n",
            "Epoch: 113 \tTest Loss: 2.098542\n",
            "\n",
            "Epoch: 114 [0/1762 (0%)]\tLoss: 2.010285\tLabel Loss: 0.009403\n",
            "Epoch: 114 [640/1762 (36%)]\tLoss: 2.208345\tLabel Loss: 0.008748\n",
            "Epoch: 114 [1280/1762 (71%)]\tLoss: 1.960802\tLabel Loss: 0.008524\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 114 \tVal Loss: 2.240714\n",
            "Epoch: 114 \tTest Loss: 2.105472\n",
            "\n",
            "Epoch: 115 [0/1762 (0%)]\tLoss: 2.241246\tLabel Loss: 0.008628\n",
            "Epoch: 115 [640/1762 (36%)]\tLoss: 2.226853\tLabel Loss: 0.008484\n",
            "Epoch: 115 [1280/1762 (71%)]\tLoss: 2.228222\tLabel Loss: 0.008376\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 115 \tVal Loss: 2.226315\n",
            "Epoch: 115 \tTest Loss: 2.092872\n",
            "\n",
            "Epoch: 116 [0/1762 (0%)]\tLoss: 2.100628\tLabel Loss: 0.008503\n",
            "Epoch: 116 [640/1762 (36%)]\tLoss: 2.324552\tLabel Loss: 0.008828\n",
            "Epoch: 116 [1280/1762 (71%)]\tLoss: 2.131711\tLabel Loss: 0.008360\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 116 \tVal Loss: 2.235382\n",
            "Epoch: 116 \tTest Loss: 2.106061\n",
            "\n",
            "Epoch: 117 [0/1762 (0%)]\tLoss: 2.101429\tLabel Loss: 0.008129\n",
            "Epoch: 117 [640/1762 (36%)]\tLoss: 2.118673\tLabel Loss: 0.008094\n",
            "Epoch: 117 [1280/1762 (71%)]\tLoss: 2.220212\tLabel Loss: 0.008196\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 117 \tVal Loss: 2.227738\n",
            "Epoch: 117 \tTest Loss: 2.099069\n",
            "\n",
            "Epoch: 118 [0/1762 (0%)]\tLoss: 1.904477\tLabel Loss: 0.008038\n",
            "Epoch: 118 [640/1762 (36%)]\tLoss: 2.212320\tLabel Loss: 0.008147\n",
            "Epoch: 118 [1280/1762 (71%)]\tLoss: 2.124382\tLabel Loss: 0.007966\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 118 \tVal Loss: 2.216629\n",
            "Epoch: 118 \tTest Loss: 2.097291\n",
            "\n",
            "Epoch: 119 [0/1762 (0%)]\tLoss: 2.103130\tLabel Loss: 0.008079\n",
            "Epoch: 119 [640/1762 (36%)]\tLoss: 2.345579\tLabel Loss: 0.007910\n",
            "Epoch: 119 [1280/1762 (71%)]\tLoss: 2.069782\tLabel Loss: 0.007915\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 119 \tVal Loss: 2.215669\n",
            "Epoch: 119 \tTest Loss: 2.093136\n",
            "\n",
            "Epoch: 120 [0/1762 (0%)]\tLoss: 2.192690\tLabel Loss: 0.007843\n",
            "Epoch: 120 [640/1762 (36%)]\tLoss: 2.151547\tLabel Loss: 0.007718\n",
            "Epoch: 120 [1280/1762 (71%)]\tLoss: 2.175803\tLabel Loss: 0.007888\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 120 \tVal Loss: 2.214913\n",
            "Epoch: 120 \tTest Loss: 2.084815\n",
            "\n",
            "Epoch: 121 [0/1762 (0%)]\tLoss: 2.135641\tLabel Loss: 0.007642\n",
            "Epoch: 121 [640/1762 (36%)]\tLoss: 1.929414\tLabel Loss: 0.007522\n",
            "Epoch: 121 [1280/1762 (71%)]\tLoss: 2.178864\tLabel Loss: 0.007556\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 121 \tVal Loss: 2.224833\n",
            "Epoch: 121 \tTest Loss: 2.096428\n",
            "\n",
            "Epoch: 122 [0/1762 (0%)]\tLoss: 2.163243\tLabel Loss: 0.007585\n",
            "Epoch: 122 [640/1762 (36%)]\tLoss: 1.940238\tLabel Loss: 0.007555\n",
            "Epoch: 122 [1280/1762 (71%)]\tLoss: 1.918663\tLabel Loss: 0.007525\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 122 \tVal Loss: 2.223162\n",
            "Epoch: 122 \tTest Loss: 2.089299\n",
            "\n",
            "Epoch: 123 [0/1762 (0%)]\tLoss: 2.064836\tLabel Loss: 0.007488\n",
            "Epoch: 123 [640/1762 (36%)]\tLoss: 2.060379\tLabel Loss: 0.007520\n",
            "Epoch: 123 [1280/1762 (71%)]\tLoss: 1.943320\tLabel Loss: 0.007455\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 123 \tVal Loss: 2.278746\n",
            "Epoch: 123 \tTest Loss: 2.141205\n",
            "\n",
            "Epoch: 124 [0/1762 (0%)]\tLoss: 2.464903\tLabel Loss: 0.007311\n",
            "Epoch: 124 [640/1762 (36%)]\tLoss: 2.092795\tLabel Loss: 0.007403\n",
            "Epoch: 124 [1280/1762 (71%)]\tLoss: 2.163800\tLabel Loss: 0.007360\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 124 \tVal Loss: 2.222482\n",
            "Epoch: 124 \tTest Loss: 2.091718\n",
            "\n",
            "Epoch: 125 [0/1762 (0%)]\tLoss: 2.069949\tLabel Loss: 0.007218\n",
            "Epoch: 125 [640/1762 (36%)]\tLoss: 2.316354\tLabel Loss: 0.007208\n",
            "Epoch: 125 [1280/1762 (71%)]\tLoss: 2.405109\tLabel Loss: 0.007078\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 125 \tVal Loss: 2.212023\n",
            "Epoch: 125 \tTest Loss: 2.082131\n",
            "\n",
            "Epoch: 126 [0/1762 (0%)]\tLoss: 2.330053\tLabel Loss: 0.007162\n",
            "Epoch: 126 [640/1762 (36%)]\tLoss: 2.137012\tLabel Loss: 0.007514\n",
            "Epoch: 126 [1280/1762 (71%)]\tLoss: 2.202876\tLabel Loss: 0.007343\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 126 \tVal Loss: 2.242528\n",
            "Epoch: 126 \tTest Loss: 2.105253\n",
            "\n",
            "Epoch: 127 [0/1762 (0%)]\tLoss: 2.131499\tLabel Loss: 0.007180\n",
            "Epoch: 127 [640/1762 (36%)]\tLoss: 2.003676\tLabel Loss: 0.007100\n",
            "Epoch: 127 [1280/1762 (71%)]\tLoss: 2.250060\tLabel Loss: 0.006929\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 127 \tVal Loss: 2.214633\n",
            "Epoch: 127 \tTest Loss: 2.095829\n",
            "\n",
            "Epoch: 128 [0/1762 (0%)]\tLoss: 1.978985\tLabel Loss: 0.006772\n",
            "Epoch: 128 [640/1762 (36%)]\tLoss: 2.119964\tLabel Loss: 0.006865\n",
            "Epoch: 128 [1280/1762 (71%)]\tLoss: 2.368893\tLabel Loss: 0.006810\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 128 \tVal Loss: 2.222669\n",
            "Epoch: 128 \tTest Loss: 2.093015\n",
            "\n",
            "Epoch: 129 [0/1762 (0%)]\tLoss: 2.071048\tLabel Loss: 0.006907\n",
            "Epoch: 129 [640/1762 (36%)]\tLoss: 2.152017\tLabel Loss: 0.006692\n",
            "Epoch: 129 [1280/1762 (71%)]\tLoss: 2.253270\tLabel Loss: 0.006647\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 129 \tVal Loss: 2.206643\n",
            "Epoch: 129 \tTest Loss: 2.082780\n",
            "\n",
            "Epoch: 130 [0/1762 (0%)]\tLoss: 1.978536\tLabel Loss: 0.006705\n",
            "Epoch: 130 [640/1762 (36%)]\tLoss: 2.234115\tLabel Loss: 0.006668\n",
            "Epoch: 130 [1280/1762 (71%)]\tLoss: 2.108741\tLabel Loss: 0.006657\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 130 \tVal Loss: 2.213136\n",
            "Epoch: 130 \tTest Loss: 2.083362\n",
            "\n",
            "Epoch: 131 [0/1762 (0%)]\tLoss: 2.284928\tLabel Loss: 0.007214\n",
            "Epoch: 131 [640/1762 (36%)]\tLoss: 2.443571\tLabel Loss: 0.006643\n",
            "Epoch: 131 [1280/1762 (71%)]\tLoss: 2.168565\tLabel Loss: 0.006452\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 131 \tVal Loss: 2.221638\n",
            "Epoch: 131 \tTest Loss: 2.088375\n",
            "\n",
            "Epoch: 132 [0/1762 (0%)]\tLoss: 1.894155\tLabel Loss: 0.006608\n",
            "Epoch: 132 [640/1762 (36%)]\tLoss: 2.203846\tLabel Loss: 0.006435\n",
            "Epoch: 132 [1280/1762 (71%)]\tLoss: 2.111157\tLabel Loss: 0.006424\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 132 \tVal Loss: 2.231762\n",
            "Epoch: 132 \tTest Loss: 2.091249\n",
            "\n",
            "Epoch: 133 [0/1762 (0%)]\tLoss: 2.271558\tLabel Loss: 0.007064\n",
            "Epoch: 133 [640/1762 (36%)]\tLoss: 2.182566\tLabel Loss: 0.006265\n",
            "Epoch: 133 [1280/1762 (71%)]\tLoss: 1.978711\tLabel Loss: 0.006534\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 133 \tVal Loss: 2.197242\n",
            "Epoch: 133 \tTest Loss: 2.076207\n",
            "\n",
            "Epoch: 134 [0/1762 (0%)]\tLoss: 2.250823\tLabel Loss: 0.006451\n",
            "Epoch: 134 [640/1762 (36%)]\tLoss: 2.048022\tLabel Loss: 0.006321\n",
            "Epoch: 134 [1280/1762 (71%)]\tLoss: 2.325058\tLabel Loss: 0.006483\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 134 \tVal Loss: 2.223090\n",
            "Epoch: 134 \tTest Loss: 2.098293\n",
            "\n",
            "Epoch: 135 [0/1762 (0%)]\tLoss: 2.055283\tLabel Loss: 0.006151\n",
            "Epoch: 135 [640/1762 (36%)]\tLoss: 2.298772\tLabel Loss: 0.006251\n",
            "Epoch: 135 [1280/1762 (71%)]\tLoss: 2.154785\tLabel Loss: 0.006212\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 135 \tVal Loss: 2.212726\n",
            "Epoch: 135 \tTest Loss: 2.081952\n",
            "\n",
            "Epoch: 136 [0/1762 (0%)]\tLoss: 2.133993\tLabel Loss: 0.006268\n",
            "Epoch: 136 [640/1762 (36%)]\tLoss: 2.338568\tLabel Loss: 0.006156\n",
            "Epoch: 136 [1280/1762 (71%)]\tLoss: 2.213076\tLabel Loss: 0.006179\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 136 \tVal Loss: 2.218844\n",
            "Epoch: 136 \tTest Loss: 2.087353\n",
            "\n",
            "Epoch: 137 [0/1762 (0%)]\tLoss: 1.943184\tLabel Loss: 0.006019\n",
            "Epoch: 137 [640/1762 (36%)]\tLoss: 2.239379\tLabel Loss: 0.006370\n",
            "Epoch: 137 [1280/1762 (71%)]\tLoss: 2.221728\tLabel Loss: 0.006589\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 137 \tVal Loss: 2.231406\n",
            "Epoch: 137 \tTest Loss: 2.096378\n",
            "\n",
            "Epoch: 138 [0/1762 (0%)]\tLoss: 2.074145\tLabel Loss: 0.005923\n",
            "Epoch: 138 [640/1762 (36%)]\tLoss: 2.154196\tLabel Loss: 0.006342\n",
            "Epoch: 138 [1280/1762 (71%)]\tLoss: 2.160222\tLabel Loss: 0.006246\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 138 \tVal Loss: 2.213481\n",
            "Epoch: 138 \tTest Loss: 2.094522\n",
            "\n",
            "Epoch: 139 [0/1762 (0%)]\tLoss: 2.081517\tLabel Loss: 0.005898\n",
            "Epoch: 139 [640/1762 (36%)]\tLoss: 2.170841\tLabel Loss: 0.005797\n",
            "Epoch: 139 [1280/1762 (71%)]\tLoss: 2.119257\tLabel Loss: 0.005789\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 139 \tVal Loss: 2.213881\n",
            "Epoch: 139 \tTest Loss: 2.088420\n",
            "\n",
            "Epoch: 140 [0/1762 (0%)]\tLoss: 2.193881\tLabel Loss: 0.005794\n",
            "Epoch: 140 [640/1762 (36%)]\tLoss: 2.231588\tLabel Loss: 0.005886\n",
            "Epoch: 140 [1280/1762 (71%)]\tLoss: 2.133911\tLabel Loss: 0.005706\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 140 \tVal Loss: 2.214186\n",
            "Epoch: 140 \tTest Loss: 2.089250\n",
            "\n",
            "Epoch: 141 [0/1762 (0%)]\tLoss: 2.197298\tLabel Loss: 0.005728\n",
            "Epoch: 141 [640/1762 (36%)]\tLoss: 2.383449\tLabel Loss: 0.005773\n",
            "Epoch: 141 [1280/1762 (71%)]\tLoss: 2.220456\tLabel Loss: 0.005671\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 141 \tVal Loss: 2.231288\n",
            "Epoch: 141 \tTest Loss: 2.109439\n",
            "\n",
            "Epoch: 142 [0/1762 (0%)]\tLoss: 2.027975\tLabel Loss: 0.005596\n",
            "Epoch: 142 [640/1762 (36%)]\tLoss: 2.147341\tLabel Loss: 0.005794\n",
            "Epoch: 142 [1280/1762 (71%)]\tLoss: 1.990637\tLabel Loss: 0.005888\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 142 \tVal Loss: 2.208111\n",
            "Epoch: 142 \tTest Loss: 2.078543\n",
            "\n",
            "Epoch: 143 [0/1762 (0%)]\tLoss: 2.163475\tLabel Loss: 0.006210\n",
            "Epoch: 143 [640/1762 (36%)]\tLoss: 1.937085\tLabel Loss: 0.005568\n",
            "Epoch: 143 [1280/1762 (71%)]\tLoss: 2.211273\tLabel Loss: 0.005610\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 143 \tVal Loss: 2.218647\n",
            "Epoch: 143 \tTest Loss: 2.090534\n",
            "\n",
            "Epoch: 144 [0/1762 (0%)]\tLoss: 2.249286\tLabel Loss: 0.005828\n",
            "Epoch: 144 [640/1762 (36%)]\tLoss: 2.032311\tLabel Loss: 0.005670\n",
            "Epoch: 144 [1280/1762 (71%)]\tLoss: 2.225958\tLabel Loss: 0.005523\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 144 \tVal Loss: 2.209004\n",
            "Epoch: 144 \tTest Loss: 2.081681\n",
            "\n",
            "Epoch: 145 [0/1762 (0%)]\tLoss: 2.346823\tLabel Loss: 0.005636\n",
            "Epoch: 145 [640/1762 (36%)]\tLoss: 2.285464\tLabel Loss: 0.005446\n",
            "Epoch: 145 [1280/1762 (71%)]\tLoss: 2.281472\tLabel Loss: 0.005453\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 145 \tVal Loss: 2.249542\n",
            "Epoch: 145 \tTest Loss: 2.106770\n",
            "\n",
            "Epoch: 146 [0/1762 (0%)]\tLoss: 2.086510\tLabel Loss: 0.005349\n",
            "Epoch: 146 [640/1762 (36%)]\tLoss: 2.021511\tLabel Loss: 0.005840\n",
            "Epoch: 146 [1280/1762 (71%)]\tLoss: 2.002854\tLabel Loss: 0.005539\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 146 \tVal Loss: 2.240140\n",
            "Epoch: 146 \tTest Loss: 2.098838\n",
            "\n",
            "Epoch: 147 [0/1762 (0%)]\tLoss: 2.205478\tLabel Loss: 0.005375\n",
            "Epoch: 147 [640/1762 (36%)]\tLoss: 2.028416\tLabel Loss: 0.005270\n",
            "Epoch: 147 [1280/1762 (71%)]\tLoss: 2.165431\tLabel Loss: 0.005507\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 147 \tVal Loss: 2.213775\n",
            "Epoch: 147 \tTest Loss: 2.087341\n",
            "\n",
            "Epoch: 148 [0/1762 (0%)]\tLoss: 2.135466\tLabel Loss: 0.005497\n",
            "Epoch: 148 [640/1762 (36%)]\tLoss: 2.030282\tLabel Loss: 0.005295\n",
            "Epoch: 148 [1280/1762 (71%)]\tLoss: 2.212906\tLabel Loss: 0.005494\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 148 \tVal Loss: 2.237787\n",
            "Epoch: 148 \tTest Loss: 2.091266\n",
            "\n",
            "Epoch: 149 [0/1762 (0%)]\tLoss: 2.107113\tLabel Loss: 0.005292\n",
            "Epoch: 149 [640/1762 (36%)]\tLoss: 2.412847\tLabel Loss: 0.005572\n",
            "Epoch: 149 [1280/1762 (71%)]\tLoss: 2.324292\tLabel Loss: 0.005505\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 149 \tVal Loss: 2.235425\n",
            "Epoch: 149 \tTest Loss: 2.103645\n",
            "\n",
            "Epoch: 150 [0/1762 (0%)]\tLoss: 2.029764\tLabel Loss: 0.005630\n",
            "Epoch: 150 [640/1762 (36%)]\tLoss: 2.339255\tLabel Loss: 0.005150\n",
            "Epoch: 150 [1280/1762 (71%)]\tLoss: 2.157162\tLabel Loss: 0.005420\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 150 \tVal Loss: 2.209990\n",
            "Epoch: 150 \tTest Loss: 2.091741\n",
            "\n",
            "Epoch: 151 [0/1762 (0%)]\tLoss: 2.206443\tLabel Loss: 0.005518\n",
            "Epoch: 151 [640/1762 (36%)]\tLoss: 2.196517\tLabel Loss: 0.005045\n",
            "Epoch: 151 [1280/1762 (71%)]\tLoss: 2.210009\tLabel Loss: 0.005185\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 151 \tVal Loss: 2.227989\n",
            "Epoch: 151 \tTest Loss: 2.090947\n",
            "\n",
            "Epoch: 152 [0/1762 (0%)]\tLoss: 2.111108\tLabel Loss: 0.005169\n",
            "Epoch: 152 [640/1762 (36%)]\tLoss: 2.022721\tLabel Loss: 0.004932\n",
            "Epoch: 152 [1280/1762 (71%)]\tLoss: 2.097887\tLabel Loss: 0.005009\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 152 \tVal Loss: 2.210902\n",
            "Epoch: 152 \tTest Loss: 2.087424\n",
            "\n",
            "Epoch: 153 [0/1762 (0%)]\tLoss: 2.256212\tLabel Loss: 0.005230\n",
            "Epoch: 153 [640/1762 (36%)]\tLoss: 2.050161\tLabel Loss: 0.004957\n",
            "Epoch: 153 [1280/1762 (71%)]\tLoss: 2.159423\tLabel Loss: 0.004948\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 153 \tVal Loss: 2.227726\n",
            "Epoch: 153 \tTest Loss: 2.085356\n",
            "\n",
            "Epoch: 154 [0/1762 (0%)]\tLoss: 2.003588\tLabel Loss: 0.005006\n",
            "Epoch: 154 [640/1762 (36%)]\tLoss: 2.015570\tLabel Loss: 0.004988\n",
            "Epoch: 154 [1280/1762 (71%)]\tLoss: 2.221954\tLabel Loss: 0.004787\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 154 \tVal Loss: 2.216765\n",
            "Epoch: 154 \tTest Loss: 2.095818\n",
            "\n",
            "Epoch: 155 [0/1762 (0%)]\tLoss: 2.201154\tLabel Loss: 0.004821\n",
            "Epoch: 155 [640/1762 (36%)]\tLoss: 1.965329\tLabel Loss: 0.004914\n",
            "Epoch: 155 [1280/1762 (71%)]\tLoss: 2.277522\tLabel Loss: 0.004877\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 155 \tVal Loss: 2.209341\n",
            "Epoch: 155 \tTest Loss: 2.077316\n",
            "\n",
            "Epoch: 156 [0/1762 (0%)]\tLoss: 2.028444\tLabel Loss: 0.004776\n",
            "Epoch: 156 [640/1762 (36%)]\tLoss: 2.127165\tLabel Loss: 0.004709\n",
            "Epoch: 156 [1280/1762 (71%)]\tLoss: 2.167253\tLabel Loss: 0.004710\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 156 \tVal Loss: 2.210128\n",
            "Epoch: 156 \tTest Loss: 2.076355\n",
            "\n",
            "Epoch: 157 [0/1762 (0%)]\tLoss: 1.954427\tLabel Loss: 0.004750\n",
            "Epoch: 157 [640/1762 (36%)]\tLoss: 1.856848\tLabel Loss: 0.004721\n",
            "Epoch: 157 [1280/1762 (71%)]\tLoss: 2.118464\tLabel Loss: 0.004758\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 157 \tVal Loss: 2.198514\n",
            "Epoch: 157 \tTest Loss: 2.082752\n",
            "\n",
            "Epoch: 158 [0/1762 (0%)]\tLoss: 2.279068\tLabel Loss: 0.004663\n",
            "Epoch: 158 [640/1762 (36%)]\tLoss: 2.311411\tLabel Loss: 0.004570\n",
            "Epoch: 158 [1280/1762 (71%)]\tLoss: 2.240209\tLabel Loss: 0.004617\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 158 \tVal Loss: 2.218916\n",
            "Epoch: 158 \tTest Loss: 2.089539\n",
            "\n",
            "Epoch: 159 [0/1762 (0%)]\tLoss: 2.123566\tLabel Loss: 0.004696\n",
            "Epoch: 159 [640/1762 (36%)]\tLoss: 2.307640\tLabel Loss: 0.004667\n",
            "Epoch: 159 [1280/1762 (71%)]\tLoss: 2.050059\tLabel Loss: 0.004582\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 159 \tVal Loss: 2.222104\n",
            "Epoch: 159 \tTest Loss: 2.085524\n",
            "\n",
            "Epoch: 160 [0/1762 (0%)]\tLoss: 2.280296\tLabel Loss: 0.004630\n",
            "Epoch: 160 [640/1762 (36%)]\tLoss: 2.163293\tLabel Loss: 0.004652\n",
            "Epoch: 160 [1280/1762 (71%)]\tLoss: 2.089079\tLabel Loss: 0.004520\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 160 \tVal Loss: 2.221770\n",
            "Epoch: 160 \tTest Loss: 2.088938\n",
            "\n",
            "Epoch: 161 [0/1762 (0%)]\tLoss: 2.220666\tLabel Loss: 0.004714\n",
            "Epoch: 161 [640/1762 (36%)]\tLoss: 2.334759\tLabel Loss: 0.004482\n",
            "Epoch: 161 [1280/1762 (71%)]\tLoss: 2.255188\tLabel Loss: 0.004556\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 161 \tVal Loss: 2.216968\n",
            "Epoch: 161 \tTest Loss: 2.090515\n",
            "\n",
            "Epoch: 162 [0/1762 (0%)]\tLoss: 2.139919\tLabel Loss: 0.004511\n",
            "Epoch: 162 [640/1762 (36%)]\tLoss: 2.229499\tLabel Loss: 0.004679\n",
            "Epoch: 162 [1280/1762 (71%)]\tLoss: 2.298913\tLabel Loss: 0.004669\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 162 \tVal Loss: 2.214360\n",
            "Epoch: 162 \tTest Loss: 2.081728\n",
            "\n",
            "Epoch: 163 [0/1762 (0%)]\tLoss: 2.017350\tLabel Loss: 0.004645\n",
            "Epoch: 163 [640/1762 (36%)]\tLoss: 2.225399\tLabel Loss: 0.004507\n",
            "Epoch: 163 [1280/1762 (71%)]\tLoss: 1.992035\tLabel Loss: 0.004398\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 163 \tVal Loss: 2.204825\n",
            "Epoch: 163 \tTest Loss: 2.072195\n",
            "\n",
            "Epoch: 164 [0/1762 (0%)]\tLoss: 2.186652\tLabel Loss: 0.004326\n",
            "Epoch: 164 [640/1762 (36%)]\tLoss: 2.122845\tLabel Loss: 0.004467\n",
            "Epoch: 164 [1280/1762 (71%)]\tLoss: 2.098779\tLabel Loss: 0.004383\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 164 \tVal Loss: 2.218615\n",
            "Epoch: 164 \tTest Loss: 2.082898\n",
            "\n",
            "Epoch: 165 [0/1762 (0%)]\tLoss: 2.174312\tLabel Loss: 0.004478\n",
            "Epoch: 165 [640/1762 (36%)]\tLoss: 2.168642\tLabel Loss: 0.004360\n",
            "Epoch: 165 [1280/1762 (71%)]\tLoss: 2.107514\tLabel Loss: 0.004589\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 165 \tVal Loss: 2.208912\n",
            "Epoch: 165 \tTest Loss: 2.083614\n",
            "\n",
            "Epoch: 166 [0/1762 (0%)]\tLoss: 2.325202\tLabel Loss: 0.004355\n",
            "Epoch: 166 [640/1762 (36%)]\tLoss: 2.260530\tLabel Loss: 0.004304\n",
            "Epoch: 166 [1280/1762 (71%)]\tLoss: 2.109774\tLabel Loss: 0.004422\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 166 \tVal Loss: 2.214778\n",
            "Epoch: 166 \tTest Loss: 2.085548\n",
            "\n",
            "Epoch: 167 [0/1762 (0%)]\tLoss: 2.262310\tLabel Loss: 0.004369\n",
            "Epoch: 167 [640/1762 (36%)]\tLoss: 2.139426\tLabel Loss: 0.004463\n",
            "Epoch: 167 [1280/1762 (71%)]\tLoss: 2.241828\tLabel Loss: 0.004212\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 167 \tVal Loss: 2.217216\n",
            "Epoch: 167 \tTest Loss: 2.081512\n",
            "\n",
            "Epoch: 168 [0/1762 (0%)]\tLoss: 2.086557\tLabel Loss: 0.004427\n",
            "Epoch: 168 [640/1762 (36%)]\tLoss: 2.242726\tLabel Loss: 0.004141\n",
            "Epoch: 168 [1280/1762 (71%)]\tLoss: 2.185001\tLabel Loss: 0.004235\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 168 \tVal Loss: 2.212457\n",
            "Epoch: 168 \tTest Loss: 2.083778\n",
            "\n",
            "Epoch: 169 [0/1762 (0%)]\tLoss: 2.133660\tLabel Loss: 0.004063\n",
            "Epoch: 169 [640/1762 (36%)]\tLoss: 2.417035\tLabel Loss: 0.004233\n",
            "Epoch: 169 [1280/1762 (71%)]\tLoss: 2.201195\tLabel Loss: 0.004086\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 169 \tVal Loss: 2.204219\n",
            "Epoch: 169 \tTest Loss: 2.069476\n",
            "\n",
            "Epoch: 170 [0/1762 (0%)]\tLoss: 2.302697\tLabel Loss: 0.004030\n",
            "Epoch: 170 [640/1762 (36%)]\tLoss: 2.185148\tLabel Loss: 0.004547\n",
            "Epoch: 170 [1280/1762 (71%)]\tLoss: 2.136871\tLabel Loss: 0.004130\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 170 \tVal Loss: 2.212063\n",
            "Epoch: 170 \tTest Loss: 2.084757\n",
            "\n",
            "Epoch: 171 [0/1762 (0%)]\tLoss: 2.095846\tLabel Loss: 0.004161\n",
            "Epoch: 171 [640/1762 (36%)]\tLoss: 2.246314\tLabel Loss: 0.004143\n",
            "Epoch: 171 [1280/1762 (71%)]\tLoss: 2.129621\tLabel Loss: 0.003984\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 171 \tVal Loss: 2.202021\n",
            "Epoch: 171 \tTest Loss: 2.071888\n",
            "\n",
            "Epoch: 172 [0/1762 (0%)]\tLoss: 2.482409\tLabel Loss: 0.004042\n",
            "Epoch: 172 [640/1762 (36%)]\tLoss: 2.034487\tLabel Loss: 0.003952\n",
            "Epoch: 172 [1280/1762 (71%)]\tLoss: 2.020696\tLabel Loss: 0.004019\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 172 \tVal Loss: 2.225735\n",
            "Epoch: 172 \tTest Loss: 2.091990\n",
            "\n",
            "Epoch: 173 [0/1762 (0%)]\tLoss: 2.136164\tLabel Loss: 0.003922\n",
            "Epoch: 173 [640/1762 (36%)]\tLoss: 2.082800\tLabel Loss: 0.004049\n",
            "Epoch: 173 [1280/1762 (71%)]\tLoss: 2.231589\tLabel Loss: 0.003956\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 173 \tVal Loss: 2.208958\n",
            "Epoch: 173 \tTest Loss: 2.074037\n",
            "\n",
            "Epoch: 174 [0/1762 (0%)]\tLoss: 2.237798\tLabel Loss: 0.004176\n",
            "Epoch: 174 [640/1762 (36%)]\tLoss: 1.936754\tLabel Loss: 0.003980\n",
            "Epoch: 174 [1280/1762 (71%)]\tLoss: 2.143335\tLabel Loss: 0.003925\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 174 \tVal Loss: 2.209927\n",
            "Epoch: 174 \tTest Loss: 2.087653\n",
            "\n",
            "Epoch: 175 [0/1762 (0%)]\tLoss: 2.327432\tLabel Loss: 0.003876\n",
            "Epoch: 175 [640/1762 (36%)]\tLoss: 2.084058\tLabel Loss: 0.004041\n",
            "Epoch: 175 [1280/1762 (71%)]\tLoss: 2.022597\tLabel Loss: 0.003851\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 175 \tVal Loss: 2.209830\n",
            "Epoch: 175 \tTest Loss: 2.087908\n",
            "\n",
            "Epoch: 176 [0/1762 (0%)]\tLoss: 2.319516\tLabel Loss: 0.003825\n",
            "Epoch: 176 [640/1762 (36%)]\tLoss: 2.291585\tLabel Loss: 0.003822\n",
            "Epoch: 176 [1280/1762 (71%)]\tLoss: 2.066614\tLabel Loss: 0.003868\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 176 \tVal Loss: 2.229439\n",
            "Epoch: 176 \tTest Loss: 2.097004\n",
            "\n",
            "Epoch: 177 [0/1762 (0%)]\tLoss: 2.098824\tLabel Loss: 0.003872\n",
            "Epoch: 177 [640/1762 (36%)]\tLoss: 2.392460\tLabel Loss: 0.003785\n",
            "Epoch: 177 [1280/1762 (71%)]\tLoss: 2.157750\tLabel Loss: 0.003811\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 177 \tVal Loss: 2.214551\n",
            "Epoch: 177 \tTest Loss: 2.083607\n",
            "\n",
            "Epoch: 178 [0/1762 (0%)]\tLoss: 2.366433\tLabel Loss: 0.003774\n",
            "Epoch: 178 [640/1762 (36%)]\tLoss: 2.174026\tLabel Loss: 0.003847\n",
            "Epoch: 178 [1280/1762 (71%)]\tLoss: 2.185560\tLabel Loss: 0.003792\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 178 \tVal Loss: 2.210231\n",
            "Epoch: 178 \tTest Loss: 2.080332\n",
            "\n",
            "Epoch: 179 [0/1762 (0%)]\tLoss: 2.245616\tLabel Loss: 0.003720\n",
            "Epoch: 179 [640/1762 (36%)]\tLoss: 2.193478\tLabel Loss: 0.003749\n",
            "Epoch: 179 [1280/1762 (71%)]\tLoss: 2.115817\tLabel Loss: 0.003728\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 179 \tVal Loss: 2.231150\n",
            "Epoch: 179 \tTest Loss: 2.105184\n",
            "\n",
            "Epoch: 180 [0/1762 (0%)]\tLoss: 2.149084\tLabel Loss: 0.003837\n",
            "Epoch: 180 [640/1762 (36%)]\tLoss: 1.882326\tLabel Loss: 0.003691\n",
            "Epoch: 180 [1280/1762 (71%)]\tLoss: 2.307637\tLabel Loss: 0.003689\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 180 \tVal Loss: 2.201099\n",
            "Epoch: 180 \tTest Loss: 2.069386\n",
            "\n",
            "Epoch: 181 [0/1762 (0%)]\tLoss: 2.013393\tLabel Loss: 0.003674\n",
            "Epoch: 181 [640/1762 (36%)]\tLoss: 2.249683\tLabel Loss: 0.003637\n",
            "Epoch: 181 [1280/1762 (71%)]\tLoss: 2.213673\tLabel Loss: 0.003676\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 181 \tVal Loss: 2.213736\n",
            "Epoch: 181 \tTest Loss: 2.080829\n",
            "\n",
            "Epoch: 182 [0/1762 (0%)]\tLoss: 2.062332\tLabel Loss: 0.003578\n",
            "Epoch: 182 [640/1762 (36%)]\tLoss: 2.089875\tLabel Loss: 0.003786\n",
            "Epoch: 182 [1280/1762 (71%)]\tLoss: 2.089858\tLabel Loss: 0.003605\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 182 \tVal Loss: 2.222342\n",
            "Epoch: 182 \tTest Loss: 2.091355\n",
            "\n",
            "Epoch: 183 [0/1762 (0%)]\tLoss: 2.034090\tLabel Loss: 0.003666\n",
            "Epoch: 183 [640/1762 (36%)]\tLoss: 2.261734\tLabel Loss: 0.003567\n",
            "Epoch: 183 [1280/1762 (71%)]\tLoss: 1.940094\tLabel Loss: 0.003622\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 183 \tVal Loss: 2.221074\n",
            "Epoch: 183 \tTest Loss: 2.084189\n",
            "\n",
            "Epoch: 184 [0/1762 (0%)]\tLoss: 2.090922\tLabel Loss: 0.003548\n",
            "Epoch: 184 [640/1762 (36%)]\tLoss: 1.971701\tLabel Loss: 0.003589\n",
            "Epoch: 184 [1280/1762 (71%)]\tLoss: 1.997438\tLabel Loss: 0.003494\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 184 \tVal Loss: 2.215073\n",
            "Epoch: 184 \tTest Loss: 2.083387\n",
            "\n",
            "Epoch: 185 [0/1762 (0%)]\tLoss: 2.342610\tLabel Loss: 0.003657\n",
            "Epoch: 185 [640/1762 (36%)]\tLoss: 1.967138\tLabel Loss: 0.003468\n",
            "Epoch: 185 [1280/1762 (71%)]\tLoss: 2.174052\tLabel Loss: 0.004142\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 185 \tVal Loss: 2.196109\n",
            "Epoch: 185 \tTest Loss: 2.067001\n",
            "\n",
            "Epoch: 186 [0/1762 (0%)]\tLoss: 2.050218\tLabel Loss: 0.004017\n",
            "Epoch: 186 [640/1762 (36%)]\tLoss: 2.188880\tLabel Loss: 0.004166\n",
            "Epoch: 186 [1280/1762 (71%)]\tLoss: 2.077496\tLabel Loss: 0.003559\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 186 \tVal Loss: 2.200322\n",
            "Epoch: 186 \tTest Loss: 2.065934\n",
            "\n",
            "Epoch: 187 [0/1762 (0%)]\tLoss: 2.082742\tLabel Loss: 0.003718\n",
            "Epoch: 187 [640/1762 (36%)]\tLoss: 1.871233\tLabel Loss: 0.003793\n",
            "Epoch: 187 [1280/1762 (71%)]\tLoss: 2.165694\tLabel Loss: 0.003395\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 187 \tVal Loss: 2.189979\n",
            "Epoch: 187 \tTest Loss: 2.061800\n",
            "\n",
            "Epoch: 188 [0/1762 (0%)]\tLoss: 2.273241\tLabel Loss: 0.003464\n",
            "Epoch: 188 [640/1762 (36%)]\tLoss: 2.023909\tLabel Loss: 0.003492\n",
            "Epoch: 188 [1280/1762 (71%)]\tLoss: 2.092985\tLabel Loss: 0.003399\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 188 \tVal Loss: 2.216431\n",
            "Epoch: 188 \tTest Loss: 2.079335\n",
            "\n",
            "Epoch: 189 [0/1762 (0%)]\tLoss: 2.114199\tLabel Loss: 0.003450\n",
            "Epoch: 189 [640/1762 (36%)]\tLoss: 2.152951\tLabel Loss: 0.003918\n",
            "Epoch: 189 [1280/1762 (71%)]\tLoss: 2.165706\tLabel Loss: 0.003369\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 189 \tVal Loss: 2.217488\n",
            "Epoch: 189 \tTest Loss: 2.074654\n",
            "\n",
            "Epoch: 190 [0/1762 (0%)]\tLoss: 2.129386\tLabel Loss: 0.003415\n",
            "Epoch: 190 [640/1762 (36%)]\tLoss: 2.266831\tLabel Loss: 0.003683\n",
            "Epoch: 190 [1280/1762 (71%)]\tLoss: 2.054143\tLabel Loss: 0.003425\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 190 \tVal Loss: 2.227508\n",
            "Epoch: 190 \tTest Loss: 2.086142\n",
            "\n",
            "Epoch: 191 [0/1762 (0%)]\tLoss: 2.217867\tLabel Loss: 0.003411\n",
            "Epoch: 191 [640/1762 (36%)]\tLoss: 2.253041\tLabel Loss: 0.003727\n",
            "Epoch: 191 [1280/1762 (71%)]\tLoss: 2.078744\tLabel Loss: 0.003321\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 191 \tVal Loss: 2.202417\n",
            "Epoch: 191 \tTest Loss: 2.081437\n",
            "\n",
            "Epoch: 192 [0/1762 (0%)]\tLoss: 2.184787\tLabel Loss: 0.003353\n",
            "Epoch: 192 [640/1762 (36%)]\tLoss: 2.158248\tLabel Loss: 0.003399\n",
            "Epoch: 192 [1280/1762 (71%)]\tLoss: 2.275417\tLabel Loss: 0.003274\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 192 \tVal Loss: 2.235097\n",
            "Epoch: 192 \tTest Loss: 2.101344\n",
            "\n",
            "Epoch: 193 [0/1762 (0%)]\tLoss: 2.131213\tLabel Loss: 0.003290\n",
            "Epoch: 193 [640/1762 (36%)]\tLoss: 2.166077\tLabel Loss: 0.003493\n",
            "Epoch: 193 [1280/1762 (71%)]\tLoss: 2.124914\tLabel Loss: 0.003285\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 193 \tVal Loss: 2.221248\n",
            "Epoch: 193 \tTest Loss: 2.087154\n",
            "\n",
            "Epoch: 194 [0/1762 (0%)]\tLoss: 2.088646\tLabel Loss: 0.003228\n",
            "Epoch: 194 [640/1762 (36%)]\tLoss: 1.989881\tLabel Loss: 0.003282\n",
            "Epoch: 194 [1280/1762 (71%)]\tLoss: 2.356363\tLabel Loss: 0.003402\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 194 \tVal Loss: 2.198889\n",
            "Epoch: 194 \tTest Loss: 2.070266\n",
            "\n",
            "Epoch: 195 [0/1762 (0%)]\tLoss: 2.005720\tLabel Loss: 0.003191\n",
            "Epoch: 195 [640/1762 (36%)]\tLoss: 2.062709\tLabel Loss: 0.003225\n",
            "Epoch: 195 [1280/1762 (71%)]\tLoss: 1.986406\tLabel Loss: 0.003224\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 195 \tVal Loss: 2.198878\n",
            "Epoch: 195 \tTest Loss: 2.069621\n",
            "\n",
            "Epoch: 196 [0/1762 (0%)]\tLoss: 2.209471\tLabel Loss: 0.003224\n",
            "Epoch: 196 [640/1762 (36%)]\tLoss: 2.130650\tLabel Loss: 0.003219\n",
            "Epoch: 196 [1280/1762 (71%)]\tLoss: 2.112139\tLabel Loss: 0.003464\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 196 \tVal Loss: 2.198286\n",
            "Epoch: 196 \tTest Loss: 2.069467\n",
            "\n",
            "Epoch: 197 [0/1762 (0%)]\tLoss: 2.071542\tLabel Loss: 0.003195\n",
            "Epoch: 197 [640/1762 (36%)]\tLoss: 2.138920\tLabel Loss: 0.003420\n",
            "Epoch: 197 [1280/1762 (71%)]\tLoss: 2.002129\tLabel Loss: 0.003133\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 197 \tVal Loss: 2.207095\n",
            "Epoch: 197 \tTest Loss: 2.071942\n",
            "\n",
            "Epoch: 198 [0/1762 (0%)]\tLoss: 2.071554\tLabel Loss: 0.003210\n",
            "Epoch: 198 [640/1762 (36%)]\tLoss: 2.153219\tLabel Loss: 0.003219\n",
            "Epoch: 198 [1280/1762 (71%)]\tLoss: 2.097292\tLabel Loss: 0.003225\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 198 \tVal Loss: 2.221704\n",
            "Epoch: 198 \tTest Loss: 2.091225\n",
            "\n",
            "Epoch: 199 [0/1762 (0%)]\tLoss: 2.058002\tLabel Loss: 0.003229\n",
            "Epoch: 199 [640/1762 (36%)]\tLoss: 2.274138\tLabel Loss: 0.003152\n",
            "Epoch: 199 [1280/1762 (71%)]\tLoss: 2.065890\tLabel Loss: 0.003446\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 199 \tVal Loss: 2.216379\n",
            "Epoch: 199 \tTest Loss: 2.086490\n",
            "\n",
            "Epoch: 200 [0/1762 (0%)]\tLoss: 2.070780\tLabel Loss: 0.003121\n",
            "Epoch: 200 [640/1762 (36%)]\tLoss: 2.188093\tLabel Loss: 0.003168\n",
            "Epoch: 200 [1280/1762 (71%)]\tLoss: 2.068859\tLabel Loss: 0.003057\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 200 \tVal Loss: 2.201545\n",
            "Epoch: 200 \tTest Loss: 2.069277\n",
            "\n",
            "Epoch: 201 [0/1762 (0%)]\tLoss: 2.048871\tLabel Loss: 0.003137\n",
            "Epoch: 201 [640/1762 (36%)]\tLoss: 2.119356\tLabel Loss: 0.003111\n",
            "Epoch: 201 [1280/1762 (71%)]\tLoss: 2.149850\tLabel Loss: 0.003087\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 201 \tVal Loss: 2.207287\n",
            "Epoch: 201 \tTest Loss: 2.082456\n",
            "\n",
            "Epoch: 202 [0/1762 (0%)]\tLoss: 1.984103\tLabel Loss: 0.003034\n",
            "Epoch: 202 [640/1762 (36%)]\tLoss: 2.108218\tLabel Loss: 0.003080\n",
            "Epoch: 202 [1280/1762 (71%)]\tLoss: 2.216719\tLabel Loss: 0.003015\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 202 \tVal Loss: 2.203703\n",
            "Epoch: 202 \tTest Loss: 2.073940\n",
            "\n",
            "Epoch: 203 [0/1762 (0%)]\tLoss: 2.337051\tLabel Loss: 0.003105\n",
            "Epoch: 203 [640/1762 (36%)]\tLoss: 2.203416\tLabel Loss: 0.003038\n",
            "Epoch: 203 [1280/1762 (71%)]\tLoss: 2.207517\tLabel Loss: 0.002982\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 203 \tVal Loss: 2.200926\n",
            "Epoch: 203 \tTest Loss: 2.066206\n",
            "\n",
            "Epoch: 204 [0/1762 (0%)]\tLoss: 2.029938\tLabel Loss: 0.002981\n",
            "Epoch: 204 [640/1762 (36%)]\tLoss: 2.427441\tLabel Loss: 0.003093\n",
            "Epoch: 204 [1280/1762 (71%)]\tLoss: 2.115952\tLabel Loss: 0.003050\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 204 \tVal Loss: 2.215646\n",
            "Epoch: 204 \tTest Loss: 2.094640\n",
            "\n",
            "Epoch: 205 [0/1762 (0%)]\tLoss: 2.443020\tLabel Loss: 0.002957\n",
            "Epoch: 205 [640/1762 (36%)]\tLoss: 2.171139\tLabel Loss: 0.003532\n",
            "Epoch: 205 [1280/1762 (71%)]\tLoss: 2.155400\tLabel Loss: 0.002958\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 205 \tVal Loss: 2.195063\n",
            "Epoch: 205 \tTest Loss: 2.066747\n",
            "\n",
            "Epoch: 206 [0/1762 (0%)]\tLoss: 1.981082\tLabel Loss: 0.003055\n",
            "Epoch: 206 [640/1762 (36%)]\tLoss: 2.264014\tLabel Loss: 0.002931\n",
            "Epoch: 206 [1280/1762 (71%)]\tLoss: 1.963640\tLabel Loss: 0.003180\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 206 \tVal Loss: 2.207086\n",
            "Epoch: 206 \tTest Loss: 2.078879\n",
            "\n",
            "Epoch: 207 [0/1762 (0%)]\tLoss: 2.023550\tLabel Loss: 0.002990\n",
            "Epoch: 207 [640/1762 (36%)]\tLoss: 2.123653\tLabel Loss: 0.002914\n",
            "Epoch: 207 [1280/1762 (71%)]\tLoss: 2.432606\tLabel Loss: 0.002959\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 207 \tVal Loss: 2.216061\n",
            "Epoch: 207 \tTest Loss: 2.072802\n",
            "\n",
            "Epoch: 208 [0/1762 (0%)]\tLoss: 2.024338\tLabel Loss: 0.003005\n",
            "Epoch: 208 [640/1762 (36%)]\tLoss: 2.203924\tLabel Loss: 0.002901\n",
            "Epoch: 208 [1280/1762 (71%)]\tLoss: 2.155423\tLabel Loss: 0.003143\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 208 \tVal Loss: 2.220540\n",
            "Epoch: 208 \tTest Loss: 2.083345\n",
            "\n",
            "Epoch: 209 [0/1762 (0%)]\tLoss: 2.126374\tLabel Loss: 0.003076\n",
            "Epoch: 209 [640/1762 (36%)]\tLoss: 2.105300\tLabel Loss: 0.003115\n",
            "Epoch: 209 [1280/1762 (71%)]\tLoss: 2.034010\tLabel Loss: 0.003077\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 209 \tVal Loss: 2.187359\n",
            "Epoch: 209 \tTest Loss: 2.063708\n",
            "\n",
            "Epoch: 210 [0/1762 (0%)]\tLoss: 2.122493\tLabel Loss: 0.002982\n",
            "Epoch: 210 [640/1762 (36%)]\tLoss: 2.292457\tLabel Loss: 0.003006\n",
            "Epoch: 210 [1280/1762 (71%)]\tLoss: 2.071214\tLabel Loss: 0.002972\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 210 \tVal Loss: 2.210056\n",
            "Epoch: 210 \tTest Loss: 2.075239\n",
            "\n",
            "Epoch: 211 [0/1762 (0%)]\tLoss: 1.996346\tLabel Loss: 0.002926\n",
            "Epoch: 211 [640/1762 (36%)]\tLoss: 2.188439\tLabel Loss: 0.002869\n",
            "Epoch: 211 [1280/1762 (71%)]\tLoss: 2.192090\tLabel Loss: 0.002841\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 211 \tVal Loss: 2.205512\n",
            "Epoch: 211 \tTest Loss: 2.077685\n",
            "\n",
            "Epoch: 212 [0/1762 (0%)]\tLoss: 1.856200\tLabel Loss: 0.002940\n",
            "Epoch: 212 [640/1762 (36%)]\tLoss: 2.023986\tLabel Loss: 0.002966\n",
            "Epoch: 212 [1280/1762 (71%)]\tLoss: 2.093149\tLabel Loss: 0.002948\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 212 \tVal Loss: 2.234536\n",
            "Epoch: 212 \tTest Loss: 2.097100\n",
            "\n",
            "Epoch: 213 [0/1762 (0%)]\tLoss: 1.921277\tLabel Loss: 0.002963\n",
            "Epoch: 213 [640/1762 (36%)]\tLoss: 2.168653\tLabel Loss: 0.002985\n",
            "Epoch: 213 [1280/1762 (71%)]\tLoss: 2.102247\tLabel Loss: 0.002891\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 213 \tVal Loss: 2.228574\n",
            "Epoch: 213 \tTest Loss: 2.099837\n",
            "\n",
            "Epoch: 214 [0/1762 (0%)]\tLoss: 2.064278\tLabel Loss: 0.002811\n",
            "Epoch: 214 [640/1762 (36%)]\tLoss: 2.185314\tLabel Loss: 0.002814\n",
            "Epoch: 214 [1280/1762 (71%)]\tLoss: 2.179479\tLabel Loss: 0.002906\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 214 \tVal Loss: 2.215436\n",
            "Epoch: 214 \tTest Loss: 2.086543\n",
            "\n",
            "Epoch: 215 [0/1762 (0%)]\tLoss: 2.114116\tLabel Loss: 0.003014\n",
            "Epoch: 215 [640/1762 (36%)]\tLoss: 2.380173\tLabel Loss: 0.003149\n",
            "Epoch: 215 [1280/1762 (71%)]\tLoss: 1.993178\tLabel Loss: 0.002989\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 215 \tVal Loss: 2.212714\n",
            "Epoch: 215 \tTest Loss: 2.069840\n",
            "\n",
            "Epoch: 216 [0/1762 (0%)]\tLoss: 2.031515\tLabel Loss: 0.003018\n",
            "Epoch: 216 [640/1762 (36%)]\tLoss: 1.948035\tLabel Loss: 0.002785\n",
            "Epoch: 216 [1280/1762 (71%)]\tLoss: 2.199384\tLabel Loss: 0.002806\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 216 \tVal Loss: 2.220317\n",
            "Epoch: 216 \tTest Loss: 2.083663\n",
            "\n",
            "Epoch: 217 [0/1762 (0%)]\tLoss: 1.991750\tLabel Loss: 0.002711\n",
            "Epoch: 217 [640/1762 (36%)]\tLoss: 2.297459\tLabel Loss: 0.002738\n",
            "Epoch: 217 [1280/1762 (71%)]\tLoss: 2.059442\tLabel Loss: 0.002839\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 217 \tVal Loss: 2.198942\n",
            "Epoch: 217 \tTest Loss: 2.068183\n",
            "\n",
            "Epoch: 218 [0/1762 (0%)]\tLoss: 2.189062\tLabel Loss: 0.002712\n",
            "Epoch: 218 [640/1762 (36%)]\tLoss: 2.244242\tLabel Loss: 0.002805\n",
            "Epoch: 218 [1280/1762 (71%)]\tLoss: 1.940528\tLabel Loss: 0.002920\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 218 \tVal Loss: 2.209140\n",
            "Epoch: 218 \tTest Loss: 2.074024\n",
            "\n",
            "Epoch: 219 [0/1762 (0%)]\tLoss: 2.169888\tLabel Loss: 0.002722\n",
            "Epoch: 219 [640/1762 (36%)]\tLoss: 2.166457\tLabel Loss: 0.002711\n",
            "Epoch: 219 [1280/1762 (71%)]\tLoss: 2.184613\tLabel Loss: 0.002719\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 219 \tVal Loss: 2.200038\n",
            "Epoch: 219 \tTest Loss: 2.073558\n",
            "\n",
            "Epoch: 220 [0/1762 (0%)]\tLoss: 2.011880\tLabel Loss: 0.003082\n",
            "Epoch: 220 [640/1762 (36%)]\tLoss: 2.115952\tLabel Loss: 0.002783\n",
            "Epoch: 220 [1280/1762 (71%)]\tLoss: 2.084354\tLabel Loss: 0.002686\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 220 \tVal Loss: 2.202521\n",
            "Epoch: 220 \tTest Loss: 2.062967\n",
            "\n",
            "Epoch: 221 [0/1762 (0%)]\tLoss: 2.087095\tLabel Loss: 0.002756\n",
            "Epoch: 221 [640/1762 (36%)]\tLoss: 1.695002\tLabel Loss: 0.002641\n",
            "Epoch: 221 [1280/1762 (71%)]\tLoss: 2.205328\tLabel Loss: 0.002700\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 221 \tVal Loss: 2.217987\n",
            "Epoch: 221 \tTest Loss: 2.081833\n",
            "\n",
            "Epoch: 222 [0/1762 (0%)]\tLoss: 1.934048\tLabel Loss: 0.002676\n",
            "Epoch: 222 [640/1762 (36%)]\tLoss: 2.389759\tLabel Loss: 0.002599\n",
            "Epoch: 222 [1280/1762 (71%)]\tLoss: 1.980491\tLabel Loss: 0.002821\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 222 \tVal Loss: 2.208516\n",
            "Epoch: 222 \tTest Loss: 2.068064\n",
            "\n",
            "Epoch: 223 [0/1762 (0%)]\tLoss: 2.090726\tLabel Loss: 0.003030\n",
            "Epoch: 223 [640/1762 (36%)]\tLoss: 2.240967\tLabel Loss: 0.002662\n",
            "Epoch: 223 [1280/1762 (71%)]\tLoss: 2.245435\tLabel Loss: 0.002752\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 223 \tVal Loss: 2.213153\n",
            "Epoch: 223 \tTest Loss: 2.079978\n",
            "\n",
            "Epoch: 224 [0/1762 (0%)]\tLoss: 2.168931\tLabel Loss: 0.002625\n",
            "Epoch: 224 [640/1762 (36%)]\tLoss: 2.021751\tLabel Loss: 0.002832\n",
            "Epoch: 224 [1280/1762 (71%)]\tLoss: 2.041908\tLabel Loss: 0.002628\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 224 \tVal Loss: 2.205340\n",
            "Epoch: 224 \tTest Loss: 2.070450\n",
            "\n",
            "Epoch: 225 [0/1762 (0%)]\tLoss: 2.118141\tLabel Loss: 0.002669\n",
            "Epoch: 225 [640/1762 (36%)]\tLoss: 1.999640\tLabel Loss: 0.002584\n",
            "Epoch: 225 [1280/1762 (71%)]\tLoss: 2.232113\tLabel Loss: 0.002614\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 225 \tVal Loss: 2.203576\n",
            "Epoch: 225 \tTest Loss: 2.069385\n",
            "\n",
            "Epoch: 226 [0/1762 (0%)]\tLoss: 2.320014\tLabel Loss: 0.002669\n",
            "Epoch: 226 [640/1762 (36%)]\tLoss: 2.036024\tLabel Loss: 0.002550\n",
            "Epoch: 226 [1280/1762 (71%)]\tLoss: 2.202884\tLabel Loss: 0.002639\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 226 \tVal Loss: 2.186668\n",
            "Epoch: 226 \tTest Loss: 2.064234\n",
            "\n",
            "Epoch: 227 [0/1762 (0%)]\tLoss: 2.029252\tLabel Loss: 0.002555\n",
            "Epoch: 227 [640/1762 (36%)]\tLoss: 2.100414\tLabel Loss: 0.002570\n",
            "Epoch: 227 [1280/1762 (71%)]\tLoss: 2.120178\tLabel Loss: 0.002563\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 227 \tVal Loss: 2.201937\n",
            "Epoch: 227 \tTest Loss: 2.070538\n",
            "\n",
            "Epoch: 228 [0/1762 (0%)]\tLoss: 1.945525\tLabel Loss: 0.002798\n",
            "Epoch: 228 [640/1762 (36%)]\tLoss: 2.118418\tLabel Loss: 0.002592\n",
            "Epoch: 228 [1280/1762 (71%)]\tLoss: 2.088943\tLabel Loss: 0.002715\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 228 \tVal Loss: 2.206698\n",
            "Epoch: 228 \tTest Loss: 2.068572\n",
            "\n",
            "Epoch: 229 [0/1762 (0%)]\tLoss: 2.122290\tLabel Loss: 0.002669\n",
            "Epoch: 229 [640/1762 (36%)]\tLoss: 2.090784\tLabel Loss: 0.002556\n",
            "Epoch: 229 [1280/1762 (71%)]\tLoss: 1.938627\tLabel Loss: 0.002580\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 229 \tVal Loss: 2.202855\n",
            "Epoch: 229 \tTest Loss: 2.066315\n",
            "\n",
            "Epoch: 230 [0/1762 (0%)]\tLoss: 2.081576\tLabel Loss: 0.002504\n",
            "Epoch: 230 [640/1762 (36%)]\tLoss: 2.372190\tLabel Loss: 0.002649\n",
            "Epoch: 230 [1280/1762 (71%)]\tLoss: 1.980024\tLabel Loss: 0.002486\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 230 \tVal Loss: 2.205258\n",
            "Epoch: 230 \tTest Loss: 2.080302\n",
            "\n",
            "Epoch: 231 [0/1762 (0%)]\tLoss: 2.276533\tLabel Loss: 0.002612\n",
            "Epoch: 231 [640/1762 (36%)]\tLoss: 2.064866\tLabel Loss: 0.002451\n",
            "Epoch: 231 [1280/1762 (71%)]\tLoss: 2.148964\tLabel Loss: 0.002724\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 231 \tVal Loss: 2.198942\n",
            "Epoch: 231 \tTest Loss: 2.070120\n",
            "\n",
            "Epoch: 232 [0/1762 (0%)]\tLoss: 2.101698\tLabel Loss: 0.002481\n",
            "Epoch: 232 [640/1762 (36%)]\tLoss: 2.009644\tLabel Loss: 0.002454\n",
            "Epoch: 232 [1280/1762 (71%)]\tLoss: 1.973870\tLabel Loss: 0.002505\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 232 \tVal Loss: 2.190872\n",
            "Epoch: 232 \tTest Loss: 2.067720\n",
            "\n",
            "Epoch: 233 [0/1762 (0%)]\tLoss: 1.930543\tLabel Loss: 0.002628\n",
            "Epoch: 233 [640/1762 (36%)]\tLoss: 2.113031\tLabel Loss: 0.002486\n",
            "Epoch: 233 [1280/1762 (71%)]\tLoss: 1.967935\tLabel Loss: 0.002479\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 233 \tVal Loss: 2.186720\n",
            "Epoch: 233 \tTest Loss: 2.056929\n",
            "\n",
            "Epoch: 234 [0/1762 (0%)]\tLoss: 2.228841\tLabel Loss: 0.002535\n",
            "Epoch: 234 [640/1762 (36%)]\tLoss: 2.151150\tLabel Loss: 0.002563\n",
            "Epoch: 234 [1280/1762 (71%)]\tLoss: 2.137484\tLabel Loss: 0.002424\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 234 \tVal Loss: 2.225698\n",
            "Epoch: 234 \tTest Loss: 2.088994\n",
            "\n",
            "Epoch: 235 [0/1762 (0%)]\tLoss: 2.134491\tLabel Loss: 0.002408\n",
            "Epoch: 235 [640/1762 (36%)]\tLoss: 2.039126\tLabel Loss: 0.002552\n",
            "Epoch: 235 [1280/1762 (71%)]\tLoss: 2.164777\tLabel Loss: 0.002558\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 235 \tVal Loss: 2.211265\n",
            "Epoch: 235 \tTest Loss: 2.079657\n",
            "\n",
            "Epoch: 236 [0/1762 (0%)]\tLoss: 2.179494\tLabel Loss: 0.002434\n",
            "Epoch: 236 [640/1762 (36%)]\tLoss: 2.262766\tLabel Loss: 0.002515\n",
            "Epoch: 236 [1280/1762 (71%)]\tLoss: 2.152139\tLabel Loss: 0.002414\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 236 \tVal Loss: 2.209365\n",
            "Epoch: 236 \tTest Loss: 2.069809\n",
            "\n",
            "Epoch: 237 [0/1762 (0%)]\tLoss: 2.134379\tLabel Loss: 0.002526\n",
            "Epoch: 237 [640/1762 (36%)]\tLoss: 2.191681\tLabel Loss: 0.002700\n",
            "Epoch: 237 [1280/1762 (71%)]\tLoss: 2.081348\tLabel Loss: 0.002490\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 237 \tVal Loss: 2.216123\n",
            "Epoch: 237 \tTest Loss: 2.081123\n",
            "\n",
            "Epoch: 238 [0/1762 (0%)]\tLoss: 2.110996\tLabel Loss: 0.002459\n",
            "Epoch: 238 [640/1762 (36%)]\tLoss: 2.053911\tLabel Loss: 0.002717\n",
            "Epoch: 238 [1280/1762 (71%)]\tLoss: 2.033751\tLabel Loss: 0.002399\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 238 \tVal Loss: 2.216495\n",
            "Epoch: 238 \tTest Loss: 2.073112\n",
            "\n",
            "Epoch: 239 [0/1762 (0%)]\tLoss: 2.128729\tLabel Loss: 0.002350\n",
            "Epoch: 239 [640/1762 (36%)]\tLoss: 2.207814\tLabel Loss: 0.002346\n",
            "Epoch: 239 [1280/1762 (71%)]\tLoss: 2.063542\tLabel Loss: 0.002339\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 239 \tVal Loss: 2.195446\n",
            "Epoch: 239 \tTest Loss: 2.057484\n",
            "\n",
            "Epoch: 240 [0/1762 (0%)]\tLoss: 2.098726\tLabel Loss: 0.002345\n",
            "Epoch: 240 [640/1762 (36%)]\tLoss: 2.176220\tLabel Loss: 0.002364\n",
            "Epoch: 240 [1280/1762 (71%)]\tLoss: 2.128573\tLabel Loss: 0.002298\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 240 \tVal Loss: 2.211756\n",
            "Epoch: 240 \tTest Loss: 2.079799\n",
            "\n",
            "Epoch: 241 [0/1762 (0%)]\tLoss: 2.129430\tLabel Loss: 0.002287\n",
            "Epoch: 241 [640/1762 (36%)]\tLoss: 2.215624\tLabel Loss: 0.002336\n",
            "Epoch: 241 [1280/1762 (71%)]\tLoss: 2.094258\tLabel Loss: 0.002319\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 241 \tVal Loss: 2.204153\n",
            "Epoch: 241 \tTest Loss: 2.076838\n",
            "\n",
            "Epoch: 242 [0/1762 (0%)]\tLoss: 2.287277\tLabel Loss: 0.002483\n",
            "Epoch: 242 [640/1762 (36%)]\tLoss: 2.191869\tLabel Loss: 0.002641\n",
            "Epoch: 242 [1280/1762 (71%)]\tLoss: 1.691396\tLabel Loss: 0.002417\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 242 \tVal Loss: 2.211264\n",
            "Epoch: 242 \tTest Loss: 2.073790\n",
            "\n",
            "Epoch: 243 [0/1762 (0%)]\tLoss: 2.097145\tLabel Loss: 0.002442\n",
            "Epoch: 243 [640/1762 (36%)]\tLoss: 2.073303\tLabel Loss: 0.002322\n",
            "Epoch: 243 [1280/1762 (71%)]\tLoss: 2.470975\tLabel Loss: 0.002277\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 243 \tVal Loss: 2.207823\n",
            "Epoch: 243 \tTest Loss: 2.072509\n",
            "\n",
            "Epoch: 244 [0/1762 (0%)]\tLoss: 2.124765\tLabel Loss: 0.002449\n",
            "Epoch: 244 [640/1762 (36%)]\tLoss: 2.062211\tLabel Loss: 0.002289\n",
            "Epoch: 244 [1280/1762 (71%)]\tLoss: 2.169954\tLabel Loss: 0.002272\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 244 \tVal Loss: 2.215495\n",
            "Epoch: 244 \tTest Loss: 2.087316\n",
            "\n",
            "Epoch: 245 [0/1762 (0%)]\tLoss: 2.190586\tLabel Loss: 0.002433\n",
            "Epoch: 245 [640/1762 (36%)]\tLoss: 1.859625\tLabel Loss: 0.002284\n",
            "Epoch: 245 [1280/1762 (71%)]\tLoss: 2.221827\tLabel Loss: 0.002266\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 245 \tVal Loss: 2.201232\n",
            "Epoch: 245 \tTest Loss: 2.070804\n",
            "\n",
            "Epoch: 246 [0/1762 (0%)]\tLoss: 1.922079\tLabel Loss: 0.002274\n",
            "Epoch: 246 [640/1762 (36%)]\tLoss: 1.900270\tLabel Loss: 0.002278\n",
            "Epoch: 246 [1280/1762 (71%)]\tLoss: 2.060716\tLabel Loss: 0.002233\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 246 \tVal Loss: 2.221441\n",
            "Epoch: 246 \tTest Loss: 2.077799\n",
            "\n",
            "Epoch: 247 [0/1762 (0%)]\tLoss: 2.340198\tLabel Loss: 0.002258\n",
            "Epoch: 247 [640/1762 (36%)]\tLoss: 2.171479\tLabel Loss: 0.002288\n",
            "Epoch: 247 [1280/1762 (71%)]\tLoss: 2.182521\tLabel Loss: 0.002281\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 247 \tVal Loss: 2.197471\n",
            "Epoch: 247 \tTest Loss: 2.066956\n",
            "\n",
            "Epoch: 248 [0/1762 (0%)]\tLoss: 2.063019\tLabel Loss: 0.002365\n",
            "Epoch: 248 [640/1762 (36%)]\tLoss: 2.079458\tLabel Loss: 0.002213\n",
            "Epoch: 248 [1280/1762 (71%)]\tLoss: 2.113071\tLabel Loss: 0.002401\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 248 \tVal Loss: 2.210148\n",
            "Epoch: 248 \tTest Loss: 2.070900\n",
            "\n",
            "Epoch: 249 [0/1762 (0%)]\tLoss: 2.183093\tLabel Loss: 0.002271\n",
            "Epoch: 249 [640/1762 (36%)]\tLoss: 2.047250\tLabel Loss: 0.002514\n",
            "Epoch: 249 [1280/1762 (71%)]\tLoss: 2.094455\tLabel Loss: 0.002305\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 249 \tVal Loss: 2.185124\n",
            "Epoch: 249 \tTest Loss: 2.063009\n",
            "\n",
            "Epoch: 250 [0/1762 (0%)]\tLoss: 1.997320\tLabel Loss: 0.002189\n",
            "Epoch: 250 [640/1762 (36%)]\tLoss: 2.089329\tLabel Loss: 0.002235\n",
            "Epoch: 250 [1280/1762 (71%)]\tLoss: 2.025411\tLabel Loss: 0.002344\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 250 \tVal Loss: 2.210381\n",
            "Epoch: 250 \tTest Loss: 2.076288\n",
            "\n",
            "Epoch: 251 [0/1762 (0%)]\tLoss: 2.298185\tLabel Loss: 0.002211\n",
            "Epoch: 251 [640/1762 (36%)]\tLoss: 2.117143\tLabel Loss: 0.002301\n",
            "Epoch: 251 [1280/1762 (71%)]\tLoss: 1.957311\tLabel Loss: 0.002211\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 251 \tVal Loss: 2.212035\n",
            "Epoch: 251 \tTest Loss: 2.078915\n",
            "\n",
            "Epoch: 252 [0/1762 (0%)]\tLoss: 1.952639\tLabel Loss: 0.002337\n",
            "Epoch: 252 [640/1762 (36%)]\tLoss: 2.283138\tLabel Loss: 0.002258\n",
            "Epoch: 252 [1280/1762 (71%)]\tLoss: 2.153439\tLabel Loss: 0.002170\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 252 \tVal Loss: 2.225135\n",
            "Epoch: 252 \tTest Loss: 2.084188\n",
            "\n",
            "Epoch: 253 [0/1762 (0%)]\tLoss: 2.095995\tLabel Loss: 0.002173\n",
            "Epoch: 253 [640/1762 (36%)]\tLoss: 2.103388\tLabel Loss: 0.002227\n",
            "Epoch: 253 [1280/1762 (71%)]\tLoss: 2.115695\tLabel Loss: 0.002110\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 253 \tVal Loss: 2.207999\n",
            "Epoch: 253 \tTest Loss: 2.076477\n",
            "\n",
            "Epoch: 254 [0/1762 (0%)]\tLoss: 2.108602\tLabel Loss: 0.002258\n",
            "Epoch: 254 [640/1762 (36%)]\tLoss: 1.971045\tLabel Loss: 0.002172\n",
            "Epoch: 254 [1280/1762 (71%)]\tLoss: 2.163378\tLabel Loss: 0.002250\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 254 \tVal Loss: 2.197734\n",
            "Epoch: 254 \tTest Loss: 2.064216\n",
            "\n",
            "Epoch: 255 [0/1762 (0%)]\tLoss: 1.889383\tLabel Loss: 0.002201\n",
            "Epoch: 255 [640/1762 (36%)]\tLoss: 1.925855\tLabel Loss: 0.002282\n",
            "Epoch: 255 [1280/1762 (71%)]\tLoss: 2.017433\tLabel Loss: 0.002120\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 255 \tVal Loss: 2.184507\n",
            "Epoch: 255 \tTest Loss: 2.056432\n",
            "\n",
            "Epoch: 256 [0/1762 (0%)]\tLoss: 2.275213\tLabel Loss: 0.002163\n",
            "Epoch: 256 [640/1762 (36%)]\tLoss: 2.115725\tLabel Loss: 0.002276\n",
            "Epoch: 256 [1280/1762 (71%)]\tLoss: 2.151760\tLabel Loss: 0.002357\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 256 \tVal Loss: 2.191085\n",
            "Epoch: 256 \tTest Loss: 2.061676\n",
            "\n",
            "Epoch: 257 [0/1762 (0%)]\tLoss: 1.938925\tLabel Loss: 0.002191\n",
            "Epoch: 257 [640/1762 (36%)]\tLoss: 2.138130\tLabel Loss: 0.002164\n",
            "Epoch: 257 [1280/1762 (71%)]\tLoss: 2.236100\tLabel Loss: 0.002175\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 257 \tVal Loss: 2.216561\n",
            "Epoch: 257 \tTest Loss: 2.077564\n",
            "\n",
            "Epoch: 258 [0/1762 (0%)]\tLoss: 2.266357\tLabel Loss: 0.002135\n",
            "Epoch: 258 [640/1762 (36%)]\tLoss: 2.095035\tLabel Loss: 0.002199\n",
            "Epoch: 258 [1280/1762 (71%)]\tLoss: 2.052536\tLabel Loss: 0.002221\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 258 \tVal Loss: 2.188766\n",
            "Epoch: 258 \tTest Loss: 2.059987\n",
            "\n",
            "Epoch: 259 [0/1762 (0%)]\tLoss: 2.087361\tLabel Loss: 0.002158\n",
            "Epoch: 259 [640/1762 (36%)]\tLoss: 2.141358\tLabel Loss: 0.002090\n",
            "Epoch: 259 [1280/1762 (71%)]\tLoss: 2.220571\tLabel Loss: 0.002127\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 259 \tVal Loss: 2.212161\n",
            "Epoch: 259 \tTest Loss: 2.077799\n",
            "\n",
            "Epoch: 260 [0/1762 (0%)]\tLoss: 2.153163\tLabel Loss: 0.002216\n",
            "Epoch: 260 [640/1762 (36%)]\tLoss: 2.024485\tLabel Loss: 0.002074\n",
            "Epoch: 260 [1280/1762 (71%)]\tLoss: 1.958054\tLabel Loss: 0.002065\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 260 \tVal Loss: 2.189571\n",
            "Epoch: 260 \tTest Loss: 2.066026\n",
            "\n",
            "Epoch: 261 [0/1762 (0%)]\tLoss: 2.206138\tLabel Loss: 0.002149\n",
            "Epoch: 261 [640/1762 (36%)]\tLoss: 2.053073\tLabel Loss: 0.002163\n",
            "Epoch: 261 [1280/1762 (71%)]\tLoss: 2.371464\tLabel Loss: 0.002076\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 261 \tVal Loss: 2.204647\n",
            "Epoch: 261 \tTest Loss: 2.072451\n",
            "\n",
            "Epoch: 262 [0/1762 (0%)]\tLoss: 2.172388\tLabel Loss: 0.002111\n",
            "Epoch: 262 [640/1762 (36%)]\tLoss: 2.089913\tLabel Loss: 0.002072\n",
            "Epoch: 262 [1280/1762 (71%)]\tLoss: 2.186237\tLabel Loss: 0.002096\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 262 \tVal Loss: 2.213050\n",
            "Epoch: 262 \tTest Loss: 2.084214\n",
            "\n",
            "Epoch: 263 [0/1762 (0%)]\tLoss: 2.150994\tLabel Loss: 0.002187\n",
            "Epoch: 263 [640/1762 (36%)]\tLoss: 2.129302\tLabel Loss: 0.002032\n",
            "Epoch: 263 [1280/1762 (71%)]\tLoss: 2.018936\tLabel Loss: 0.002063\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 263 \tVal Loss: 2.207629\n",
            "Epoch: 263 \tTest Loss: 2.073267\n",
            "\n",
            "Epoch: 264 [0/1762 (0%)]\tLoss: 1.962427\tLabel Loss: 0.002201\n",
            "Epoch: 264 [640/1762 (36%)]\tLoss: 1.972732\tLabel Loss: 0.002032\n",
            "Epoch: 264 [1280/1762 (71%)]\tLoss: 2.045798\tLabel Loss: 0.002062\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 264 \tVal Loss: 2.193602\n",
            "Epoch: 264 \tTest Loss: 2.062040\n",
            "\n",
            "Epoch: 265 [0/1762 (0%)]\tLoss: 1.951912\tLabel Loss: 0.002039\n",
            "Epoch: 265 [640/1762 (36%)]\tLoss: 2.224275\tLabel Loss: 0.002071\n",
            "Epoch: 265 [1280/1762 (71%)]\tLoss: 1.977126\tLabel Loss: 0.002006\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 265 \tVal Loss: 2.211452\n",
            "Epoch: 265 \tTest Loss: 2.072148\n",
            "\n",
            "Epoch: 266 [0/1762 (0%)]\tLoss: 2.047215\tLabel Loss: 0.002077\n",
            "Epoch: 266 [640/1762 (36%)]\tLoss: 2.070538\tLabel Loss: 0.002265\n",
            "Epoch: 266 [1280/1762 (71%)]\tLoss: 2.158216\tLabel Loss: 0.002066\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 266 \tVal Loss: 2.211768\n",
            "Epoch: 266 \tTest Loss: 2.077284\n",
            "\n",
            "Epoch: 267 [0/1762 (0%)]\tLoss: 2.274926\tLabel Loss: 0.002077\n",
            "Epoch: 267 [640/1762 (36%)]\tLoss: 2.037155\tLabel Loss: 0.002181\n",
            "Epoch: 267 [1280/1762 (71%)]\tLoss: 2.300776\tLabel Loss: 0.002074\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 267 \tVal Loss: 2.205888\n",
            "Epoch: 267 \tTest Loss: 2.069106\n",
            "\n",
            "Epoch: 268 [0/1762 (0%)]\tLoss: 2.025874\tLabel Loss: 0.002053\n",
            "Epoch: 268 [640/1762 (36%)]\tLoss: 2.203503\tLabel Loss: 0.002045\n",
            "Epoch: 268 [1280/1762 (71%)]\tLoss: 2.040926\tLabel Loss: 0.002165\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 268 \tVal Loss: 2.206457\n",
            "Epoch: 268 \tTest Loss: 2.075813\n",
            "\n",
            "Epoch: 269 [0/1762 (0%)]\tLoss: 2.177277\tLabel Loss: 0.002028\n",
            "Epoch: 269 [640/1762 (36%)]\tLoss: 2.073370\tLabel Loss: 0.002005\n",
            "Epoch: 269 [1280/1762 (71%)]\tLoss: 2.186239\tLabel Loss: 0.002004\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 269 \tVal Loss: 2.204122\n",
            "Epoch: 269 \tTest Loss: 2.072021\n",
            "\n",
            "Epoch: 270 [0/1762 (0%)]\tLoss: 2.259888\tLabel Loss: 0.002148\n",
            "Epoch: 270 [640/1762 (36%)]\tLoss: 2.097396\tLabel Loss: 0.002008\n",
            "Epoch: 270 [1280/1762 (71%)]\tLoss: 2.015401\tLabel Loss: 0.002005\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 270 \tVal Loss: 2.183335\n",
            "Epoch: 270 \tTest Loss: 2.061330\n",
            "\n",
            "Epoch: 271 [0/1762 (0%)]\tLoss: 2.102775\tLabel Loss: 0.001988\n",
            "Epoch: 271 [640/1762 (36%)]\tLoss: 2.110185\tLabel Loss: 0.002031\n",
            "Epoch: 271 [1280/1762 (71%)]\tLoss: 2.121739\tLabel Loss: 0.001954\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 271 \tVal Loss: 2.195660\n",
            "Epoch: 271 \tTest Loss: 2.069366\n",
            "\n",
            "Epoch: 272 [0/1762 (0%)]\tLoss: 2.110543\tLabel Loss: 0.001967\n",
            "Epoch: 272 [640/1762 (36%)]\tLoss: 1.988536\tLabel Loss: 0.002016\n",
            "Epoch: 272 [1280/1762 (71%)]\tLoss: 2.102326\tLabel Loss: 0.001983\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 272 \tVal Loss: 2.204224\n",
            "Epoch: 272 \tTest Loss: 2.074243\n",
            "\n",
            "Epoch: 273 [0/1762 (0%)]\tLoss: 2.096282\tLabel Loss: 0.001965\n",
            "Epoch: 273 [640/1762 (36%)]\tLoss: 1.933984\tLabel Loss: 0.002048\n",
            "Epoch: 273 [1280/1762 (71%)]\tLoss: 2.053196\tLabel Loss: 0.002046\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 273 \tVal Loss: 2.212672\n",
            "Epoch: 273 \tTest Loss: 2.075825\n",
            "\n",
            "Epoch: 274 [0/1762 (0%)]\tLoss: 2.204868\tLabel Loss: 0.002088\n",
            "Epoch: 274 [640/1762 (36%)]\tLoss: 2.160630\tLabel Loss: 0.002045\n",
            "Epoch: 274 [1280/1762 (71%)]\tLoss: 2.053213\tLabel Loss: 0.002031\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 274 \tVal Loss: 2.184964\n",
            "Epoch: 274 \tTest Loss: 2.058940\n",
            "\n",
            "Epoch: 275 [0/1762 (0%)]\tLoss: 2.192805\tLabel Loss: 0.002026\n",
            "Epoch: 275 [640/1762 (36%)]\tLoss: 2.377844\tLabel Loss: 0.002050\n",
            "Epoch: 275 [1280/1762 (71%)]\tLoss: 1.928006\tLabel Loss: 0.001914\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 275 \tVal Loss: 2.212370\n",
            "Epoch: 275 \tTest Loss: 2.068465\n",
            "\n",
            "Epoch: 276 [0/1762 (0%)]\tLoss: 1.940303\tLabel Loss: 0.001932\n",
            "Epoch: 276 [640/1762 (36%)]\tLoss: 2.063631\tLabel Loss: 0.002036\n",
            "Epoch: 276 [1280/1762 (71%)]\tLoss: 2.087426\tLabel Loss: 0.002064\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 276 \tVal Loss: 2.204333\n",
            "Epoch: 276 \tTest Loss: 2.070334\n",
            "\n",
            "Epoch: 277 [0/1762 (0%)]\tLoss: 2.016198\tLabel Loss: 0.001899\n",
            "Epoch: 277 [640/1762 (36%)]\tLoss: 2.075473\tLabel Loss: 0.001941\n",
            "Epoch: 277 [1280/1762 (71%)]\tLoss: 1.973945\tLabel Loss: 0.002009\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 277 \tVal Loss: 2.211030\n",
            "Epoch: 277 \tTest Loss: 2.073856\n",
            "\n",
            "Epoch: 278 [0/1762 (0%)]\tLoss: 2.156936\tLabel Loss: 0.001964\n",
            "Epoch: 278 [640/1762 (36%)]\tLoss: 1.951355\tLabel Loss: 0.001866\n",
            "Epoch: 278 [1280/1762 (71%)]\tLoss: 2.105415\tLabel Loss: 0.001917\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 278 \tVal Loss: 2.199496\n",
            "Epoch: 278 \tTest Loss: 2.075953\n",
            "\n",
            "Epoch: 279 [0/1762 (0%)]\tLoss: 2.073381\tLabel Loss: 0.001984\n",
            "Epoch: 279 [640/1762 (36%)]\tLoss: 2.275638\tLabel Loss: 0.002036\n",
            "Epoch: 279 [1280/1762 (71%)]\tLoss: 2.157472\tLabel Loss: 0.001884\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 279 \tVal Loss: 2.198314\n",
            "Epoch: 279 \tTest Loss: 2.068282\n",
            "\n",
            "Epoch: 280 [0/1762 (0%)]\tLoss: 1.946710\tLabel Loss: 0.002287\n",
            "Epoch: 280 [640/1762 (36%)]\tLoss: 2.191096\tLabel Loss: 0.002113\n",
            "Epoch: 280 [1280/1762 (71%)]\tLoss: 2.034437\tLabel Loss: 0.001921\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 280 \tVal Loss: 2.193572\n",
            "Epoch: 280 \tTest Loss: 2.065456\n",
            "\n",
            "Epoch: 281 [0/1762 (0%)]\tLoss: 2.058894\tLabel Loss: 0.002114\n",
            "Epoch: 281 [640/1762 (36%)]\tLoss: 1.925725\tLabel Loss: 0.001883\n",
            "Epoch: 281 [1280/1762 (71%)]\tLoss: 2.115818\tLabel Loss: 0.002091\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 281 \tVal Loss: 2.199396\n",
            "Epoch: 281 \tTest Loss: 2.061139\n",
            "\n",
            "Epoch: 282 [0/1762 (0%)]\tLoss: 2.231783\tLabel Loss: 0.001978\n",
            "Epoch: 282 [640/1762 (36%)]\tLoss: 2.108247\tLabel Loss: 0.001876\n",
            "Epoch: 282 [1280/1762 (71%)]\tLoss: 2.025410\tLabel Loss: 0.001894\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 282 \tVal Loss: 2.194359\n",
            "Epoch: 282 \tTest Loss: 2.056644\n",
            "\n",
            "Epoch: 283 [0/1762 (0%)]\tLoss: 1.935622\tLabel Loss: 0.002009\n",
            "Epoch: 283 [640/1762 (36%)]\tLoss: 2.010860\tLabel Loss: 0.002100\n",
            "Epoch: 283 [1280/1762 (71%)]\tLoss: 2.103529\tLabel Loss: 0.002063\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 283 \tVal Loss: 2.205501\n",
            "Epoch: 283 \tTest Loss: 2.074599\n",
            "\n",
            "Epoch: 284 [0/1762 (0%)]\tLoss: 1.937394\tLabel Loss: 0.001860\n",
            "Epoch: 284 [640/1762 (36%)]\tLoss: 1.919962\tLabel Loss: 0.001872\n",
            "Epoch: 284 [1280/1762 (71%)]\tLoss: 1.959706\tLabel Loss: 0.001837\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 284 \tVal Loss: 2.197281\n",
            "Epoch: 284 \tTest Loss: 2.078817\n",
            "\n",
            "Epoch: 285 [0/1762 (0%)]\tLoss: 2.076525\tLabel Loss: 0.001858\n",
            "Epoch: 285 [640/1762 (36%)]\tLoss: 2.168948\tLabel Loss: 0.001873\n",
            "Epoch: 285 [1280/1762 (71%)]\tLoss: 2.114634\tLabel Loss: 0.001819\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 285 \tVal Loss: 2.179930\n",
            "Epoch: 285 \tTest Loss: 2.054856\n",
            "\n",
            "Epoch: 286 [0/1762 (0%)]\tLoss: 1.848182\tLabel Loss: 0.001791\n",
            "Epoch: 286 [640/1762 (36%)]\tLoss: 2.142827\tLabel Loss: 0.001884\n",
            "Epoch: 286 [1280/1762 (71%)]\tLoss: 2.218270\tLabel Loss: 0.001813\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 286 \tVal Loss: 2.190784\n",
            "Epoch: 286 \tTest Loss: 2.054086\n",
            "\n",
            "Epoch: 287 [0/1762 (0%)]\tLoss: 2.000264\tLabel Loss: 0.001836\n",
            "Epoch: 287 [640/1762 (36%)]\tLoss: 2.077763\tLabel Loss: 0.001789\n",
            "Epoch: 287 [1280/1762 (71%)]\tLoss: 2.018310\tLabel Loss: 0.001818\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 287 \tVal Loss: 2.182566\n",
            "Epoch: 287 \tTest Loss: 2.056278\n",
            "\n",
            "Epoch: 288 [0/1762 (0%)]\tLoss: 2.106538\tLabel Loss: 0.001889\n",
            "Epoch: 288 [640/1762 (36%)]\tLoss: 2.212795\tLabel Loss: 0.001952\n",
            "Epoch: 288 [1280/1762 (71%)]\tLoss: 1.993350\tLabel Loss: 0.002039\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 288 \tVal Loss: 2.206092\n",
            "Epoch: 288 \tTest Loss: 2.079255\n",
            "\n",
            "Epoch: 289 [0/1762 (0%)]\tLoss: 2.143968\tLabel Loss: 0.001806\n",
            "Epoch: 289 [640/1762 (36%)]\tLoss: 2.118240\tLabel Loss: 0.001898\n",
            "Epoch: 289 [1280/1762 (71%)]\tLoss: 2.065073\tLabel Loss: 0.002098\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 289 \tVal Loss: 2.192363\n",
            "Epoch: 289 \tTest Loss: 2.059137\n",
            "\n",
            "Epoch: 290 [0/1762 (0%)]\tLoss: 1.917750\tLabel Loss: 0.001824\n",
            "Epoch: 290 [640/1762 (36%)]\tLoss: 2.135063\tLabel Loss: 0.001798\n",
            "Epoch: 290 [1280/1762 (71%)]\tLoss: 1.963756\tLabel Loss: 0.002043\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 290 \tVal Loss: 2.204396\n",
            "Epoch: 290 \tTest Loss: 2.076795\n",
            "\n",
            "Epoch: 291 [0/1762 (0%)]\tLoss: 2.065272\tLabel Loss: 0.001890\n",
            "Epoch: 291 [640/1762 (36%)]\tLoss: 2.141571\tLabel Loss: 0.001777\n",
            "Epoch: 291 [1280/1762 (71%)]\tLoss: 2.332849\tLabel Loss: 0.001805\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 291 \tVal Loss: 2.204447\n",
            "Epoch: 291 \tTest Loss: 2.068533\n",
            "\n",
            "Epoch: 292 [0/1762 (0%)]\tLoss: 1.998138\tLabel Loss: 0.001797\n",
            "Epoch: 292 [640/1762 (36%)]\tLoss: 2.136270\tLabel Loss: 0.001771\n",
            "Epoch: 292 [1280/1762 (71%)]\tLoss: 2.022347\tLabel Loss: 0.001808\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 292 \tVal Loss: 2.188095\n",
            "Epoch: 292 \tTest Loss: 2.058301\n",
            "\n",
            "Epoch: 293 [0/1762 (0%)]\tLoss: 2.025504\tLabel Loss: 0.001803\n",
            "Epoch: 293 [640/1762 (36%)]\tLoss: 2.277706\tLabel Loss: 0.001751\n",
            "Epoch: 293 [1280/1762 (71%)]\tLoss: 2.036174\tLabel Loss: 0.001768\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 293 \tVal Loss: 2.198862\n",
            "Epoch: 293 \tTest Loss: 2.070903\n",
            "\n",
            "Epoch: 294 [0/1762 (0%)]\tLoss: 2.146967\tLabel Loss: 0.001741\n",
            "Epoch: 294 [640/1762 (36%)]\tLoss: 2.052396\tLabel Loss: 0.001934\n",
            "Epoch: 294 [1280/1762 (71%)]\tLoss: 2.075819\tLabel Loss: 0.001760\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 294 \tVal Loss: 2.211464\n",
            "Epoch: 294 \tTest Loss: 2.068080\n",
            "\n",
            "Epoch: 295 [0/1762 (0%)]\tLoss: 2.479876\tLabel Loss: 0.001774\n",
            "Epoch: 295 [640/1762 (36%)]\tLoss: 2.089525\tLabel Loss: 0.001824\n",
            "Epoch: 295 [1280/1762 (71%)]\tLoss: 2.169541\tLabel Loss: 0.001755\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 295 \tVal Loss: 2.220557\n",
            "Epoch: 295 \tTest Loss: 2.073017\n",
            "\n",
            "Epoch: 296 [0/1762 (0%)]\tLoss: 2.132516\tLabel Loss: 0.001748\n",
            "Epoch: 296 [640/1762 (36%)]\tLoss: 2.009400\tLabel Loss: 0.001733\n",
            "Epoch: 296 [1280/1762 (71%)]\tLoss: 1.916333\tLabel Loss: 0.001720\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 296 \tVal Loss: 2.194517\n",
            "Epoch: 296 \tTest Loss: 2.065735\n",
            "\n",
            "Epoch: 297 [0/1762 (0%)]\tLoss: 2.215442\tLabel Loss: 0.001744\n",
            "Epoch: 297 [640/1762 (36%)]\tLoss: 2.311854\tLabel Loss: 0.001835\n",
            "Epoch: 297 [1280/1762 (71%)]\tLoss: 2.155848\tLabel Loss: 0.001705\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 297 \tVal Loss: 2.207781\n",
            "Epoch: 297 \tTest Loss: 2.074154\n",
            "\n",
            "Epoch: 298 [0/1762 (0%)]\tLoss: 2.071187\tLabel Loss: 0.001829\n",
            "Epoch: 298 [640/1762 (36%)]\tLoss: 2.105159\tLabel Loss: 0.001854\n",
            "Epoch: 298 [1280/1762 (71%)]\tLoss: 1.959557\tLabel Loss: 0.001723\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 298 \tVal Loss: 2.192871\n",
            "Epoch: 298 \tTest Loss: 2.066755\n",
            "\n",
            "Epoch: 299 [0/1762 (0%)]\tLoss: 2.243029\tLabel Loss: 0.001748\n",
            "Epoch: 299 [640/1762 (36%)]\tLoss: 2.126292\tLabel Loss: 0.001703\n",
            "Epoch: 299 [1280/1762 (71%)]\tLoss: 2.173779\tLabel Loss: 0.001723\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 299 \tVal Loss: 2.206330\n",
            "Epoch: 299 \tTest Loss: 2.067528\n",
            "\n",
            "Epoch: 300 [0/1762 (0%)]\tLoss: 2.157210\tLabel Loss: 0.001751\n",
            "Epoch: 300 [640/1762 (36%)]\tLoss: 2.063991\tLabel Loss: 0.001703\n",
            "Epoch: 300 [1280/1762 (71%)]\tLoss: 1.989683\tLabel Loss: 0.001763\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 300 \tVal Loss: 2.198331\n",
            "Epoch: 300 \tTest Loss: 2.066946\n",
            "\n",
            "Epoch: 301 [0/1762 (0%)]\tLoss: 1.938312\tLabel Loss: 0.001698\n",
            "Epoch: 301 [640/1762 (36%)]\tLoss: 2.042897\tLabel Loss: 0.001692\n",
            "Epoch: 301 [1280/1762 (71%)]\tLoss: 1.958132\tLabel Loss: 0.001695\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 301 \tVal Loss: 2.190187\n",
            "Epoch: 301 \tTest Loss: 2.060515\n",
            "\n",
            "Epoch: 302 [0/1762 (0%)]\tLoss: 2.010168\tLabel Loss: 0.001679\n",
            "Epoch: 302 [640/1762 (36%)]\tLoss: 2.054874\tLabel Loss: 0.001702\n",
            "Epoch: 302 [1280/1762 (71%)]\tLoss: 1.995536\tLabel Loss: 0.001751\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 302 \tVal Loss: 2.191770\n",
            "Epoch: 302 \tTest Loss: 2.061006\n",
            "\n",
            "Epoch: 303 [0/1762 (0%)]\tLoss: 1.854722\tLabel Loss: 0.001736\n",
            "Epoch: 303 [640/1762 (36%)]\tLoss: 2.219922\tLabel Loss: 0.001743\n",
            "Epoch: 303 [1280/1762 (71%)]\tLoss: 2.028284\tLabel Loss: 0.001782\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 303 \tVal Loss: 2.243242\n",
            "Epoch: 303 \tTest Loss: 2.101382\n",
            "\n",
            "Epoch: 304 [0/1762 (0%)]\tLoss: 2.028984\tLabel Loss: 0.001905\n",
            "Epoch: 304 [640/1762 (36%)]\tLoss: 2.147122\tLabel Loss: 0.001843\n",
            "Epoch: 304 [1280/1762 (71%)]\tLoss: 2.042121\tLabel Loss: 0.001765\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 304 \tVal Loss: 2.222966\n",
            "Epoch: 304 \tTest Loss: 2.090224\n",
            "\n",
            "Epoch: 305 [0/1762 (0%)]\tLoss: 2.264074\tLabel Loss: 0.001800\n",
            "Epoch: 305 [640/1762 (36%)]\tLoss: 2.224168\tLabel Loss: 0.001812\n",
            "Epoch: 305 [1280/1762 (71%)]\tLoss: 2.223687\tLabel Loss: 0.001753\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 305 \tVal Loss: 2.198599\n",
            "Epoch: 305 \tTest Loss: 2.066222\n",
            "\n",
            "Epoch: 306 [0/1762 (0%)]\tLoss: 1.943955\tLabel Loss: 0.001721\n",
            "Epoch: 306 [640/1762 (36%)]\tLoss: 2.230409\tLabel Loss: 0.001763\n",
            "Epoch: 306 [1280/1762 (71%)]\tLoss: 1.980680\tLabel Loss: 0.001812\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 306 \tVal Loss: 2.189579\n",
            "Epoch: 306 \tTest Loss: 2.055280\n",
            "\n",
            "Epoch: 307 [0/1762 (0%)]\tLoss: 2.062838\tLabel Loss: 0.001674\n",
            "Epoch: 307 [640/1762 (36%)]\tLoss: 2.115186\tLabel Loss: 0.001678\n",
            "Epoch: 307 [1280/1762 (71%)]\tLoss: 2.275342\tLabel Loss: 0.001690\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 307 \tVal Loss: 2.201550\n",
            "Epoch: 307 \tTest Loss: 2.069438\n",
            "\n",
            "Epoch: 308 [0/1762 (0%)]\tLoss: 1.855973\tLabel Loss: 0.001647\n",
            "Epoch: 308 [640/1762 (36%)]\tLoss: 2.242395\tLabel Loss: 0.001796\n",
            "Epoch: 308 [1280/1762 (71%)]\tLoss: 2.145695\tLabel Loss: 0.001806\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 308 \tVal Loss: 2.209287\n",
            "Epoch: 308 \tTest Loss: 2.075257\n",
            "\n",
            "Epoch: 309 [0/1762 (0%)]\tLoss: 2.225363\tLabel Loss: 0.001718\n",
            "Epoch: 309 [640/1762 (36%)]\tLoss: 1.937122\tLabel Loss: 0.001773\n",
            "Epoch: 309 [1280/1762 (71%)]\tLoss: 2.140852\tLabel Loss: 0.001668\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 309 \tVal Loss: 2.198833\n",
            "Epoch: 309 \tTest Loss: 2.056665\n",
            "\n",
            "Epoch: 310 [0/1762 (0%)]\tLoss: 2.107269\tLabel Loss: 0.001633\n",
            "Epoch: 310 [640/1762 (36%)]\tLoss: 2.095207\tLabel Loss: 0.001674\n",
            "Epoch: 310 [1280/1762 (71%)]\tLoss: 2.081814\tLabel Loss: 0.001679\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 310 \tVal Loss: 2.210521\n",
            "Epoch: 310 \tTest Loss: 2.071100\n",
            "\n",
            "Epoch: 311 [0/1762 (0%)]\tLoss: 2.037275\tLabel Loss: 0.001629\n",
            "Epoch: 311 [640/1762 (36%)]\tLoss: 2.224822\tLabel Loss: 0.001656\n",
            "Epoch: 311 [1280/1762 (71%)]\tLoss: 2.032309\tLabel Loss: 0.001657\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 311 \tVal Loss: 2.201081\n",
            "Epoch: 311 \tTest Loss: 2.064329\n",
            "\n",
            "Epoch: 312 [0/1762 (0%)]\tLoss: 2.204743\tLabel Loss: 0.001787\n",
            "Epoch: 312 [640/1762 (36%)]\tLoss: 2.161454\tLabel Loss: 0.001675\n",
            "Epoch: 312 [1280/1762 (71%)]\tLoss: 2.260120\tLabel Loss: 0.001631\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 312 \tVal Loss: 2.178733\n",
            "Epoch: 312 \tTest Loss: 2.065060\n",
            "\n",
            "Epoch: 313 [0/1762 (0%)]\tLoss: 2.044683\tLabel Loss: 0.001652\n",
            "Epoch: 313 [640/1762 (36%)]\tLoss: 2.009754\tLabel Loss: 0.001644\n",
            "Epoch: 313 [1280/1762 (71%)]\tLoss: 2.207797\tLabel Loss: 0.001635\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 313 \tVal Loss: 2.206051\n",
            "Epoch: 313 \tTest Loss: 2.072605\n",
            "\n",
            "Epoch: 314 [0/1762 (0%)]\tLoss: 2.196268\tLabel Loss: 0.001608\n",
            "Epoch: 314 [640/1762 (36%)]\tLoss: 1.911738\tLabel Loss: 0.001697\n",
            "Epoch: 314 [1280/1762 (71%)]\tLoss: 2.233328\tLabel Loss: 0.001701\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 314 \tVal Loss: 2.185874\n",
            "Epoch: 314 \tTest Loss: 2.053970\n",
            "\n",
            "Epoch: 315 [0/1762 (0%)]\tLoss: 2.178553\tLabel Loss: 0.001692\n",
            "Epoch: 315 [640/1762 (36%)]\tLoss: 1.895452\tLabel Loss: 0.001628\n",
            "Epoch: 315 [1280/1762 (71%)]\tLoss: 2.192555\tLabel Loss: 0.001799\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 315 \tVal Loss: 2.180887\n",
            "Epoch: 315 \tTest Loss: 2.056306\n",
            "\n",
            "Epoch: 316 [0/1762 (0%)]\tLoss: 2.249673\tLabel Loss: 0.001658\n",
            "Epoch: 316 [640/1762 (36%)]\tLoss: 1.886168\tLabel Loss: 0.001644\n",
            "Epoch: 316 [1280/1762 (71%)]\tLoss: 2.019687\tLabel Loss: 0.001597\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 316 \tVal Loss: 2.206448\n",
            "Epoch: 316 \tTest Loss: 2.076065\n",
            "\n",
            "Epoch: 317 [0/1762 (0%)]\tLoss: 2.057987\tLabel Loss: 0.001633\n",
            "Epoch: 317 [640/1762 (36%)]\tLoss: 2.183819\tLabel Loss: 0.001657\n",
            "Epoch: 317 [1280/1762 (71%)]\tLoss: 2.264759\tLabel Loss: 0.001721\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 317 \tVal Loss: 2.188563\n",
            "Epoch: 317 \tTest Loss: 2.062079\n",
            "\n",
            "Epoch: 318 [0/1762 (0%)]\tLoss: 1.929552\tLabel Loss: 0.001620\n",
            "Epoch: 318 [640/1762 (36%)]\tLoss: 2.383615\tLabel Loss: 0.001648\n",
            "Epoch: 318 [1280/1762 (71%)]\tLoss: 2.026821\tLabel Loss: 0.001569\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 318 \tVal Loss: 2.197655\n",
            "Epoch: 318 \tTest Loss: 2.067457\n",
            "\n",
            "Epoch: 319 [0/1762 (0%)]\tLoss: 1.966875\tLabel Loss: 0.001643\n",
            "Epoch: 319 [640/1762 (36%)]\tLoss: 2.115849\tLabel Loss: 0.001638\n",
            "Epoch: 319 [1280/1762 (71%)]\tLoss: 2.079468\tLabel Loss: 0.001574\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 319 \tVal Loss: 2.209119\n",
            "Epoch: 319 \tTest Loss: 2.074564\n",
            "\n",
            "Epoch: 320 [0/1762 (0%)]\tLoss: 2.206021\tLabel Loss: 0.001610\n",
            "Epoch: 320 [640/1762 (36%)]\tLoss: 2.200608\tLabel Loss: 0.001541\n",
            "Epoch: 320 [1280/1762 (71%)]\tLoss: 2.175199\tLabel Loss: 0.001586\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 320 \tVal Loss: 2.209837\n",
            "Epoch: 320 \tTest Loss: 2.075366\n",
            "\n",
            "Epoch: 321 [0/1762 (0%)]\tLoss: 2.067838\tLabel Loss: 0.001552\n",
            "Epoch: 321 [640/1762 (36%)]\tLoss: 2.293990\tLabel Loss: 0.001603\n",
            "Epoch: 321 [1280/1762 (71%)]\tLoss: 2.073904\tLabel Loss: 0.001528\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 321 \tVal Loss: 2.192764\n",
            "Epoch: 321 \tTest Loss: 2.064517\n",
            "\n",
            "Epoch: 322 [0/1762 (0%)]\tLoss: 2.128978\tLabel Loss: 0.001641\n",
            "Epoch: 322 [640/1762 (36%)]\tLoss: 2.136787\tLabel Loss: 0.001624\n",
            "Epoch: 322 [1280/1762 (71%)]\tLoss: 2.369265\tLabel Loss: 0.001552\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 322 \tVal Loss: 2.197939\n",
            "Epoch: 322 \tTest Loss: 2.063947\n",
            "\n",
            "Epoch: 323 [0/1762 (0%)]\tLoss: 2.108953\tLabel Loss: 0.001698\n",
            "Epoch: 323 [640/1762 (36%)]\tLoss: 2.075898\tLabel Loss: 0.001581\n",
            "Epoch: 323 [1280/1762 (71%)]\tLoss: 2.134092\tLabel Loss: 0.001621\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 323 \tVal Loss: 2.201584\n",
            "Epoch: 323 \tTest Loss: 2.061065\n",
            "\n",
            "Epoch: 324 [0/1762 (0%)]\tLoss: 2.263307\tLabel Loss: 0.001701\n",
            "Epoch: 324 [640/1762 (36%)]\tLoss: 2.064695\tLabel Loss: 0.001666\n",
            "Epoch: 324 [1280/1762 (71%)]\tLoss: 2.200631\tLabel Loss: 0.001595\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 324 \tVal Loss: 2.188854\n",
            "Epoch: 324 \tTest Loss: 2.063324\n",
            "\n",
            "Epoch: 325 [0/1762 (0%)]\tLoss: 2.178033\tLabel Loss: 0.001533\n",
            "Epoch: 325 [640/1762 (36%)]\tLoss: 1.907958\tLabel Loss: 0.001573\n",
            "Epoch: 325 [1280/1762 (71%)]\tLoss: 2.071261\tLabel Loss: 0.001801\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 325 \tVal Loss: 2.200457\n",
            "Epoch: 325 \tTest Loss: 2.069985\n",
            "\n",
            "Epoch: 326 [0/1762 (0%)]\tLoss: 2.250722\tLabel Loss: 0.001720\n",
            "Epoch: 326 [640/1762 (36%)]\tLoss: 2.031795\tLabel Loss: 0.001551\n",
            "Epoch: 326 [1280/1762 (71%)]\tLoss: 2.247950\tLabel Loss: 0.001537\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 326 \tVal Loss: 2.187611\n",
            "Epoch: 326 \tTest Loss: 2.051386\n",
            "\n",
            "Epoch: 327 [0/1762 (0%)]\tLoss: 2.275837\tLabel Loss: 0.001525\n",
            "Epoch: 327 [640/1762 (36%)]\tLoss: 1.925010\tLabel Loss: 0.001582\n",
            "Epoch: 327 [1280/1762 (71%)]\tLoss: 2.167275\tLabel Loss: 0.001523\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 327 \tVal Loss: 2.190792\n",
            "Epoch: 327 \tTest Loss: 2.069877\n",
            "\n",
            "Epoch: 328 [0/1762 (0%)]\tLoss: 2.027351\tLabel Loss: 0.001625\n",
            "Epoch: 328 [640/1762 (36%)]\tLoss: 2.114416\tLabel Loss: 0.001569\n",
            "Epoch: 328 [1280/1762 (71%)]\tLoss: 2.326844\tLabel Loss: 0.001538\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 328 \tVal Loss: 2.186532\n",
            "Epoch: 328 \tTest Loss: 2.062497\n",
            "\n",
            "Epoch: 329 [0/1762 (0%)]\tLoss: 2.050086\tLabel Loss: 0.001589\n",
            "Epoch: 329 [640/1762 (36%)]\tLoss: 2.306091\tLabel Loss: 0.001720\n",
            "Epoch: 329 [1280/1762 (71%)]\tLoss: 2.078937\tLabel Loss: 0.001617\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 329 \tVal Loss: 2.203755\n",
            "Epoch: 329 \tTest Loss: 2.066530\n",
            "\n",
            "Epoch: 330 [0/1762 (0%)]\tLoss: 2.322058\tLabel Loss: 0.001513\n",
            "Epoch: 330 [640/1762 (36%)]\tLoss: 2.033907\tLabel Loss: 0.001557\n",
            "Epoch: 330 [1280/1762 (71%)]\tLoss: 1.835968\tLabel Loss: 0.001526\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 330 \tVal Loss: 2.184729\n",
            "Epoch: 330 \tTest Loss: 2.052874\n",
            "\n",
            "Epoch: 331 [0/1762 (0%)]\tLoss: 1.952452\tLabel Loss: 0.001510\n",
            "Epoch: 331 [640/1762 (36%)]\tLoss: 2.097301\tLabel Loss: 0.001533\n",
            "Epoch: 331 [1280/1762 (71%)]\tLoss: 2.278274\tLabel Loss: 0.001658\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 331 \tVal Loss: 2.199046\n",
            "Epoch: 331 \tTest Loss: 2.061554\n",
            "\n",
            "Epoch: 332 [0/1762 (0%)]\tLoss: 2.005096\tLabel Loss: 0.001698\n",
            "Epoch: 332 [640/1762 (36%)]\tLoss: 1.946346\tLabel Loss: 0.001709\n",
            "Epoch: 332 [1280/1762 (71%)]\tLoss: 2.112288\tLabel Loss: 0.001541\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 332 \tVal Loss: 2.195046\n",
            "Epoch: 332 \tTest Loss: 2.066979\n",
            "\n",
            "Epoch: 333 [0/1762 (0%)]\tLoss: 1.969362\tLabel Loss: 0.001525\n",
            "Epoch: 333 [640/1762 (36%)]\tLoss: 2.189659\tLabel Loss: 0.001499\n",
            "Epoch: 333 [1280/1762 (71%)]\tLoss: 2.215102\tLabel Loss: 0.001549\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 333 \tVal Loss: 2.184297\n",
            "Epoch: 333 \tTest Loss: 2.056590\n",
            "\n",
            "Epoch: 334 [0/1762 (0%)]\tLoss: 1.991630\tLabel Loss: 0.001572\n",
            "Epoch: 334 [640/1762 (36%)]\tLoss: 2.174858\tLabel Loss: 0.001556\n",
            "Epoch: 334 [1280/1762 (71%)]\tLoss: 2.141202\tLabel Loss: 0.001555\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 334 \tVal Loss: 2.173526\n",
            "Epoch: 334 \tTest Loss: 2.050893\n",
            "\n",
            "Epoch: 335 [0/1762 (0%)]\tLoss: 1.955655\tLabel Loss: 0.001611\n",
            "Epoch: 335 [640/1762 (36%)]\tLoss: 2.061663\tLabel Loss: 0.001607\n",
            "Epoch: 335 [1280/1762 (71%)]\tLoss: 2.371428\tLabel Loss: 0.001521\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 335 \tVal Loss: 2.183103\n",
            "Epoch: 335 \tTest Loss: 2.059614\n",
            "\n",
            "Epoch: 336 [0/1762 (0%)]\tLoss: 2.234590\tLabel Loss: 0.001553\n",
            "Epoch: 336 [640/1762 (36%)]\tLoss: 1.964820\tLabel Loss: 0.001544\n",
            "Epoch: 336 [1280/1762 (71%)]\tLoss: 2.056893\tLabel Loss: 0.001480\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 336 \tVal Loss: 2.178946\n",
            "Epoch: 336 \tTest Loss: 2.061768\n",
            "\n",
            "Epoch: 337 [0/1762 (0%)]\tLoss: 2.111628\tLabel Loss: 0.001448\n",
            "Epoch: 337 [640/1762 (36%)]\tLoss: 2.040813\tLabel Loss: 0.001494\n",
            "Epoch: 337 [1280/1762 (71%)]\tLoss: 2.193442\tLabel Loss: 0.001488\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 337 \tVal Loss: 2.196256\n",
            "Epoch: 337 \tTest Loss: 2.069629\n",
            "\n",
            "Epoch: 338 [0/1762 (0%)]\tLoss: 2.126627\tLabel Loss: 0.001554\n",
            "Epoch: 338 [640/1762 (36%)]\tLoss: 2.001328\tLabel Loss: 0.001524\n",
            "Epoch: 338 [1280/1762 (71%)]\tLoss: 2.129305\tLabel Loss: 0.001487\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 338 \tVal Loss: 2.190842\n",
            "Epoch: 338 \tTest Loss: 2.056274\n",
            "\n",
            "Epoch: 339 [0/1762 (0%)]\tLoss: 1.875159\tLabel Loss: 0.001468\n",
            "Epoch: 339 [640/1762 (36%)]\tLoss: 2.175694\tLabel Loss: 0.001465\n",
            "Epoch: 339 [1280/1762 (71%)]\tLoss: 2.136291\tLabel Loss: 0.001587\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 339 \tVal Loss: 2.189083\n",
            "Epoch: 339 \tTest Loss: 2.056874\n",
            "\n",
            "Epoch: 340 [0/1762 (0%)]\tLoss: 2.141575\tLabel Loss: 0.001504\n",
            "Epoch: 340 [640/1762 (36%)]\tLoss: 2.102338\tLabel Loss: 0.001447\n",
            "Epoch: 340 [1280/1762 (71%)]\tLoss: 1.912833\tLabel Loss: 0.001463\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 340 \tVal Loss: 2.199164\n",
            "Epoch: 340 \tTest Loss: 2.071439\n",
            "\n",
            "Epoch: 341 [0/1762 (0%)]\tLoss: 2.101670\tLabel Loss: 0.001516\n",
            "Epoch: 341 [640/1762 (36%)]\tLoss: 2.116067\tLabel Loss: 0.001479\n",
            "Epoch: 341 [1280/1762 (71%)]\tLoss: 2.268226\tLabel Loss: 0.001462\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 341 \tVal Loss: 2.191452\n",
            "Epoch: 341 \tTest Loss: 2.057835\n",
            "\n",
            "Epoch: 342 [0/1762 (0%)]\tLoss: 2.231490\tLabel Loss: 0.001428\n",
            "Epoch: 342 [640/1762 (36%)]\tLoss: 2.112957\tLabel Loss: 0.001477\n",
            "Epoch: 342 [1280/1762 (71%)]\tLoss: 2.121386\tLabel Loss: 0.001689\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 342 \tVal Loss: 2.190106\n",
            "Epoch: 342 \tTest Loss: 2.053698\n",
            "\n",
            "Epoch: 343 [0/1762 (0%)]\tLoss: 2.173791\tLabel Loss: 0.001425\n",
            "Epoch: 343 [640/1762 (36%)]\tLoss: 2.186688\tLabel Loss: 0.001431\n",
            "Epoch: 343 [1280/1762 (71%)]\tLoss: 2.141580\tLabel Loss: 0.001427\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 343 \tVal Loss: 2.204535\n",
            "Epoch: 343 \tTest Loss: 2.071515\n",
            "\n",
            "Epoch: 344 [0/1762 (0%)]\tLoss: 2.169103\tLabel Loss: 0.001624\n",
            "Epoch: 344 [640/1762 (36%)]\tLoss: 2.225613\tLabel Loss: 0.001854\n",
            "Epoch: 344 [1280/1762 (71%)]\tLoss: 2.110244\tLabel Loss: 0.001504\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 344 \tVal Loss: 2.199209\n",
            "Epoch: 344 \tTest Loss: 2.073952\n",
            "\n",
            "Epoch: 345 [0/1762 (0%)]\tLoss: 1.966719\tLabel Loss: 0.001478\n",
            "Epoch: 345 [640/1762 (36%)]\tLoss: 1.835320\tLabel Loss: 0.001435\n",
            "Epoch: 345 [1280/1762 (71%)]\tLoss: 2.137455\tLabel Loss: 0.001422\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 345 \tVal Loss: 2.198356\n",
            "Epoch: 345 \tTest Loss: 2.061030\n",
            "\n",
            "Epoch: 346 [0/1762 (0%)]\tLoss: 2.207377\tLabel Loss: 0.001441\n",
            "Epoch: 346 [640/1762 (36%)]\tLoss: 2.096037\tLabel Loss: 0.001641\n",
            "Epoch: 346 [1280/1762 (71%)]\tLoss: 2.024148\tLabel Loss: 0.001468\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 346 \tVal Loss: 2.198530\n",
            "Epoch: 346 \tTest Loss: 2.057239\n",
            "\n",
            "Epoch: 347 [0/1762 (0%)]\tLoss: 2.018658\tLabel Loss: 0.001484\n",
            "Epoch: 347 [640/1762 (36%)]\tLoss: 2.171782\tLabel Loss: 0.001457\n",
            "Epoch: 347 [1280/1762 (71%)]\tLoss: 2.017738\tLabel Loss: 0.001523\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 347 \tVal Loss: 2.198859\n",
            "Epoch: 347 \tTest Loss: 2.061946\n",
            "\n",
            "Epoch: 348 [0/1762 (0%)]\tLoss: 2.289267\tLabel Loss: 0.001624\n",
            "Epoch: 348 [640/1762 (36%)]\tLoss: 1.836103\tLabel Loss: 0.001484\n",
            "Epoch: 348 [1280/1762 (71%)]\tLoss: 2.137221\tLabel Loss: 0.001426\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 348 \tVal Loss: 2.195854\n",
            "Epoch: 348 \tTest Loss: 2.062976\n",
            "\n",
            "Epoch: 349 [0/1762 (0%)]\tLoss: 2.237012\tLabel Loss: 0.001411\n",
            "Epoch: 349 [640/1762 (36%)]\tLoss: 2.166206\tLabel Loss: 0.001479\n",
            "Epoch: 349 [1280/1762 (71%)]\tLoss: 2.120731\tLabel Loss: 0.001433\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 349 \tVal Loss: 2.190851\n",
            "Epoch: 349 \tTest Loss: 2.062200\n",
            "\n",
            "Epoch: 350 [0/1762 (0%)]\tLoss: 1.891286\tLabel Loss: 0.001415\n",
            "Epoch: 350 [640/1762 (36%)]\tLoss: 2.092236\tLabel Loss: 0.001415\n",
            "Epoch: 350 [1280/1762 (71%)]\tLoss: 2.149489\tLabel Loss: 0.001439\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 350 \tVal Loss: 2.201812\n",
            "Epoch: 350 \tTest Loss: 2.067978\n",
            "\n",
            "Epoch: 351 [0/1762 (0%)]\tLoss: 2.115951\tLabel Loss: 0.001527\n",
            "Epoch: 351 [640/1762 (36%)]\tLoss: 1.929793\tLabel Loss: 0.001559\n",
            "Epoch: 351 [1280/1762 (71%)]\tLoss: 1.877840\tLabel Loss: 0.001426\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 351 \tVal Loss: 2.193388\n",
            "Epoch: 351 \tTest Loss: 2.060150\n",
            "\n",
            "Epoch: 352 [0/1762 (0%)]\tLoss: 2.091502\tLabel Loss: 0.001384\n",
            "Epoch: 352 [640/1762 (36%)]\tLoss: 2.146171\tLabel Loss: 0.001428\n",
            "Epoch: 352 [1280/1762 (71%)]\tLoss: 2.198843\tLabel Loss: 0.001400\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 352 \tVal Loss: 2.199301\n",
            "Epoch: 352 \tTest Loss: 2.064686\n",
            "\n",
            "Epoch: 353 [0/1762 (0%)]\tLoss: 2.066076\tLabel Loss: 0.001405\n",
            "Epoch: 353 [640/1762 (36%)]\tLoss: 2.055397\tLabel Loss: 0.001470\n",
            "Epoch: 353 [1280/1762 (71%)]\tLoss: 1.948786\tLabel Loss: 0.001428\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 353 \tVal Loss: 2.199020\n",
            "Epoch: 353 \tTest Loss: 2.062375\n",
            "\n",
            "Epoch: 354 [0/1762 (0%)]\tLoss: 2.047033\tLabel Loss: 0.001445\n",
            "Epoch: 354 [640/1762 (36%)]\tLoss: 1.808615\tLabel Loss: 0.001379\n",
            "Epoch: 354 [1280/1762 (71%)]\tLoss: 2.094092\tLabel Loss: 0.001361\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 354 \tVal Loss: 2.197340\n",
            "Epoch: 354 \tTest Loss: 2.075180\n",
            "\n",
            "Epoch: 355 [0/1762 (0%)]\tLoss: 2.085189\tLabel Loss: 0.001471\n",
            "Epoch: 355 [640/1762 (36%)]\tLoss: 2.244602\tLabel Loss: 0.001574\n",
            "Epoch: 355 [1280/1762 (71%)]\tLoss: 2.004323\tLabel Loss: 0.001385\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 355 \tVal Loss: 2.190222\n",
            "Epoch: 355 \tTest Loss: 2.059709\n",
            "\n",
            "Epoch: 356 [0/1762 (0%)]\tLoss: 2.010944\tLabel Loss: 0.001443\n",
            "Epoch: 356 [640/1762 (36%)]\tLoss: 2.207730\tLabel Loss: 0.001386\n",
            "Epoch: 356 [1280/1762 (71%)]\tLoss: 2.085433\tLabel Loss: 0.001380\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 356 \tVal Loss: 2.189875\n",
            "Epoch: 356 \tTest Loss: 2.056209\n",
            "\n",
            "Epoch: 357 [0/1762 (0%)]\tLoss: 2.112676\tLabel Loss: 0.001360\n",
            "Epoch: 357 [640/1762 (36%)]\tLoss: 2.215685\tLabel Loss: 0.001394\n",
            "Epoch: 357 [1280/1762 (71%)]\tLoss: 1.979300\tLabel Loss: 0.001392\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 357 \tVal Loss: 2.181470\n",
            "Epoch: 357 \tTest Loss: 2.057940\n",
            "\n",
            "Epoch: 358 [0/1762 (0%)]\tLoss: 2.026033\tLabel Loss: 0.001440\n",
            "Epoch: 358 [640/1762 (36%)]\tLoss: 1.922499\tLabel Loss: 0.001359\n",
            "Epoch: 358 [1280/1762 (71%)]\tLoss: 2.248612\tLabel Loss: 0.001419\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 358 \tVal Loss: 2.181657\n",
            "Epoch: 358 \tTest Loss: 2.052193\n",
            "\n",
            "Epoch: 359 [0/1762 (0%)]\tLoss: 1.975956\tLabel Loss: 0.001355\n",
            "Epoch: 359 [640/1762 (36%)]\tLoss: 2.372235\tLabel Loss: 0.001490\n",
            "Epoch: 359 [1280/1762 (71%)]\tLoss: 2.140871\tLabel Loss: 0.001345\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 359 \tVal Loss: 2.200531\n",
            "Epoch: 359 \tTest Loss: 2.063156\n",
            "\n",
            "Epoch: 360 [0/1762 (0%)]\tLoss: 2.192440\tLabel Loss: 0.001356\n",
            "Epoch: 360 [640/1762 (36%)]\tLoss: 2.299690\tLabel Loss: 0.001326\n",
            "Epoch: 360 [1280/1762 (71%)]\tLoss: 2.183774\tLabel Loss: 0.001408\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 360 \tVal Loss: 2.192429\n",
            "Epoch: 360 \tTest Loss: 2.059097\n",
            "\n",
            "Epoch: 361 [0/1762 (0%)]\tLoss: 2.102338\tLabel Loss: 0.001361\n",
            "Epoch: 361 [640/1762 (36%)]\tLoss: 2.054526\tLabel Loss: 0.001415\n",
            "Epoch: 361 [1280/1762 (71%)]\tLoss: 2.023187\tLabel Loss: 0.001415\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 361 \tVal Loss: 2.216239\n",
            "Epoch: 361 \tTest Loss: 2.075548\n",
            "\n",
            "Epoch: 362 [0/1762 (0%)]\tLoss: 2.153565\tLabel Loss: 0.001409\n",
            "Epoch: 362 [640/1762 (36%)]\tLoss: 2.282180\tLabel Loss: 0.001361\n",
            "Epoch: 362 [1280/1762 (71%)]\tLoss: 2.178347\tLabel Loss: 0.001344\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 362 \tVal Loss: 2.185810\n",
            "Epoch: 362 \tTest Loss: 2.062058\n",
            "\n",
            "Epoch: 363 [0/1762 (0%)]\tLoss: 2.004084\tLabel Loss: 0.001342\n",
            "Epoch: 363 [640/1762 (36%)]\tLoss: 2.341130\tLabel Loss: 0.001341\n",
            "Epoch: 363 [1280/1762 (71%)]\tLoss: 2.170272\tLabel Loss: 0.001345\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 363 \tVal Loss: 2.187234\n",
            "Epoch: 363 \tTest Loss: 2.056791\n",
            "\n",
            "Epoch: 364 [0/1762 (0%)]\tLoss: 2.077400\tLabel Loss: 0.001428\n",
            "Epoch: 364 [640/1762 (36%)]\tLoss: 2.145888\tLabel Loss: 0.001351\n",
            "Epoch: 364 [1280/1762 (71%)]\tLoss: 2.106570\tLabel Loss: 0.001445\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 364 \tVal Loss: 2.193386\n",
            "Epoch: 364 \tTest Loss: 2.059742\n",
            "\n",
            "Epoch: 365 [0/1762 (0%)]\tLoss: 1.826186\tLabel Loss: 0.001347\n",
            "Epoch: 365 [640/1762 (36%)]\tLoss: 1.880272\tLabel Loss: 0.001372\n",
            "Epoch: 365 [1280/1762 (71%)]\tLoss: 1.895078\tLabel Loss: 0.001416\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 365 \tVal Loss: 2.179073\n",
            "Epoch: 365 \tTest Loss: 2.051597\n",
            "\n",
            "Epoch: 366 [0/1762 (0%)]\tLoss: 2.084356\tLabel Loss: 0.001362\n",
            "Epoch: 366 [640/1762 (36%)]\tLoss: 2.003742\tLabel Loss: 0.001383\n",
            "Epoch: 366 [1280/1762 (71%)]\tLoss: 2.210796\tLabel Loss: 0.001294\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 366 \tVal Loss: 2.200679\n",
            "Epoch: 366 \tTest Loss: 2.059310\n",
            "\n",
            "Epoch: 367 [0/1762 (0%)]\tLoss: 2.093157\tLabel Loss: 0.001424\n",
            "Epoch: 367 [640/1762 (36%)]\tLoss: 2.067924\tLabel Loss: 0.001340\n",
            "Epoch: 367 [1280/1762 (71%)]\tLoss: 1.977771\tLabel Loss: 0.001369\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 367 \tVal Loss: 2.180635\n",
            "Epoch: 367 \tTest Loss: 2.050819\n",
            "\n",
            "Epoch: 368 [0/1762 (0%)]\tLoss: 2.173899\tLabel Loss: 0.001303\n",
            "Epoch: 368 [640/1762 (36%)]\tLoss: 2.342911\tLabel Loss: 0.001346\n",
            "Epoch: 368 [1280/1762 (71%)]\tLoss: 2.179991\tLabel Loss: 0.001345\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 368 \tVal Loss: 2.195353\n",
            "Epoch: 368 \tTest Loss: 2.060023\n",
            "\n",
            "Epoch: 369 [0/1762 (0%)]\tLoss: 2.159365\tLabel Loss: 0.001324\n",
            "Epoch: 369 [640/1762 (36%)]\tLoss: 2.125417\tLabel Loss: 0.001356\n",
            "Epoch: 369 [1280/1762 (71%)]\tLoss: 1.950532\tLabel Loss: 0.001310\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 369 \tVal Loss: 2.201654\n",
            "Epoch: 369 \tTest Loss: 2.066148\n",
            "\n",
            "Epoch: 370 [0/1762 (0%)]\tLoss: 2.067767\tLabel Loss: 0.001309\n",
            "Epoch: 370 [640/1762 (36%)]\tLoss: 2.370807\tLabel Loss: 0.001417\n",
            "Epoch: 370 [1280/1762 (71%)]\tLoss: 2.109302\tLabel Loss: 0.001308\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 370 \tVal Loss: 2.191714\n",
            "Epoch: 370 \tTest Loss: 2.052314\n",
            "\n",
            "Epoch: 371 [0/1762 (0%)]\tLoss: 2.103150\tLabel Loss: 0.001272\n",
            "Epoch: 371 [640/1762 (36%)]\tLoss: 2.104045\tLabel Loss: 0.001387\n",
            "Epoch: 371 [1280/1762 (71%)]\tLoss: 2.113842\tLabel Loss: 0.001378\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 371 \tVal Loss: 2.187299\n",
            "Epoch: 371 \tTest Loss: 2.059396\n",
            "\n",
            "Epoch: 372 [0/1762 (0%)]\tLoss: 2.426251\tLabel Loss: 0.001393\n",
            "Epoch: 372 [640/1762 (36%)]\tLoss: 2.029372\tLabel Loss: 0.001427\n",
            "Epoch: 372 [1280/1762 (71%)]\tLoss: 2.180146\tLabel Loss: 0.001300\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 372 \tVal Loss: 2.189787\n",
            "Epoch: 372 \tTest Loss: 2.056263\n",
            "\n",
            "Epoch: 373 [0/1762 (0%)]\tLoss: 2.043014\tLabel Loss: 0.001377\n",
            "Epoch: 373 [640/1762 (36%)]\tLoss: 2.188107\tLabel Loss: 0.001469\n",
            "Epoch: 373 [1280/1762 (71%)]\tLoss: 1.786554\tLabel Loss: 0.001339\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 373 \tVal Loss: 2.181140\n",
            "Epoch: 373 \tTest Loss: 2.050536\n",
            "\n",
            "Epoch: 374 [0/1762 (0%)]\tLoss: 2.061336\tLabel Loss: 0.001285\n",
            "Epoch: 374 [640/1762 (36%)]\tLoss: 1.852538\tLabel Loss: 0.001400\n",
            "Epoch: 374 [1280/1762 (71%)]\tLoss: 2.265780\tLabel Loss: 0.001348\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 374 \tVal Loss: 2.201428\n",
            "Epoch: 374 \tTest Loss: 2.064545\n",
            "\n",
            "Epoch: 375 [0/1762 (0%)]\tLoss: 2.123812\tLabel Loss: 0.001384\n",
            "Epoch: 375 [640/1762 (36%)]\tLoss: 2.027960\tLabel Loss: 0.001303\n",
            "Epoch: 375 [1280/1762 (71%)]\tLoss: 2.266411\tLabel Loss: 0.001330\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 375 \tVal Loss: 2.196394\n",
            "Epoch: 375 \tTest Loss: 2.056688\n",
            "\n",
            "Epoch: 376 [0/1762 (0%)]\tLoss: 2.233438\tLabel Loss: 0.001305\n",
            "Epoch: 376 [640/1762 (36%)]\tLoss: 2.096080\tLabel Loss: 0.001275\n",
            "Epoch: 376 [1280/1762 (71%)]\tLoss: 2.008305\tLabel Loss: 0.001368\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 376 \tVal Loss: 2.183891\n",
            "Epoch: 376 \tTest Loss: 2.055279\n",
            "\n",
            "Epoch: 377 [0/1762 (0%)]\tLoss: 2.304430\tLabel Loss: 0.001310\n",
            "Epoch: 377 [640/1762 (36%)]\tLoss: 2.157713\tLabel Loss: 0.001326\n",
            "Epoch: 377 [1280/1762 (71%)]\tLoss: 2.134707\tLabel Loss: 0.001274\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 377 \tVal Loss: 2.180856\n",
            "Epoch: 377 \tTest Loss: 2.061956\n",
            "\n",
            "Epoch: 378 [0/1762 (0%)]\tLoss: 2.113929\tLabel Loss: 0.001270\n",
            "Epoch: 378 [640/1762 (36%)]\tLoss: 2.119129\tLabel Loss: 0.001387\n",
            "Epoch: 378 [1280/1762 (71%)]\tLoss: 2.032611\tLabel Loss: 0.001294\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 378 \tVal Loss: 2.203550\n",
            "Epoch: 378 \tTest Loss: 2.060556\n",
            "\n",
            "Epoch: 379 [0/1762 (0%)]\tLoss: 2.017146\tLabel Loss: 0.001360\n",
            "Epoch: 379 [640/1762 (36%)]\tLoss: 2.105797\tLabel Loss: 0.001451\n",
            "Epoch: 379 [1280/1762 (71%)]\tLoss: 2.229297\tLabel Loss: 0.001298\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 379 \tVal Loss: 2.199291\n",
            "Epoch: 379 \tTest Loss: 2.060333\n",
            "\n",
            "Epoch: 380 [0/1762 (0%)]\tLoss: 1.953481\tLabel Loss: 0.001492\n",
            "Epoch: 380 [640/1762 (36%)]\tLoss: 2.328169\tLabel Loss: 0.001265\n",
            "Epoch: 380 [1280/1762 (71%)]\tLoss: 1.976084\tLabel Loss: 0.001346\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 380 \tVal Loss: 2.225602\n",
            "Epoch: 380 \tTest Loss: 2.083252\n",
            "\n",
            "Epoch: 381 [0/1762 (0%)]\tLoss: 2.195835\tLabel Loss: 0.001310\n",
            "Epoch: 381 [640/1762 (36%)]\tLoss: 2.075269\tLabel Loss: 0.001288\n",
            "Epoch: 381 [1280/1762 (71%)]\tLoss: 2.279091\tLabel Loss: 0.001279\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 381 \tVal Loss: 2.217481\n",
            "Epoch: 381 \tTest Loss: 2.082731\n",
            "\n",
            "Epoch: 382 [0/1762 (0%)]\tLoss: 2.116562\tLabel Loss: 0.001270\n",
            "Epoch: 382 [640/1762 (36%)]\tLoss: 2.079677\tLabel Loss: 0.001321\n",
            "Epoch: 382 [1280/1762 (71%)]\tLoss: 2.027982\tLabel Loss: 0.001239\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 382 \tVal Loss: 2.174280\n",
            "Epoch: 382 \tTest Loss: 2.047172\n",
            "\n",
            "Epoch: 383 [0/1762 (0%)]\tLoss: 2.009912\tLabel Loss: 0.001339\n",
            "Epoch: 383 [640/1762 (36%)]\tLoss: 2.059327\tLabel Loss: 0.001312\n",
            "Epoch: 383 [1280/1762 (71%)]\tLoss: 2.209144\tLabel Loss: 0.001266\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 383 \tVal Loss: 2.194630\n",
            "Epoch: 383 \tTest Loss: 2.074923\n",
            "\n",
            "Epoch: 384 [0/1762 (0%)]\tLoss: 2.018948\tLabel Loss: 0.001235\n",
            "Epoch: 384 [640/1762 (36%)]\tLoss: 2.152082\tLabel Loss: 0.001250\n",
            "Epoch: 384 [1280/1762 (71%)]\tLoss: 2.048607\tLabel Loss: 0.001224\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 384 \tVal Loss: 2.190456\n",
            "Epoch: 384 \tTest Loss: 2.052019\n",
            "\n",
            "Epoch: 385 [0/1762 (0%)]\tLoss: 2.112185\tLabel Loss: 0.001271\n",
            "Epoch: 385 [640/1762 (36%)]\tLoss: 1.887237\tLabel Loss: 0.001295\n",
            "Epoch: 385 [1280/1762 (71%)]\tLoss: 1.918968\tLabel Loss: 0.001273\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 385 \tVal Loss: 2.206029\n",
            "Epoch: 385 \tTest Loss: 2.064766\n",
            "\n",
            "Epoch: 386 [0/1762 (0%)]\tLoss: 2.519877\tLabel Loss: 0.001453\n",
            "Epoch: 386 [640/1762 (36%)]\tLoss: 2.106395\tLabel Loss: 0.001499\n",
            "Epoch: 386 [1280/1762 (71%)]\tLoss: 2.293918\tLabel Loss: 0.001201\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 386 \tVal Loss: 2.196410\n",
            "Epoch: 386 \tTest Loss: 2.060541\n",
            "\n",
            "Epoch: 387 [0/1762 (0%)]\tLoss: 1.999344\tLabel Loss: 0.001286\n",
            "Epoch: 387 [640/1762 (36%)]\tLoss: 1.875380\tLabel Loss: 0.001218\n",
            "Epoch: 387 [1280/1762 (71%)]\tLoss: 2.137877\tLabel Loss: 0.001212\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 387 \tVal Loss: 2.185404\n",
            "Epoch: 387 \tTest Loss: 2.067128\n",
            "\n",
            "Epoch: 388 [0/1762 (0%)]\tLoss: 2.015518\tLabel Loss: 0.001234\n",
            "Epoch: 388 [640/1762 (36%)]\tLoss: 1.978486\tLabel Loss: 0.001309\n",
            "Epoch: 388 [1280/1762 (71%)]\tLoss: 2.097355\tLabel Loss: 0.001253\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 388 \tVal Loss: 2.187559\n",
            "Epoch: 388 \tTest Loss: 2.056271\n",
            "\n",
            "Epoch: 389 [0/1762 (0%)]\tLoss: 2.228529\tLabel Loss: 0.001247\n",
            "Epoch: 389 [640/1762 (36%)]\tLoss: 2.021282\tLabel Loss: 0.001232\n",
            "Epoch: 389 [1280/1762 (71%)]\tLoss: 1.904940\tLabel Loss: 0.001203\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 389 \tVal Loss: 2.176555\n",
            "Epoch: 389 \tTest Loss: 2.047962\n",
            "\n",
            "Epoch: 390 [0/1762 (0%)]\tLoss: 1.797533\tLabel Loss: 0.001219\n",
            "Epoch: 390 [640/1762 (36%)]\tLoss: 2.007709\tLabel Loss: 0.001222\n",
            "Epoch: 390 [1280/1762 (71%)]\tLoss: 2.218522\tLabel Loss: 0.001324\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 390 \tVal Loss: 2.187754\n",
            "Epoch: 390 \tTest Loss: 2.060822\n",
            "\n",
            "Epoch: 391 [0/1762 (0%)]\tLoss: 2.022003\tLabel Loss: 0.001252\n",
            "Epoch: 391 [640/1762 (36%)]\tLoss: 1.861643\tLabel Loss: 0.001250\n",
            "Epoch: 391 [1280/1762 (71%)]\tLoss: 2.202177\tLabel Loss: 0.001235\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 391 \tVal Loss: 2.191484\n",
            "Epoch: 391 \tTest Loss: 2.063221\n",
            "\n",
            "Epoch: 392 [0/1762 (0%)]\tLoss: 2.049954\tLabel Loss: 0.001269\n",
            "Epoch: 392 [640/1762 (36%)]\tLoss: 2.097461\tLabel Loss: 0.001284\n",
            "Epoch: 392 [1280/1762 (71%)]\tLoss: 2.025068\tLabel Loss: 0.001251\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 392 \tVal Loss: 2.190357\n",
            "Epoch: 392 \tTest Loss: 2.064034\n",
            "\n",
            "Epoch: 393 [0/1762 (0%)]\tLoss: 1.913445\tLabel Loss: 0.001373\n",
            "Epoch: 393 [640/1762 (36%)]\tLoss: 2.222653\tLabel Loss: 0.001278\n",
            "Epoch: 393 [1280/1762 (71%)]\tLoss: 2.048278\tLabel Loss: 0.001216\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 393 \tVal Loss: 2.172272\n",
            "Epoch: 393 \tTest Loss: 2.045166\n",
            "\n",
            "Epoch: 394 [0/1762 (0%)]\tLoss: 1.971293\tLabel Loss: 0.001249\n",
            "Epoch: 394 [640/1762 (36%)]\tLoss: 2.235809\tLabel Loss: 0.001207\n",
            "Epoch: 394 [1280/1762 (71%)]\tLoss: 2.105661\tLabel Loss: 0.001235\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 394 \tVal Loss: 2.197069\n",
            "Epoch: 394 \tTest Loss: 2.061710\n",
            "\n",
            "Epoch: 395 [0/1762 (0%)]\tLoss: 2.069251\tLabel Loss: 0.001246\n",
            "Epoch: 395 [640/1762 (36%)]\tLoss: 2.101238\tLabel Loss: 0.001289\n",
            "Epoch: 395 [1280/1762 (71%)]\tLoss: 2.093577\tLabel Loss: 0.001162\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 395 \tVal Loss: 2.187048\n",
            "Epoch: 395 \tTest Loss: 2.057311\n",
            "\n",
            "Epoch: 396 [0/1762 (0%)]\tLoss: 1.952939\tLabel Loss: 0.001208\n",
            "Epoch: 396 [640/1762 (36%)]\tLoss: 2.110061\tLabel Loss: 0.001225\n",
            "Epoch: 396 [1280/1762 (71%)]\tLoss: 2.041658\tLabel Loss: 0.001204\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 396 \tVal Loss: 2.205198\n",
            "Epoch: 396 \tTest Loss: 2.067282\n",
            "\n",
            "Epoch: 397 [0/1762 (0%)]\tLoss: 2.300923\tLabel Loss: 0.001202\n",
            "Epoch: 397 [640/1762 (36%)]\tLoss: 2.209179\tLabel Loss: 0.001259\n",
            "Epoch: 397 [1280/1762 (71%)]\tLoss: 2.062259\tLabel Loss: 0.001259\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 397 \tVal Loss: 2.210730\n",
            "Epoch: 397 \tTest Loss: 2.066712\n",
            "\n",
            "Epoch: 398 [0/1762 (0%)]\tLoss: 2.067900\tLabel Loss: 0.001247\n",
            "Epoch: 398 [640/1762 (36%)]\tLoss: 2.019400\tLabel Loss: 0.001189\n",
            "Epoch: 398 [1280/1762 (71%)]\tLoss: 2.225359\tLabel Loss: 0.001173\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 398 \tVal Loss: 2.195651\n",
            "Epoch: 398 \tTest Loss: 2.062536\n",
            "\n",
            "Epoch: 399 [0/1762 (0%)]\tLoss: 1.981230\tLabel Loss: 0.001215\n",
            "Epoch: 399 [640/1762 (36%)]\tLoss: 2.001104\tLabel Loss: 0.001204\n",
            "Epoch: 399 [1280/1762 (71%)]\tLoss: 1.952207\tLabel Loss: 0.001277\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 399 \tVal Loss: 2.189510\n",
            "Epoch: 399 \tTest Loss: 2.055941\n",
            "\n",
            "Epoch: 400 [0/1762 (0%)]\tLoss: 2.203301\tLabel Loss: 0.001201\n",
            "Epoch: 400 [640/1762 (36%)]\tLoss: 2.107366\tLabel Loss: 0.001260\n",
            "Epoch: 400 [1280/1762 (71%)]\tLoss: 2.082230\tLabel Loss: 0.001206\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 400 \tVal Loss: 2.176212\n",
            "Epoch: 400 \tTest Loss: 2.049444\n",
            "\n",
            "Epoch: 401 [0/1762 (0%)]\tLoss: 2.036243\tLabel Loss: 0.001332\n",
            "Epoch: 401 [640/1762 (36%)]\tLoss: 1.980924\tLabel Loss: 0.001302\n",
            "Epoch: 401 [1280/1762 (71%)]\tLoss: 2.089108\tLabel Loss: 0.001376\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 401 \tVal Loss: 2.209004\n",
            "Epoch: 401 \tTest Loss: 2.068065\n",
            "\n",
            "Epoch: 402 [0/1762 (0%)]\tLoss: 1.987742\tLabel Loss: 0.001385\n",
            "Epoch: 402 [640/1762 (36%)]\tLoss: 2.261478\tLabel Loss: 0.001206\n",
            "Epoch: 402 [1280/1762 (71%)]\tLoss: 2.057066\tLabel Loss: 0.001150\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 402 \tVal Loss: 2.182731\n",
            "Epoch: 402 \tTest Loss: 2.052459\n",
            "\n",
            "Epoch: 403 [0/1762 (0%)]\tLoss: 2.098808\tLabel Loss: 0.001171\n",
            "Epoch: 403 [640/1762 (36%)]\tLoss: 2.027899\tLabel Loss: 0.001174\n",
            "Epoch: 403 [1280/1762 (71%)]\tLoss: 2.069075\tLabel Loss: 0.001196\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 403 \tVal Loss: 2.188542\n",
            "Epoch: 403 \tTest Loss: 2.066300\n",
            "\n",
            "Epoch: 404 [0/1762 (0%)]\tLoss: 1.923296\tLabel Loss: 0.001169\n",
            "Epoch: 404 [640/1762 (36%)]\tLoss: 2.081582\tLabel Loss: 0.001200\n",
            "Epoch: 404 [1280/1762 (71%)]\tLoss: 2.073440\tLabel Loss: 0.001173\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 404 \tVal Loss: 2.173320\n",
            "Epoch: 404 \tTest Loss: 2.047545\n",
            "\n",
            "Epoch: 405 [0/1762 (0%)]\tLoss: 2.185869\tLabel Loss: 0.001373\n",
            "Epoch: 405 [640/1762 (36%)]\tLoss: 2.210205\tLabel Loss: 0.001365\n",
            "Epoch: 405 [1280/1762 (71%)]\tLoss: 2.058657\tLabel Loss: 0.001206\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 405 \tVal Loss: 2.203363\n",
            "Epoch: 405 \tTest Loss: 2.075009\n",
            "\n",
            "Epoch: 406 [0/1762 (0%)]\tLoss: 2.065370\tLabel Loss: 0.001164\n",
            "Epoch: 406 [640/1762 (36%)]\tLoss: 2.139634\tLabel Loss: 0.001215\n",
            "Epoch: 406 [1280/1762 (71%)]\tLoss: 2.157603\tLabel Loss: 0.001153\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 406 \tVal Loss: 2.170496\n",
            "Epoch: 406 \tTest Loss: 2.042338\n",
            "\n",
            "Epoch: 407 [0/1762 (0%)]\tLoss: 2.145422\tLabel Loss: 0.001153\n",
            "Epoch: 407 [640/1762 (36%)]\tLoss: 2.056019\tLabel Loss: 0.001201\n",
            "Epoch: 407 [1280/1762 (71%)]\tLoss: 2.114481\tLabel Loss: 0.001156\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 407 \tVal Loss: 2.199419\n",
            "Epoch: 407 \tTest Loss: 2.066868\n",
            "\n",
            "Epoch: 408 [0/1762 (0%)]\tLoss: 1.818572\tLabel Loss: 0.001143\n",
            "Epoch: 408 [640/1762 (36%)]\tLoss: 2.045379\tLabel Loss: 0.001202\n",
            "Epoch: 408 [1280/1762 (71%)]\tLoss: 2.032842\tLabel Loss: 0.001211\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 408 \tVal Loss: 2.187231\n",
            "Epoch: 408 \tTest Loss: 2.050286\n",
            "\n",
            "Epoch: 409 [0/1762 (0%)]\tLoss: 1.917537\tLabel Loss: 0.001132\n",
            "Epoch: 409 [640/1762 (36%)]\tLoss: 2.060314\tLabel Loss: 0.001178\n",
            "Epoch: 409 [1280/1762 (71%)]\tLoss: 1.984196\tLabel Loss: 0.001152\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 409 \tVal Loss: 2.183920\n",
            "Epoch: 409 \tTest Loss: 2.070106\n",
            "\n",
            "Epoch: 410 [0/1762 (0%)]\tLoss: 2.089090\tLabel Loss: 0.001166\n",
            "Epoch: 410 [640/1762 (36%)]\tLoss: 2.088958\tLabel Loss: 0.001254\n",
            "Epoch: 410 [1280/1762 (71%)]\tLoss: 2.112883\tLabel Loss: 0.001332\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 410 \tVal Loss: 2.184586\n",
            "Epoch: 410 \tTest Loss: 2.056745\n",
            "\n",
            "Epoch: 411 [0/1762 (0%)]\tLoss: 2.033579\tLabel Loss: 0.001158\n",
            "Epoch: 411 [640/1762 (36%)]\tLoss: 1.991093\tLabel Loss: 0.001170\n",
            "Epoch: 411 [1280/1762 (71%)]\tLoss: 2.052325\tLabel Loss: 0.001152\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 411 \tVal Loss: 2.181046\n",
            "Epoch: 411 \tTest Loss: 2.054052\n",
            "\n",
            "Epoch: 412 [0/1762 (0%)]\tLoss: 1.868520\tLabel Loss: 0.001188\n",
            "Epoch: 412 [640/1762 (36%)]\tLoss: 2.010501\tLabel Loss: 0.001152\n",
            "Epoch: 412 [1280/1762 (71%)]\tLoss: 1.984047\tLabel Loss: 0.001246\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 412 \tVal Loss: 2.178294\n",
            "Epoch: 412 \tTest Loss: 2.063924\n",
            "\n",
            "Epoch: 413 [0/1762 (0%)]\tLoss: 2.158447\tLabel Loss: 0.001210\n",
            "Epoch: 413 [640/1762 (36%)]\tLoss: 1.896555\tLabel Loss: 0.001235\n",
            "Epoch: 413 [1280/1762 (71%)]\tLoss: 1.897990\tLabel Loss: 0.001138\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 413 \tVal Loss: 2.178765\n",
            "Epoch: 413 \tTest Loss: 2.046794\n",
            "\n",
            "Epoch: 414 [0/1762 (0%)]\tLoss: 1.998300\tLabel Loss: 0.001147\n",
            "Epoch: 414 [640/1762 (36%)]\tLoss: 2.035466\tLabel Loss: 0.001190\n",
            "Epoch: 414 [1280/1762 (71%)]\tLoss: 1.942272\tLabel Loss: 0.001139\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 414 \tVal Loss: 2.176402\n",
            "Epoch: 414 \tTest Loss: 2.055457\n",
            "\n",
            "Epoch: 415 [0/1762 (0%)]\tLoss: 2.136633\tLabel Loss: 0.001137\n",
            "Epoch: 415 [640/1762 (36%)]\tLoss: 2.070799\tLabel Loss: 0.001202\n",
            "Epoch: 415 [1280/1762 (71%)]\tLoss: 2.124174\tLabel Loss: 0.001222\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 415 \tVal Loss: 2.192212\n",
            "Epoch: 415 \tTest Loss: 2.062138\n",
            "\n",
            "Epoch: 416 [0/1762 (0%)]\tLoss: 1.807968\tLabel Loss: 0.001131\n",
            "Epoch: 416 [640/1762 (36%)]\tLoss: 2.003175\tLabel Loss: 0.001153\n",
            "Epoch: 416 [1280/1762 (71%)]\tLoss: 2.021137\tLabel Loss: 0.001164\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 416 \tVal Loss: 2.177651\n",
            "Epoch: 416 \tTest Loss: 2.045206\n",
            "\n",
            "Epoch: 417 [0/1762 (0%)]\tLoss: 1.982619\tLabel Loss: 0.001185\n",
            "Epoch: 417 [640/1762 (36%)]\tLoss: 2.338076\tLabel Loss: 0.001223\n",
            "Epoch: 417 [1280/1762 (71%)]\tLoss: 2.081806\tLabel Loss: 0.001143\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 417 \tVal Loss: 2.191218\n",
            "Epoch: 417 \tTest Loss: 2.059604\n",
            "\n",
            "Epoch: 418 [0/1762 (0%)]\tLoss: 1.999223\tLabel Loss: 0.001215\n",
            "Epoch: 418 [640/1762 (36%)]\tLoss: 2.054320\tLabel Loss: 0.001099\n",
            "Epoch: 418 [1280/1762 (71%)]\tLoss: 1.935462\tLabel Loss: 0.001144\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 418 \tVal Loss: 2.172308\n",
            "Epoch: 418 \tTest Loss: 2.046481\n",
            "\n",
            "Epoch: 419 [0/1762 (0%)]\tLoss: 2.216614\tLabel Loss: 0.001148\n",
            "Epoch: 419 [640/1762 (36%)]\tLoss: 1.886805\tLabel Loss: 0.001167\n",
            "Epoch: 419 [1280/1762 (71%)]\tLoss: 1.963862\tLabel Loss: 0.001086\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 419 \tVal Loss: 2.188272\n",
            "Epoch: 419 \tTest Loss: 2.058306\n",
            "\n",
            "Epoch: 420 [0/1762 (0%)]\tLoss: 2.129932\tLabel Loss: 0.001168\n",
            "Epoch: 420 [640/1762 (36%)]\tLoss: 1.970535\tLabel Loss: 0.001110\n",
            "Epoch: 420 [1280/1762 (71%)]\tLoss: 1.962946\tLabel Loss: 0.001086\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 420 \tVal Loss: 2.231491\n",
            "Epoch: 420 \tTest Loss: 2.094057\n",
            "\n",
            "Epoch: 421 [0/1762 (0%)]\tLoss: 1.950140\tLabel Loss: 0.001159\n",
            "Epoch: 421 [640/1762 (36%)]\tLoss: 2.179485\tLabel Loss: 0.001406\n",
            "Epoch: 421 [1280/1762 (71%)]\tLoss: 1.908486\tLabel Loss: 0.001128\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 421 \tVal Loss: 2.186776\n",
            "Epoch: 421 \tTest Loss: 2.056392\n",
            "\n",
            "Epoch: 422 [0/1762 (0%)]\tLoss: 1.886406\tLabel Loss: 0.001161\n",
            "Epoch: 422 [640/1762 (36%)]\tLoss: 2.104088\tLabel Loss: 0.001092\n",
            "Epoch: 422 [1280/1762 (71%)]\tLoss: 2.071786\tLabel Loss: 0.001122\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 422 \tVal Loss: 2.179052\n",
            "Epoch: 422 \tTest Loss: 2.053733\n",
            "\n",
            "Epoch: 423 [0/1762 (0%)]\tLoss: 2.224602\tLabel Loss: 0.001177\n",
            "Epoch: 423 [640/1762 (36%)]\tLoss: 1.881223\tLabel Loss: 0.001167\n",
            "Epoch: 423 [1280/1762 (71%)]\tLoss: 1.918783\tLabel Loss: 0.001191\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 423 \tVal Loss: 2.202555\n",
            "Epoch: 423 \tTest Loss: 2.061315\n",
            "\n",
            "Epoch: 424 [0/1762 (0%)]\tLoss: 2.104475\tLabel Loss: 0.001126\n",
            "Epoch: 424 [640/1762 (36%)]\tLoss: 2.280150\tLabel Loss: 0.001108\n",
            "Epoch: 424 [1280/1762 (71%)]\tLoss: 2.020902\tLabel Loss: 0.001101\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 424 \tVal Loss: 2.175972\n",
            "Epoch: 424 \tTest Loss: 2.048004\n",
            "\n",
            "Epoch: 425 [0/1762 (0%)]\tLoss: 1.965132\tLabel Loss: 0.001095\n",
            "Epoch: 425 [640/1762 (36%)]\tLoss: 2.184123\tLabel Loss: 0.001114\n",
            "Epoch: 425 [1280/1762 (71%)]\tLoss: 2.017802\tLabel Loss: 0.001123\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 425 \tVal Loss: 2.183734\n",
            "Epoch: 425 \tTest Loss: 2.055428\n",
            "\n",
            "Epoch: 426 [0/1762 (0%)]\tLoss: 1.918172\tLabel Loss: 0.001112\n",
            "Epoch: 426 [640/1762 (36%)]\tLoss: 2.286731\tLabel Loss: 0.001113\n",
            "Epoch: 426 [1280/1762 (71%)]\tLoss: 2.157130\tLabel Loss: 0.001114\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 426 \tVal Loss: 2.181853\n",
            "Epoch: 426 \tTest Loss: 2.049863\n",
            "\n",
            "Epoch: 427 [0/1762 (0%)]\tLoss: 1.987141\tLabel Loss: 0.001247\n",
            "Epoch: 427 [640/1762 (36%)]\tLoss: 2.086015\tLabel Loss: 0.001124\n",
            "Epoch: 427 [1280/1762 (71%)]\tLoss: 2.132888\tLabel Loss: 0.001087\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 427 \tVal Loss: 2.177458\n",
            "Epoch: 427 \tTest Loss: 2.052762\n",
            "\n",
            "Epoch: 428 [0/1762 (0%)]\tLoss: 1.965367\tLabel Loss: 0.001125\n",
            "Epoch: 428 [640/1762 (36%)]\tLoss: 2.300705\tLabel Loss: 0.001099\n",
            "Epoch: 428 [1280/1762 (71%)]\tLoss: 2.287857\tLabel Loss: 0.001092\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 428 \tVal Loss: 2.195102\n",
            "Epoch: 428 \tTest Loss: 2.069155\n",
            "\n",
            "Epoch: 429 [0/1762 (0%)]\tLoss: 1.958501\tLabel Loss: 0.001171\n",
            "Epoch: 429 [640/1762 (36%)]\tLoss: 2.173553\tLabel Loss: 0.001117\n",
            "Epoch: 429 [1280/1762 (71%)]\tLoss: 2.030009\tLabel Loss: 0.001095\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 429 \tVal Loss: 2.197926\n",
            "Epoch: 429 \tTest Loss: 2.059600\n",
            "\n",
            "Epoch: 430 [0/1762 (0%)]\tLoss: 2.073158\tLabel Loss: 0.001151\n",
            "Epoch: 430 [640/1762 (36%)]\tLoss: 2.161085\tLabel Loss: 0.001077\n",
            "Epoch: 430 [1280/1762 (71%)]\tLoss: 1.987598\tLabel Loss: 0.001106\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 430 \tVal Loss: 2.196491\n",
            "Epoch: 430 \tTest Loss: 2.058835\n",
            "\n",
            "Epoch: 431 [0/1762 (0%)]\tLoss: 2.189426\tLabel Loss: 0.001105\n",
            "Epoch: 431 [640/1762 (36%)]\tLoss: 1.992995\tLabel Loss: 0.001090\n",
            "Epoch: 431 [1280/1762 (71%)]\tLoss: 2.043820\tLabel Loss: 0.001137\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 431 \tVal Loss: 2.176689\n",
            "Epoch: 431 \tTest Loss: 2.054141\n",
            "\n",
            "Epoch: 432 [0/1762 (0%)]\tLoss: 1.835045\tLabel Loss: 0.001128\n",
            "Epoch: 432 [640/1762 (36%)]\tLoss: 2.186694\tLabel Loss: 0.001097\n",
            "Epoch: 432 [1280/1762 (71%)]\tLoss: 1.933752\tLabel Loss: 0.001097\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 432 \tVal Loss: 2.194956\n",
            "Epoch: 432 \tTest Loss: 2.061372\n",
            "\n",
            "Epoch: 433 [0/1762 (0%)]\tLoss: 2.158734\tLabel Loss: 0.001121\n",
            "Epoch: 433 [640/1762 (36%)]\tLoss: 2.181952\tLabel Loss: 0.001118\n",
            "Epoch: 433 [1280/1762 (71%)]\tLoss: 2.000357\tLabel Loss: 0.001127\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 433 \tVal Loss: 2.176436\n",
            "Epoch: 433 \tTest Loss: 2.050563\n",
            "\n",
            "Epoch: 434 [0/1762 (0%)]\tLoss: 2.064919\tLabel Loss: 0.001101\n",
            "Epoch: 434 [640/1762 (36%)]\tLoss: 2.034437\tLabel Loss: 0.001074\n",
            "Epoch: 434 [1280/1762 (71%)]\tLoss: 2.187910\tLabel Loss: 0.001080\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 434 \tVal Loss: 2.179695\n",
            "Epoch: 434 \tTest Loss: 2.049023\n",
            "\n",
            "Epoch: 435 [0/1762 (0%)]\tLoss: 2.067921\tLabel Loss: 0.001082\n",
            "Epoch: 435 [640/1762 (36%)]\tLoss: 2.213414\tLabel Loss: 0.001189\n",
            "Epoch: 435 [1280/1762 (71%)]\tLoss: 1.863067\tLabel Loss: 0.001062\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 435 \tVal Loss: 2.191475\n",
            "Epoch: 435 \tTest Loss: 2.058936\n",
            "\n",
            "Epoch: 436 [0/1762 (0%)]\tLoss: 2.037734\tLabel Loss: 0.001074\n",
            "Epoch: 436 [640/1762 (36%)]\tLoss: 1.991871\tLabel Loss: 0.001097\n",
            "Epoch: 436 [1280/1762 (71%)]\tLoss: 2.075838\tLabel Loss: 0.001074\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 436 \tVal Loss: 2.195006\n",
            "Epoch: 436 \tTest Loss: 2.077386\n",
            "\n",
            "Epoch: 437 [0/1762 (0%)]\tLoss: 2.065251\tLabel Loss: 0.001101\n",
            "Epoch: 437 [640/1762 (36%)]\tLoss: 2.111740\tLabel Loss: 0.001086\n",
            "Epoch: 437 [1280/1762 (71%)]\tLoss: 2.296494\tLabel Loss: 0.001068\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 437 \tVal Loss: 2.179273\n",
            "Epoch: 437 \tTest Loss: 2.056358\n",
            "\n",
            "Epoch: 438 [0/1762 (0%)]\tLoss: 2.192468\tLabel Loss: 0.001105\n",
            "Epoch: 438 [640/1762 (36%)]\tLoss: 2.065803\tLabel Loss: 0.001065\n",
            "Epoch: 438 [1280/1762 (71%)]\tLoss: 2.013139\tLabel Loss: 0.001145\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 438 \tVal Loss: 2.211266\n",
            "Epoch: 438 \tTest Loss: 2.070698\n",
            "\n",
            "Epoch: 439 [0/1762 (0%)]\tLoss: 1.763449\tLabel Loss: 0.001150\n",
            "Epoch: 439 [640/1762 (36%)]\tLoss: 2.339150\tLabel Loss: 0.001223\n",
            "Epoch: 439 [1280/1762 (71%)]\tLoss: 2.270419\tLabel Loss: 0.001109\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 439 \tVal Loss: 2.188769\n",
            "Epoch: 439 \tTest Loss: 2.052826\n",
            "\n",
            "Epoch: 440 [0/1762 (0%)]\tLoss: 2.089598\tLabel Loss: 0.001088\n",
            "Epoch: 440 [640/1762 (36%)]\tLoss: 2.291836\tLabel Loss: 0.001159\n",
            "Epoch: 440 [1280/1762 (71%)]\tLoss: 2.070301\tLabel Loss: 0.001070\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 440 \tVal Loss: 2.176820\n",
            "Epoch: 440 \tTest Loss: 2.047927\n",
            "\n",
            "Epoch: 441 [0/1762 (0%)]\tLoss: 2.048846\tLabel Loss: 0.001063\n",
            "Epoch: 441 [640/1762 (36%)]\tLoss: 2.086467\tLabel Loss: 0.001100\n",
            "Epoch: 441 [1280/1762 (71%)]\tLoss: 2.131229\tLabel Loss: 0.001076\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 441 \tVal Loss: 2.196166\n",
            "Epoch: 441 \tTest Loss: 2.058871\n",
            "\n",
            "Epoch: 442 [0/1762 (0%)]\tLoss: 2.176327\tLabel Loss: 0.001126\n",
            "Epoch: 442 [640/1762 (36%)]\tLoss: 2.147459\tLabel Loss: 0.001082\n",
            "Epoch: 442 [1280/1762 (71%)]\tLoss: 1.954766\tLabel Loss: 0.001054\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 442 \tVal Loss: 2.179424\n",
            "Epoch: 442 \tTest Loss: 2.049580\n",
            "\n",
            "Epoch: 443 [0/1762 (0%)]\tLoss: 2.033607\tLabel Loss: 0.001131\n",
            "Epoch: 443 [640/1762 (36%)]\tLoss: 2.010063\tLabel Loss: 0.001078\n",
            "Epoch: 443 [1280/1762 (71%)]\tLoss: 2.146537\tLabel Loss: 0.001024\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 443 \tVal Loss: 2.190731\n",
            "Epoch: 443 \tTest Loss: 2.065891\n",
            "\n",
            "Epoch: 444 [0/1762 (0%)]\tLoss: 1.956794\tLabel Loss: 0.001039\n",
            "Epoch: 444 [640/1762 (36%)]\tLoss: 1.875355\tLabel Loss: 0.001143\n",
            "Epoch: 444 [1280/1762 (71%)]\tLoss: 2.537962\tLabel Loss: 0.001086\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 444 \tVal Loss: 2.187233\n",
            "Epoch: 444 \tTest Loss: 2.054915\n",
            "\n",
            "Epoch: 445 [0/1762 (0%)]\tLoss: 1.996427\tLabel Loss: 0.001062\n",
            "Epoch: 445 [640/1762 (36%)]\tLoss: 2.081653\tLabel Loss: 0.001099\n",
            "Epoch: 445 [1280/1762 (71%)]\tLoss: 1.970126\tLabel Loss: 0.001064\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 445 \tVal Loss: 2.194499\n",
            "Epoch: 445 \tTest Loss: 2.061500\n",
            "\n",
            "Epoch: 446 [0/1762 (0%)]\tLoss: 2.199430\tLabel Loss: 0.001047\n",
            "Epoch: 446 [640/1762 (36%)]\tLoss: 2.260299\tLabel Loss: 0.001087\n",
            "Epoch: 446 [1280/1762 (71%)]\tLoss: 2.142170\tLabel Loss: 0.001060\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 446 \tVal Loss: 2.202303\n",
            "Epoch: 446 \tTest Loss: 2.065815\n",
            "\n",
            "Epoch: 447 [0/1762 (0%)]\tLoss: 2.051565\tLabel Loss: 0.001091\n",
            "Epoch: 447 [640/1762 (36%)]\tLoss: 2.090152\tLabel Loss: 0.001065\n",
            "Epoch: 447 [1280/1762 (71%)]\tLoss: 1.939315\tLabel Loss: 0.001076\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 447 \tVal Loss: 2.202575\n",
            "Epoch: 447 \tTest Loss: 2.071778\n",
            "\n",
            "Epoch: 448 [0/1762 (0%)]\tLoss: 2.029396\tLabel Loss: 0.001071\n",
            "Epoch: 448 [640/1762 (36%)]\tLoss: 2.167461\tLabel Loss: 0.001080\n",
            "Epoch: 448 [1280/1762 (71%)]\tLoss: 2.128017\tLabel Loss: 0.001076\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 448 \tVal Loss: 2.176671\n",
            "Epoch: 448 \tTest Loss: 2.046644\n",
            "\n",
            "Epoch: 449 [0/1762 (0%)]\tLoss: 2.074507\tLabel Loss: 0.001019\n",
            "Epoch: 449 [640/1762 (36%)]\tLoss: 2.108632\tLabel Loss: 0.001059\n",
            "Epoch: 449 [1280/1762 (71%)]\tLoss: 2.209768\tLabel Loss: 0.001052\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 449 \tVal Loss: 2.196535\n",
            "Epoch: 449 \tTest Loss: 2.060646\n",
            "\n",
            "Epoch: 450 [0/1762 (0%)]\tLoss: 2.095756\tLabel Loss: 0.001065\n",
            "Epoch: 450 [640/1762 (36%)]\tLoss: 2.222888\tLabel Loss: 0.001014\n",
            "Epoch: 450 [1280/1762 (71%)]\tLoss: 1.956861\tLabel Loss: 0.001022\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 450 \tVal Loss: 2.193960\n",
            "Epoch: 450 \tTest Loss: 2.067653\n",
            "\n",
            "Epoch: 451 [0/1762 (0%)]\tLoss: 2.044034\tLabel Loss: 0.001036\n",
            "Epoch: 451 [640/1762 (36%)]\tLoss: 2.226049\tLabel Loss: 0.001046\n",
            "Epoch: 451 [1280/1762 (71%)]\tLoss: 2.365515\tLabel Loss: 0.001073\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 451 \tVal Loss: 2.186275\n",
            "Epoch: 451 \tTest Loss: 2.047762\n",
            "\n",
            "Epoch: 452 [0/1762 (0%)]\tLoss: 2.336422\tLabel Loss: 0.001053\n",
            "Epoch: 452 [640/1762 (36%)]\tLoss: 1.926993\tLabel Loss: 0.001096\n",
            "Epoch: 452 [1280/1762 (71%)]\tLoss: 2.031531\tLabel Loss: 0.001016\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 452 \tVal Loss: 2.180945\n",
            "Epoch: 452 \tTest Loss: 2.061732\n",
            "\n",
            "Epoch: 453 [0/1762 (0%)]\tLoss: 2.125846\tLabel Loss: 0.001020\n",
            "Epoch: 453 [640/1762 (36%)]\tLoss: 1.990621\tLabel Loss: 0.001243\n",
            "Epoch: 453 [1280/1762 (71%)]\tLoss: 2.059578\tLabel Loss: 0.001131\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 453 \tVal Loss: 2.210483\n",
            "Epoch: 453 \tTest Loss: 2.074876\n",
            "\n",
            "Epoch: 454 [0/1762 (0%)]\tLoss: 2.283399\tLabel Loss: 0.001110\n",
            "Epoch: 454 [640/1762 (36%)]\tLoss: 2.194800\tLabel Loss: 0.001050\n",
            "Epoch: 454 [1280/1762 (71%)]\tLoss: 2.222628\tLabel Loss: 0.001060\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 454 \tVal Loss: 2.205108\n",
            "Epoch: 454 \tTest Loss: 2.060487\n",
            "\n",
            "Epoch: 455 [0/1762 (0%)]\tLoss: 2.058225\tLabel Loss: 0.001101\n",
            "Epoch: 455 [640/1762 (36%)]\tLoss: 1.912073\tLabel Loss: 0.001025\n",
            "Epoch: 455 [1280/1762 (71%)]\tLoss: 2.165812\tLabel Loss: 0.001027\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 455 \tVal Loss: 2.174970\n",
            "Epoch: 455 \tTest Loss: 2.055708\n",
            "\n",
            "Epoch: 456 [0/1762 (0%)]\tLoss: 2.173254\tLabel Loss: 0.001035\n",
            "Epoch: 456 [640/1762 (36%)]\tLoss: 2.048154\tLabel Loss: 0.001028\n",
            "Epoch: 456 [1280/1762 (71%)]\tLoss: 1.934080\tLabel Loss: 0.001034\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 456 \tVal Loss: 2.175984\n",
            "Epoch: 456 \tTest Loss: 2.050053\n",
            "\n",
            "Epoch: 457 [0/1762 (0%)]\tLoss: 2.020884\tLabel Loss: 0.001030\n",
            "Epoch: 457 [640/1762 (36%)]\tLoss: 2.201020\tLabel Loss: 0.000988\n",
            "Epoch: 457 [1280/1762 (71%)]\tLoss: 2.397797\tLabel Loss: 0.001063\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 457 \tVal Loss: 2.186702\n",
            "Epoch: 457 \tTest Loss: 2.049420\n",
            "\n",
            "Epoch: 458 [0/1762 (0%)]\tLoss: 2.061192\tLabel Loss: 0.001111\n",
            "Epoch: 458 [640/1762 (36%)]\tLoss: 1.944468\tLabel Loss: 0.001058\n",
            "Epoch: 458 [1280/1762 (71%)]\tLoss: 2.006899\tLabel Loss: 0.001074\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 458 \tVal Loss: 2.195256\n",
            "Epoch: 458 \tTest Loss: 2.060820\n",
            "\n",
            "Epoch: 459 [0/1762 (0%)]\tLoss: 2.198225\tLabel Loss: 0.001032\n",
            "Epoch: 459 [640/1762 (36%)]\tLoss: 1.829433\tLabel Loss: 0.001023\n",
            "Epoch: 459 [1280/1762 (71%)]\tLoss: 1.996379\tLabel Loss: 0.001010\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 459 \tVal Loss: 2.186645\n",
            "Epoch: 459 \tTest Loss: 2.057786\n",
            "\n",
            "Epoch: 460 [0/1762 (0%)]\tLoss: 2.044518\tLabel Loss: 0.001085\n",
            "Epoch: 460 [640/1762 (36%)]\tLoss: 2.413046\tLabel Loss: 0.001013\n",
            "Epoch: 460 [1280/1762 (71%)]\tLoss: 2.254094\tLabel Loss: 0.001092\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 460 \tVal Loss: 2.194437\n",
            "Epoch: 460 \tTest Loss: 2.058994\n",
            "\n",
            "Epoch: 461 [0/1762 (0%)]\tLoss: 2.073382\tLabel Loss: 0.001038\n",
            "Epoch: 461 [640/1762 (36%)]\tLoss: 2.312974\tLabel Loss: 0.001027\n",
            "Epoch: 461 [1280/1762 (71%)]\tLoss: 2.217245\tLabel Loss: 0.001023\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 461 \tVal Loss: 2.174680\n",
            "Epoch: 461 \tTest Loss: 2.045511\n",
            "\n",
            "Epoch: 462 [0/1762 (0%)]\tLoss: 1.963865\tLabel Loss: 0.001036\n",
            "Epoch: 462 [640/1762 (36%)]\tLoss: 2.151844\tLabel Loss: 0.000997\n",
            "Epoch: 462 [1280/1762 (71%)]\tLoss: 2.026458\tLabel Loss: 0.001000\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 462 \tVal Loss: 2.174412\n",
            "Epoch: 462 \tTest Loss: 2.048197\n",
            "\n",
            "Epoch: 463 [0/1762 (0%)]\tLoss: 2.146860\tLabel Loss: 0.000979\n",
            "Epoch: 463 [640/1762 (36%)]\tLoss: 2.182798\tLabel Loss: 0.001047\n",
            "Epoch: 463 [1280/1762 (71%)]\tLoss: 1.982760\tLabel Loss: 0.001006\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 463 \tVal Loss: 2.207996\n",
            "Epoch: 463 \tTest Loss: 2.070824\n",
            "\n",
            "Epoch: 464 [0/1762 (0%)]\tLoss: 1.939480\tLabel Loss: 0.001014\n",
            "Epoch: 464 [640/1762 (36%)]\tLoss: 2.070151\tLabel Loss: 0.001048\n",
            "Epoch: 464 [1280/1762 (71%)]\tLoss: 2.244360\tLabel Loss: 0.001036\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 464 \tVal Loss: 2.182338\n",
            "Epoch: 464 \tTest Loss: 2.050952\n",
            "\n",
            "Epoch: 465 [0/1762 (0%)]\tLoss: 2.053712\tLabel Loss: 0.001003\n",
            "Epoch: 465 [640/1762 (36%)]\tLoss: 2.217920\tLabel Loss: 0.000994\n",
            "Epoch: 465 [1280/1762 (71%)]\tLoss: 2.071461\tLabel Loss: 0.001018\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 465 \tVal Loss: 2.211719\n",
            "Epoch: 465 \tTest Loss: 2.079328\n",
            "\n",
            "Epoch: 466 [0/1762 (0%)]\tLoss: 2.170892\tLabel Loss: 0.001045\n",
            "Epoch: 466 [640/1762 (36%)]\tLoss: 2.176128\tLabel Loss: 0.000992\n",
            "Epoch: 466 [1280/1762 (71%)]\tLoss: 2.260971\tLabel Loss: 0.001013\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 466 \tVal Loss: 2.188673\n",
            "Epoch: 466 \tTest Loss: 2.057839\n",
            "\n",
            "Epoch: 467 [0/1762 (0%)]\tLoss: 2.064171\tLabel Loss: 0.001030\n",
            "Epoch: 467 [640/1762 (36%)]\tLoss: 2.157920\tLabel Loss: 0.000991\n",
            "Epoch: 467 [1280/1762 (71%)]\tLoss: 1.908323\tLabel Loss: 0.001024\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 467 \tVal Loss: 2.185182\n",
            "Epoch: 467 \tTest Loss: 2.054942\n",
            "\n",
            "Epoch: 468 [0/1762 (0%)]\tLoss: 1.964389\tLabel Loss: 0.001053\n",
            "Epoch: 468 [640/1762 (36%)]\tLoss: 1.973903\tLabel Loss: 0.001003\n",
            "Epoch: 468 [1280/1762 (71%)]\tLoss: 1.838135\tLabel Loss: 0.001040\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 468 \tVal Loss: 2.187125\n",
            "Epoch: 468 \tTest Loss: 2.051571\n",
            "\n",
            "Epoch: 469 [0/1762 (0%)]\tLoss: 2.067127\tLabel Loss: 0.001003\n",
            "Epoch: 469 [640/1762 (36%)]\tLoss: 2.209237\tLabel Loss: 0.000953\n",
            "Epoch: 469 [1280/1762 (71%)]\tLoss: 2.210242\tLabel Loss: 0.001037\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 469 \tVal Loss: 2.176452\n",
            "Epoch: 469 \tTest Loss: 2.048090\n",
            "\n",
            "Epoch: 470 [0/1762 (0%)]\tLoss: 2.172947\tLabel Loss: 0.001011\n",
            "Epoch: 470 [640/1762 (36%)]\tLoss: 2.179129\tLabel Loss: 0.001002\n",
            "Epoch: 470 [1280/1762 (71%)]\tLoss: 1.966619\tLabel Loss: 0.000976\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 470 \tVal Loss: 2.188424\n",
            "Epoch: 470 \tTest Loss: 2.053046\n",
            "\n",
            "Epoch: 471 [0/1762 (0%)]\tLoss: 2.005398\tLabel Loss: 0.000987\n",
            "Epoch: 471 [640/1762 (36%)]\tLoss: 2.191264\tLabel Loss: 0.000994\n",
            "Epoch: 471 [1280/1762 (71%)]\tLoss: 2.224433\tLabel Loss: 0.001049\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 471 \tVal Loss: 2.185741\n",
            "Epoch: 471 \tTest Loss: 2.054653\n",
            "\n",
            "Epoch: 472 [0/1762 (0%)]\tLoss: 2.210029\tLabel Loss: 0.001128\n",
            "Epoch: 472 [640/1762 (36%)]\tLoss: 2.174514\tLabel Loss: 0.001042\n",
            "Epoch: 472 [1280/1762 (71%)]\tLoss: 2.024103\tLabel Loss: 0.001067\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 472 \tVal Loss: 2.191697\n",
            "Epoch: 472 \tTest Loss: 2.059774\n",
            "\n",
            "Epoch: 473 [0/1762 (0%)]\tLoss: 1.912357\tLabel Loss: 0.000989\n",
            "Epoch: 473 [640/1762 (36%)]\tLoss: 1.982636\tLabel Loss: 0.000993\n",
            "Epoch: 473 [1280/1762 (71%)]\tLoss: 2.193235\tLabel Loss: 0.000997\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 473 \tVal Loss: 2.184148\n",
            "Epoch: 473 \tTest Loss: 2.060139\n",
            "\n",
            "Epoch: 474 [0/1762 (0%)]\tLoss: 2.080122\tLabel Loss: 0.001129\n",
            "Epoch: 474 [640/1762 (36%)]\tLoss: 2.123192\tLabel Loss: 0.001016\n",
            "Epoch: 474 [1280/1762 (71%)]\tLoss: 2.019405\tLabel Loss: 0.000997\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 474 \tVal Loss: 2.196727\n",
            "Epoch: 474 \tTest Loss: 2.060742\n",
            "\n",
            "Epoch: 475 [0/1762 (0%)]\tLoss: 2.105253\tLabel Loss: 0.001007\n",
            "Epoch: 475 [640/1762 (36%)]\tLoss: 2.275947\tLabel Loss: 0.000988\n",
            "Epoch: 475 [1280/1762 (71%)]\tLoss: 2.295422\tLabel Loss: 0.001014\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 475 \tVal Loss: 2.170343\n",
            "Epoch: 475 \tTest Loss: 2.044879\n",
            "\n",
            "Epoch: 476 [0/1762 (0%)]\tLoss: 1.844485\tLabel Loss: 0.001019\n",
            "Epoch: 476 [640/1762 (36%)]\tLoss: 2.188402\tLabel Loss: 0.000958\n",
            "Epoch: 476 [1280/1762 (71%)]\tLoss: 1.966914\tLabel Loss: 0.000980\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 476 \tVal Loss: 2.185786\n",
            "Epoch: 476 \tTest Loss: 2.064824\n",
            "\n",
            "Epoch: 477 [0/1762 (0%)]\tLoss: 2.193924\tLabel Loss: 0.000978\n",
            "Epoch: 477 [640/1762 (36%)]\tLoss: 2.080628\tLabel Loss: 0.000991\n",
            "Epoch: 477 [1280/1762 (71%)]\tLoss: 2.125790\tLabel Loss: 0.000956\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 477 \tVal Loss: 2.172305\n",
            "Epoch: 477 \tTest Loss: 2.052953\n",
            "\n",
            "Epoch: 478 [0/1762 (0%)]\tLoss: 2.095544\tLabel Loss: 0.001050\n",
            "Epoch: 478 [640/1762 (36%)]\tLoss: 2.052581\tLabel Loss: 0.001001\n",
            "Epoch: 478 [1280/1762 (71%)]\tLoss: 2.053760\tLabel Loss: 0.000972\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 478 \tVal Loss: 2.190730\n",
            "Epoch: 478 \tTest Loss: 2.060686\n",
            "\n",
            "Epoch: 479 [0/1762 (0%)]\tLoss: 2.018303\tLabel Loss: 0.000951\n",
            "Epoch: 479 [640/1762 (36%)]\tLoss: 2.060474\tLabel Loss: 0.000973\n",
            "Epoch: 479 [1280/1762 (71%)]\tLoss: 2.143108\tLabel Loss: 0.000964\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 479 \tVal Loss: 2.179590\n",
            "Epoch: 479 \tTest Loss: 2.050655\n",
            "\n",
            "Epoch: 480 [0/1762 (0%)]\tLoss: 1.935631\tLabel Loss: 0.000945\n",
            "Epoch: 480 [640/1762 (36%)]\tLoss: 2.158546\tLabel Loss: 0.000997\n",
            "Epoch: 480 [1280/1762 (71%)]\tLoss: 2.243163\tLabel Loss: 0.000951\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 480 \tVal Loss: 2.197467\n",
            "Epoch: 480 \tTest Loss: 2.068354\n",
            "\n",
            "Epoch: 481 [0/1762 (0%)]\tLoss: 2.013485\tLabel Loss: 0.001009\n",
            "Epoch: 481 [640/1762 (36%)]\tLoss: 1.947551\tLabel Loss: 0.000941\n",
            "Epoch: 481 [1280/1762 (71%)]\tLoss: 2.222183\tLabel Loss: 0.000946\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 481 \tVal Loss: 2.182287\n",
            "Epoch: 481 \tTest Loss: 2.052932\n",
            "\n",
            "Epoch: 482 [0/1762 (0%)]\tLoss: 2.049275\tLabel Loss: 0.000957\n",
            "Epoch: 482 [640/1762 (36%)]\tLoss: 1.965056\tLabel Loss: 0.000940\n",
            "Epoch: 482 [1280/1762 (71%)]\tLoss: 1.929977\tLabel Loss: 0.000973\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 482 \tVal Loss: 2.185041\n",
            "Epoch: 482 \tTest Loss: 2.058161\n",
            "\n",
            "Epoch: 483 [0/1762 (0%)]\tLoss: 2.018849\tLabel Loss: 0.000946\n",
            "Epoch: 483 [640/1762 (36%)]\tLoss: 2.023489\tLabel Loss: 0.000960\n",
            "Epoch: 483 [1280/1762 (71%)]\tLoss: 2.214059\tLabel Loss: 0.000976\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 483 \tVal Loss: 2.189628\n",
            "Epoch: 483 \tTest Loss: 2.059874\n",
            "\n",
            "Epoch: 484 [0/1762 (0%)]\tLoss: 2.093047\tLabel Loss: 0.001016\n",
            "Epoch: 484 [640/1762 (36%)]\tLoss: 1.705757\tLabel Loss: 0.000943\n",
            "Epoch: 484 [1280/1762 (71%)]\tLoss: 2.236822\tLabel Loss: 0.000970\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 484 \tVal Loss: 2.220665\n",
            "Epoch: 484 \tTest Loss: 2.083847\n",
            "\n",
            "Epoch: 485 [0/1762 (0%)]\tLoss: 2.100504\tLabel Loss: 0.001078\n",
            "Epoch: 485 [640/1762 (36%)]\tLoss: 2.136971\tLabel Loss: 0.000982\n",
            "Epoch: 485 [1280/1762 (71%)]\tLoss: 1.996837\tLabel Loss: 0.001006\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 485 \tVal Loss: 2.180353\n",
            "Epoch: 485 \tTest Loss: 2.047511\n",
            "\n",
            "Epoch: 486 [0/1762 (0%)]\tLoss: 2.192821\tLabel Loss: 0.000971\n",
            "Epoch: 486 [640/1762 (36%)]\tLoss: 2.033133\tLabel Loss: 0.000945\n",
            "Epoch: 486 [1280/1762 (71%)]\tLoss: 2.151736\tLabel Loss: 0.000951\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 486 \tVal Loss: 2.172092\n",
            "Epoch: 486 \tTest Loss: 2.044785\n",
            "\n",
            "Epoch: 487 [0/1762 (0%)]\tLoss: 2.054852\tLabel Loss: 0.000917\n",
            "Epoch: 487 [640/1762 (36%)]\tLoss: 2.162733\tLabel Loss: 0.000996\n",
            "Epoch: 487 [1280/1762 (71%)]\tLoss: 2.077301\tLabel Loss: 0.001091\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 487 \tVal Loss: 2.179104\n",
            "Epoch: 487 \tTest Loss: 2.051241\n",
            "\n",
            "Epoch: 488 [0/1762 (0%)]\tLoss: 2.296151\tLabel Loss: 0.000985\n",
            "Epoch: 488 [640/1762 (36%)]\tLoss: 2.149561\tLabel Loss: 0.001070\n",
            "Epoch: 488 [1280/1762 (71%)]\tLoss: 1.980758\tLabel Loss: 0.000961\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 488 \tVal Loss: 2.176899\n",
            "Epoch: 488 \tTest Loss: 2.053877\n",
            "\n",
            "Epoch: 489 [0/1762 (0%)]\tLoss: 2.054968\tLabel Loss: 0.000955\n",
            "Epoch: 489 [640/1762 (36%)]\tLoss: 2.131524\tLabel Loss: 0.000950\n",
            "Epoch: 489 [1280/1762 (71%)]\tLoss: 1.895461\tLabel Loss: 0.000986\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 489 \tVal Loss: 2.186084\n",
            "Epoch: 489 \tTest Loss: 2.049379\n",
            "\n",
            "Epoch: 490 [0/1762 (0%)]\tLoss: 2.107626\tLabel Loss: 0.000922\n",
            "Epoch: 490 [640/1762 (36%)]\tLoss: 2.169887\tLabel Loss: 0.000993\n",
            "Epoch: 490 [1280/1762 (71%)]\tLoss: 1.962531\tLabel Loss: 0.000922\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 490 \tVal Loss: 2.186246\n",
            "Epoch: 490 \tTest Loss: 2.056636\n",
            "\n",
            "Epoch: 491 [0/1762 (0%)]\tLoss: 2.171282\tLabel Loss: 0.000984\n",
            "Epoch: 491 [640/1762 (36%)]\tLoss: 2.025111\tLabel Loss: 0.000932\n",
            "Epoch: 491 [1280/1762 (71%)]\tLoss: 2.135800\tLabel Loss: 0.001018\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 491 \tVal Loss: 2.200399\n",
            "Epoch: 491 \tTest Loss: 2.061988\n",
            "\n",
            "Epoch: 492 [0/1762 (0%)]\tLoss: 2.291915\tLabel Loss: 0.001025\n",
            "Epoch: 492 [640/1762 (36%)]\tLoss: 2.261194\tLabel Loss: 0.000966\n",
            "Epoch: 492 [1280/1762 (71%)]\tLoss: 1.978512\tLabel Loss: 0.000986\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 492 \tVal Loss: 2.212693\n",
            "Epoch: 492 \tTest Loss: 2.083441\n",
            "\n",
            "Epoch: 493 [0/1762 (0%)]\tLoss: 2.110676\tLabel Loss: 0.000928\n",
            "Epoch: 493 [640/1762 (36%)]\tLoss: 1.983711\tLabel Loss: 0.000999\n",
            "Epoch: 493 [1280/1762 (71%)]\tLoss: 1.912650\tLabel Loss: 0.001001\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 493 \tVal Loss: 2.179814\n",
            "Epoch: 493 \tTest Loss: 2.053784\n",
            "\n",
            "Epoch: 494 [0/1762 (0%)]\tLoss: 2.048838\tLabel Loss: 0.000940\n",
            "Epoch: 494 [640/1762 (36%)]\tLoss: 2.012434\tLabel Loss: 0.000966\n",
            "Epoch: 494 [1280/1762 (71%)]\tLoss: 2.297434\tLabel Loss: 0.000947\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 494 \tVal Loss: 2.178735\n",
            "Epoch: 494 \tTest Loss: 2.062084\n",
            "\n",
            "Epoch: 495 [0/1762 (0%)]\tLoss: 2.184543\tLabel Loss: 0.000973\n",
            "Epoch: 495 [640/1762 (36%)]\tLoss: 2.148645\tLabel Loss: 0.000933\n",
            "Epoch: 495 [1280/1762 (71%)]\tLoss: 2.151861\tLabel Loss: 0.000931\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 495 \tVal Loss: 2.171471\n",
            "Epoch: 495 \tTest Loss: 2.045244\n",
            "\n",
            "Epoch: 496 [0/1762 (0%)]\tLoss: 1.992882\tLabel Loss: 0.000951\n",
            "Epoch: 496 [640/1762 (36%)]\tLoss: 2.236588\tLabel Loss: 0.000909\n",
            "Epoch: 496 [1280/1762 (71%)]\tLoss: 2.127816\tLabel Loss: 0.000921\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 496 \tVal Loss: 2.181150\n",
            "Epoch: 496 \tTest Loss: 2.046405\n",
            "\n",
            "Epoch: 497 [0/1762 (0%)]\tLoss: 2.087093\tLabel Loss: 0.000943\n",
            "Epoch: 497 [640/1762 (36%)]\tLoss: 1.907402\tLabel Loss: 0.000899\n",
            "Epoch: 497 [1280/1762 (71%)]\tLoss: 2.087388\tLabel Loss: 0.000932\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 497 \tVal Loss: 2.187615\n",
            "Epoch: 497 \tTest Loss: 2.053287\n",
            "\n",
            "Epoch: 498 [0/1762 (0%)]\tLoss: 2.142152\tLabel Loss: 0.000932\n",
            "Epoch: 498 [640/1762 (36%)]\tLoss: 2.166870\tLabel Loss: 0.000951\n",
            "Epoch: 498 [1280/1762 (71%)]\tLoss: 2.174266\tLabel Loss: 0.001041\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 498 \tVal Loss: 2.200986\n",
            "Epoch: 498 \tTest Loss: 2.069500\n",
            "\n",
            "Epoch: 499 [0/1762 (0%)]\tLoss: 2.217570\tLabel Loss: 0.000983\n",
            "Epoch: 499 [640/1762 (36%)]\tLoss: 1.975603\tLabel Loss: 0.000939\n",
            "Epoch: 499 [1280/1762 (71%)]\tLoss: 1.884121\tLabel Loss: 0.000931\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 499 \tVal Loss: 2.199335\n",
            "Epoch: 499 \tTest Loss: 2.063415\n",
            "\n",
            "Epoch: 500 [0/1762 (0%)]\tLoss: 2.209823\tLabel Loss: 0.000977\n",
            "Epoch: 500 [640/1762 (36%)]\tLoss: 2.420662\tLabel Loss: 0.000956\n",
            "Epoch: 500 [1280/1762 (71%)]\tLoss: 2.063920\tLabel Loss: 0.000912\n",
            "Time used: 2\n",
            "\n",
            "Epoch: 500 \tVal Loss: 2.199336\n",
            "Epoch: 500 \tTest Loss: 2.060208\n",
            "\n",
            "Parameter containing:\n",
            "tensor([1.7284, 0.4559, 0.3880, 1.0551], device='cuda:0', requires_grad=True)\n",
            "Val RMSE: 2.1703 \tTest RMSE: 2.0449\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "P7JCx0SqB_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss= np.load('/content/checkpoint/loss.npy')\n",
        "mae= np.load('/content/checkpoint/mae.npy')\n",
        "rmse= np.load('/content/checkpoint/rmse.npy')"
      ],
      "metadata": {
        "id": "aEGi57_BC2hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.shape)\n",
        "print(mae.shape)\n",
        "print(rmse.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu2VmymGC5gs",
        "outputId": "f774eef5-d6f4-4870-dceb-baf2b891dd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 500)\n",
            "(2, 500)\n",
            "(2, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the train, val, and test losses\n",
        "train_loss = loss[0]\n",
        "val_loss = loss[1]\n",
        "test_loss = loss[2]\n",
        "val_mae = mae[0]\n",
        "test_mae = mae[1]\n",
        "val_rmse = rmse[0]\n",
        "test_rmse =rmse[1]"
      ],
      "metadata": {
        "id": "kyuBu5krC77h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DpzPTzeHC-sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot the loss curve\n",
        "plt.plot(x, train_loss, label='Train Loss')\n",
        "#plt.plot(x, val_loss, label='Validation Loss')\n",
        "plt.plot(x, test_loss, label='Test Loss')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "#plt.savefig('loss_curve1.pdf', bbox_inches='tight', pad_inches=0)\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tDmxStaoDA0h",
        "outputId": "d2b8a110-cc1d-46d8-c9d6-68cfc2501481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loss[-1])\n",
        "print(val_loss[-1])\n",
        "print(test_loss[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmy_6Cdqxfxl",
        "outputId": "0064d2d2-50c7-4133-9d81-06759048481d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161584920000.0\n",
            "602209400.0\n",
            "252681200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_mae[-1])\n",
        "print(test_mae[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5406crr1xtZ0",
        "outputId": "d41b7976-47a9-4542-9f79-9940d3609052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.957607\n",
            "34.114666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_rmse[-1])\n",
        "print(test_rmse[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6foOiIx0-P",
        "outputId": "b5229ea2-9ae0-4dd3-d6e5-30f604a0ec28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.37294\n",
            "60.8839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_5_val_mae = val_mae[-5:]\n",
        "last_5_test_mae = test_mae[-5:]\n",
        "last_5_val_rmse = val_rmse[-5:]\n",
        "last_5_test_rmse = test_rmse[-5:]"
      ],
      "metadata": {
        "id": "i0SCwUwMi-qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MAE\n",
        "mae_val = np.mean(last_5_val_mae)\n",
        "mae_test = np.mean(last_5_test_mae)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_val = np.mean(last_5_val_rmse)\n",
        "rmse_test = np.mean(last_5_test_rmse)\n",
        "\n",
        "# Print the results\n",
        "print(\"MAE - Validation: {:.4f}, Test: {:.4f}\".format( mae_val, mae_test))\n",
        "print(\"RMSE - Validation: {:.4f}, Test: {:.4f}\".format( rmse_val, rmse_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANluzrtbDENx",
        "outputId": "4fbe61f1-5b4a-433c-b752-0bda64e8d903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE - Validation: 5.3115, Test: 4.6779\n",
            "RMSE - Validation: 10.1102, Test: 7.7564\n"
          ]
        }
      ]
    }
  ]
}